{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0773d1-0f15-49cf-bd99-88c7602c1671",
   "metadata": {},
   "source": [
    "# Test EOF reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9e9a6-847c-4c1c-8746-23d1d8a35ddf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e41cee-9dc6-4386-b7fa-a7e8c0876353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pathlib\n",
    "import os\n",
    "import src.utils\n",
    "import cartopy.crs as ccrs\n",
    "import cmocean\n",
    "\n",
    "## initialize RNG\n",
    "rng = np.random.default_rng(seed=100)\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a3905-0610-41c1-9e2e-a57c99b14d04",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7982e-cf1c-4fc5-93c3-34b6883fe102",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which model to look at\n",
    "model = \"cesm\"\n",
    "\n",
    "## get data filepath for given model\n",
    "MODEL_FP = DATA_FP / model\n",
    "\n",
    "## model data\n",
    "model_load_fp = pathlib.Path(MODEL_FP, \"Th_anom.nc\")\n",
    "Th_model = xr.open_dataset(model_load_fp)\n",
    "\n",
    "## EOFs (only do sst)\n",
    "eofs_sst = src.utils.load_eofs(MODEL_FP / \"eofs_tos.nc\")\n",
    "eofs_ssh = src.utils.load_eofs(MODEL_FP / \"eofs_zos.nc\")\n",
    "\n",
    "## for convenience, put components and scores into datasets\n",
    "components = xr.merge(\n",
    "    [eofs_sst.components().rename(\"sst\"), eofs_ssh.components().rename(\"ssh\")]\n",
    ")\n",
    "scores = xr.merge([eofs_sst.scores().rename(\"sst\"), eofs_ssh.scores().rename(\"ssh\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b885c-3b48-462e-b207-049d57eba1f9",
   "metadata": {},
   "source": [
    "## Compute anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ca819-df07-48c3-bb23-7976098dd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emean, anom = src.utils.separate_forced(scores, n=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadcfec-6ec6-46fb-afde-5d1796a828c4",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afeeb0-d002-4028-9ea1-a15f05765fa3",
   "metadata": {},
   "source": [
    "### Identity reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f89ea6-064c-4810-adda-420f2473cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get random subset for testing\n",
    "sample = scores.isel(member=slice(2, 4), time=slice(24, 60))\n",
    "\n",
    "## identity function\n",
    "identity = lambda x: x\n",
    "\n",
    "## reconstruct 2 different ways\n",
    "r0 = eofs_sst.inverse_transform(sample[\"sst\"])\n",
    "r1 = src.utils.reconstruct_fn(components[\"sst\"], sample[\"sst\"], fn=identity)\n",
    "\n",
    "## check allclose\n",
    "print(f\"All close? {np.max(np.abs(r0-r1)).values < 1e-10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb37f7c-9809-43cd-a121-24736effa681",
   "metadata": {},
   "source": [
    "### Ni単o 3.4 reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590b383-38a0-4b13-a467-febcc9df1ba9",
   "metadata": {},
   "source": [
    "#### anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c46407-4b71-4476-be55-2a9f7f9339be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## next, nino 34\n",
    "n34_r0 = src.utils.get_nino34(r0)\n",
    "n34_r1 = src.utils.reconstruct_fn(\n",
    "    eofs_sst.components(), sample[\"sst\"], fn=src.utils.get_nino34\n",
    ")\n",
    "print(f\"All close? {np.allclose(n34_r0, n34_r1)}\\n\")\n",
    "\n",
    "## get reconstruction error on full dataset\n",
    "n34_recon = src.utils.reconstruct_fn(\n",
    "    components[\"sst\"], anom[\"sst\"], fn=src.utils.get_nino34\n",
    ")\n",
    "h_recon = src.utils.reconstruct_fn(\n",
    "    components[\"ssh\"], anom[\"ssh\"], fn=src.utils.get_RO_h\n",
    ")\n",
    "hw_recon = src.utils.reconstruct_fn(\n",
    "    components[\"ssh\"], anom[\"ssh\"], fn=src.utils.get_RO_hw\n",
    ")\n",
    "\n",
    "## compute correlation with non-truncated data\n",
    "corr_n34 = xr.corr(n34_recon, Th_model[\"T_34\"].sel(time=n34_recon.time))\n",
    "corr_h = xr.corr(h_recon, Th_model[\"h\"].sel(time=n34_recon.time))\n",
    "corr_hw = xr.corr(hw_recon, Th_model[\"h_w\"].sel(time=n34_recon.time))\n",
    "\n",
    "print(f\"Corr w/ non-truncated Ni単o 3.4 index: {corr_n34:.5f}\")\n",
    "print(f\"Corr w/ non-truncated h index:        {corr_h:.5f}\")\n",
    "print(f\"Corr w/ non-truncated hw index:       {corr_hw:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0c0a8-bf27-4d56-adda-1dd517809cde",
   "metadata": {},
   "source": [
    "Plot a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe9dad-f6e0-4921-94c2-4e728adad55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify time index for plotting\n",
    "sample_idx = dict(member=20, time=slice(-120, None))\n",
    "\n",
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7.5, 2))\n",
    "\n",
    "## plot Ni単o 3.4\n",
    "axs[0].set_title(\"Ni単o 3.4\")\n",
    "axs[0].plot(Th_model[\"T_34\"].isel(sample_idx))\n",
    "axs[0].plot(n34_recon.isel(sample_idx), ls=\"--\")\n",
    "\n",
    "## plot h\n",
    "axs[1].set_title(r\"$h$\")\n",
    "axs[1].plot(Th_model[\"h\"].isel(sample_idx))\n",
    "axs[1].plot(h_recon.isel(sample_idx), ls=\"--\")\n",
    "\n",
    "## plot hw\n",
    "axs[2].set_title(r\"$h_w$\")\n",
    "axs[2].plot(Th_model[\"h_w\"].isel(sample_idx))\n",
    "axs[2].plot(hw_recon.isel(sample_idx), ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4a12a-023e-4cf4-b03c-291a1d5abb9e",
   "metadata": {},
   "source": [
    "#### forced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e66c9-5af3-4303-abd4-ba6d4bf37e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground truth\n",
    "model_load_fp = pathlib.Path(MODEL_FP, \"Th_emean.nc\")\n",
    "emean_truth = xr.open_dataset(model_load_fp)[[\"T_34\", \"h\"]]\n",
    "\n",
    "### reconstruction\n",
    "n34_recon = src.utils.reconstruct_fn(\n",
    "    components[\"sst\"], emean[\"sst\"], fn=src.utils.get_nino34\n",
    ")\n",
    "h_recon = src.utils.reconstruct_fn(\n",
    "    components[\"ssh\"], emean[\"ssh\"], fn=src.utils.get_RO_h\n",
    ")\n",
    "emean_recon = xr.merge([n34_recon.rename(\"T_34\"), h_recon.rename(\"h\")])\n",
    "\n",
    "## unstack year and month\n",
    "emean_recon = src.utils.unstack_month_and_year(emean_recon)\n",
    "emean_truth = src.utils.unstack_month_and_year(emean_truth)\n",
    "\n",
    "## Check correlation for each month is close\n",
    "monthly_corr = xr.merge(\n",
    "    [xr.corr(emean_truth[v], emean_recon[v], dim=\"year\") for v in list(emean_truth)]\n",
    ")\n",
    "\n",
    "## compute diff\n",
    "all_close = (np.abs(1 - monthly_corr) < 1e-5).all()\n",
    "\n",
    "## print out results\n",
    "for v in [\"T_34\", \"h\"]:\n",
    "    print(f\"{v} all close?: {all_close[v].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d38d6b-a20c-4a95-98ac-4c0f7d5b4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which variable to plot\n",
    "v = \"T_34\"\n",
    "\n",
    "## get plot data\n",
    "p0 = emean_truth[v].mean(\"month\") - emean_truth[v].mean()\n",
    "p1 = emean_recon[v].mean(\"month\") - emean_recon[v].mean()\n",
    "diff = (emean_recon - emean_truth)[v].mean(\"month\")\n",
    "\n",
    "## make plot\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "ax.plot(p0.year, p0, label=\"Truth\")\n",
    "ax.plot(p1.year, p1, ls=\"--\", label=\"Recon.\")\n",
    "ax.plot(diff.year, diff, label=\"difference\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b443fb9-cb3c-4225-bff1-191de0050145",
   "metadata": {},
   "source": [
    "### Test spatial recon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a4e7d-2b71-468c-b7f0-b054c8be5f64",
   "metadata": {},
   "source": [
    "preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9e8c3-e1c2-44aa-ab56-38f572e1cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    \"\"\"removing 2nd-order polynomial from each calendar month\"\"\"\n",
    "\n",
    "    ## detrending function\n",
    "    detrend_fn = lambda x: src.utils.detrend_dim(x, dim=\"time\", deg=2)\n",
    "\n",
    "    ## get anomalies and remainder\n",
    "    anom = x.groupby(\"time.month\").map(detrend_fn)\n",
    "    forced = x - anom\n",
    "    return anom, forced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2dfc0-c55b-4e13-b830-8e5b08dc42f9",
   "metadata": {},
   "source": [
    "Get detrended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb809426-6838-4ba2-b049-0116f78c03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forced_diff(forced):\n",
    "    \"\"\"given forced component, get difference from clim\"\"\"\n",
    "\n",
    "    ## get climatology\n",
    "    clim = forced.isel(time=slice(None, 360)).groupby(\"time.month\").mean()\n",
    "\n",
    "    ## subtract off clim\n",
    "    return forced.groupby(\"time.month\") - clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd5e9d-0de6-4dae-b6f1-dd9181b15f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## member to look at\n",
    "member = rng.choice(scores.member.values).item()\n",
    "\n",
    "## time idx to reconstruct\n",
    "# t_idx = -rng.choice(1032)\n",
    "t_idx = np.arange(-36, -24)\n",
    "t_ = t_idx[0]\n",
    "\n",
    "## get ground truth\n",
    "truth = xr.open_dataset(\n",
    "    pathlib.Path(\n",
    "        DATA_FP, f\"mpi/ts/cmip6_MPI-ESM1-2-LR_ssp585_r{member}i1p1f1_ts_2015_2100.nc\"\n",
    "    )\n",
    ")\n",
    "truth = truth[\"sst\"].compute()\n",
    "\n",
    "## get reconstruction\n",
    "proj = scores[\"sst\"].sel(member=member).sel(time=truth.time)\n",
    "\n",
    "## apply detrending to both and get specified sample\n",
    "truth_detrend, truth_forced = preprocess(truth)\n",
    "proj_detrend, proj_forced = preprocess(proj)\n",
    "\n",
    "## subset in time for anoms\n",
    "truth_detrend = truth_detrend.isel(time=t_)\n",
    "proj_detrend = proj_detrend.isel(time=t_)\n",
    "\n",
    "## average in time for forced component\n",
    "truth_forced = get_forced_diff(truth_forced).isel(time=t_idx).mean(\"time\")\n",
    "proj_forced = get_forced_diff(proj_forced).isel(time=t_idx).mean(\"time\")\n",
    "\n",
    "## reconstruct projections\n",
    "recon_detrend = src.utils.reconstruct_fn(components[\"sst\"], proj_detrend, fn=identity)\n",
    "recon_forced = src.utils.reconstruct_fn(components[\"sst\"], proj_forced, fn=identity)\n",
    "\n",
    "## make sure NaNs match\n",
    "is_nan = np.isnan(truth_forced)\n",
    "recon_forced.values[is_nan] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256f02c-a4da-437c-a934-04da41fe1ad1",
   "metadata": {},
   "source": [
    "Plot reconstruction and difference as sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e7dcf-fa73-4735-8204-508bc35f6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify labels\n",
    "labels = [\"ground truth\", \"reconstruction\", \"error\"]\n",
    "amps = np.array([3, 3, 0.3])\n",
    "\n",
    "## anomaly component\n",
    "kwargs = dict(cmap=\"cmo.balance\", levels=src.utils.make_cb_range(3, 0.3), extend=\"both\")\n",
    "diff_kwargs = dict(kwargs, levels=src.utils.make_cb_range(0.3, 0.03))\n",
    "fig, axs, _, _ = src.utils.spatial_comp(\n",
    "    recon_detrend, truth_detrend, kwargs=kwargs, diff_kwargs=diff_kwargs\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## forced component\n",
    "kwargs = dict(cmap=\"cmo.balance\", levels=src.utils.make_cb_range(4, 0.4), extend=\"both\")\n",
    "diff_kwargs = dict(kwargs, levels=src.utils.make_cb_range(0.1, 0.01))\n",
    "fig, axs, _, _ = src.utils.spatial_comp(\n",
    "    recon_forced, truth_forced, kwargs=kwargs, diff_kwargs=diff_kwargs\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96bf11e-47b8-43b2-8e18-efc645101ded",
   "metadata": {},
   "source": [
    "### spatial variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06351e26-0c71-4967-94cc-03491c2b3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute rolling mean (so ensemble-dim doesn't have zero mean...)\n",
    "emean, anom = src.utils.separate_forced(scores, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619fe68-b6fa-4dca-aa77-36069057342e",
   "metadata": {},
   "source": [
    "Gridcell-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cff7d2-78b0-4025-8f7c-308fb7178f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time index\n",
    "t_idx = dict(time=slice(-120, None))\n",
    "\n",
    "## point to check std dev. at\n",
    "posn_coords = dict(latitude=-20.5, longitude=200.5)\n",
    "\n",
    "## compute using custom function\n",
    "std0_all = src.utils.reconstruct_std(\n",
    "    scores=anom.isel(t_idx), components=components\n",
    ").compute()\n",
    "std0 = std0_all.sel(posn_coords)\n",
    "\n",
    "## check at single point (reconstruct, then compute std dev.)\n",
    "sel_fn = lambda x: x.sel(posn_coords)\n",
    "recon = src.utils.reconstruct_fn(components, anom.isel(t_idx), fn=sel_fn)\n",
    "recon_prime = recon - recon.mean([\"member\", \"time\"])\n",
    "std1 = np.sqrt((recon_prime**2).mean([\"time\", \"member\"]))\n",
    "\n",
    "## use built-in\n",
    "std2 = recon.std([\"time\", \"member\"])\n",
    "\n",
    "print(f\"All close? {np.allclose(std0.to_dataarray(), std1.to_dataarray())}\")\n",
    "print(f\"All close? {np.allclose(std1.to_dataarray(), std2.to_dataarray())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6856712-593c-4a0d-ae36-cd72e7152629",
   "metadata": {},
   "source": [
    "Function of the state (latitude-mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d590c6-97d9-4c33-9f79-4ed3a2747d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## func to get meridional mean\n",
    "eq_mean = lambda x: x.mean(\"latitude\")\n",
    "\n",
    "## specify longitude\n",
    "posn_coords = dict(longitude=200.5)\n",
    "\n",
    "## compute using custom function\n",
    "std0_all = src.utils.reconstruct_std(\n",
    "    scores=anom.isel(t_idx), components=components, fn=eq_mean\n",
    ").compute()\n",
    "std0 = std0_all.sel(posn_coords)\n",
    "\n",
    "## check at single point (reconstruct, then compute std dev)\n",
    "sel_fn = lambda x: eq_mean(x.sel(posn_coords))\n",
    "recon = src.utils.reconstruct_fn(components, anom.isel(t_idx), fn=sel_fn)\n",
    "std1 = recon.std([\"time\", \"member\"])\n",
    "\n",
    "print(f\"All close? {np.allclose(std0.to_dataarray(), std1.to_dataarray())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac6685-9e99-4a57-aff8-c5287e034451",
   "metadata": {},
   "source": [
    "#### synthetic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6990cf-4eb4-44c9-9b08-f50d04803842",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "n = 24\n",
    "\n",
    "## generate random data\n",
    "rng = np.random.default_rng()\n",
    "X = rng.normal(size=(m, n))\n",
    "\n",
    "## get true std dev\n",
    "stdX = np.sqrt(np.diag(src.utils.get_cov(X)))\n",
    "\n",
    "## do SVD on data\n",
    "U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "\n",
    "## compute covariance and reconstruct variance\n",
    "scores_cov = src.utils.get_cov(Vt)\n",
    "stdXhat = np.sqrt(np.diag(U @ S @ scores_cov @ S @ U.T))\n",
    "\n",
    "print(f\"All close? {np.allclose(stdX, stdXhat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
