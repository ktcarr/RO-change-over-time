{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287d082a-1ad3-4544-b5d8-25ad7a9da4e9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a29b8-4a30-45c8-99c2-7822bb9738b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import xeofs as xe\n",
    "import time\n",
    "\n",
    "## specify filepath for data\n",
    "DATA_FP = pathlib.Path(\"/vortexfs1/home/kcarr/enso2025_xro/data\")\n",
    "# DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI for presentation\n",
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ee97b-5871-40d3-b923-bbf84af00c1a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1197f-1557-42b0-8ab7-29fe2b11f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_pattern(name, sim, n):\n",
    "    \"\"\"\n",
    "    Function to get file pattern. Args:\n",
    "        - name: \"ts\" or \"ssh\"\n",
    "        - simulation type: one of \"historical\" or \"ssp585\"\n",
    "        - n: ensemble member ID, ranging from 1 to 50\n",
    "    \"\"\"\n",
    "    return (DATA_FP / \"mpi\" / name).glob(f\"*{sim}*r{n}i*.nc\")\n",
    "\n",
    "\n",
    "def load_member(name, sim, n):\n",
    "    \"\"\"load ensemble member. Args:\n",
    "    - name: \"ts\" or \"ssh\"\n",
    "    - simulation type: one of \"historical\" or \"ssp585\"\n",
    "    - n: ensemble member ID, ranging from 1 to 50\n",
    "    \"\"\"\n",
    "    return xr.open_mfdataset(file_pattern(name, sim, n))\n",
    "\n",
    "\n",
    "def compute_T_indices(data):\n",
    "    \"\"\"\n",
    "    See Figure 1 in Vialard et al (2025). Compute following indices:\n",
    "        - T_3: Niño 3 index (5°N–5°S,150°–90°W)\n",
    "        - T_34: Niño 3.4 index (5°N–5°S,170°–120°W)\n",
    "    \"\"\"\n",
    "\n",
    "    ## specify coords for boxes\n",
    "    T_3_kwargs = dict(latitude=slice(-5, 5), longitude=slice(210, 270))\n",
    "    T_34_kwargs = dict(latitude=slice(-5, 5), longitude=slice(190, 240))\n",
    "\n",
    "    ## compute indices\n",
    "    T_3 = spatial_avg(data[\"sst\"].sel(T_3_kwargs)).rename(\"T_3\")\n",
    "    T_34 = spatial_avg(data[\"sst\"].sel(T_34_kwargs)).rename(\"T_34\")\n",
    "\n",
    "    return xr.merge([T_3, T_34, data[\"sst_trop\"], data[\"ts_glob\"]])\n",
    "\n",
    "\n",
    "def compute_h_indices(data):\n",
    "    \"\"\"\n",
    "    See Figure 1 in Vialard et al (2025). Compute following indices:\n",
    "        - h_w: western Pacific SSH (5°N–5°S, 120°E−150°W)\n",
    "        - h: equatorial Pacific SSH (5°N–5°S, 120°E−75°W)\n",
    "    \"\"\"\n",
    "\n",
    "    ## speicfy coords for boxes\n",
    "    h_w_kwargs = dict(latitude=slice(-5, 5), longitude=slice(120, 210))\n",
    "    h_kwargs = dict(latitude=slice(-5, 5), longitude=slice(120, 285))\n",
    "\n",
    "    ## compute indices\n",
    "    h_w = spatial_avg(data[\"ssh\"].sel(h_w_kwargs)).rename(\"h_w\")\n",
    "    h = spatial_avg(data[\"ssh\"].sel(h_kwargs)).rename(\"h\")\n",
    "\n",
    "    return xr.merge(\n",
    "        [h_w.rename(\"h_w\"), h.rename(\"h\"), data[\"ssh_trop\"], data[\"ssh_glob\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_member_indices(sim, n):\n",
    "    \"\"\"compute T and h indices for given ensemble member and simulation\"\"\"\n",
    "\n",
    "    ## shared arguments\n",
    "    kwargs = dict(sim=sim, n=n)\n",
    "\n",
    "    ## compute T indices\n",
    "    sst = load_member(\"ts\", **kwargs)\n",
    "    T = compute_T_indices(sst)\n",
    "\n",
    "    ## compute h indices\n",
    "    ssh = load_member(\"ssh\", **kwargs)\n",
    "    h = compute_h_indices(ssh)\n",
    "\n",
    "    ## return data\n",
    "    return xr.merge([T, h])\n",
    "\n",
    "\n",
    "def spatial_avg(data):\n",
    "    \"\"\"get spatial average, weighting by cos of latitude\"\"\"\n",
    "\n",
    "    ## get weighted data\n",
    "    weights = np.cos(np.deg2rad(data.latitude))\n",
    "\n",
    "    return data.weighted(weights).mean([\"latitude\", \"longitude\"])\n",
    "\n",
    "\n",
    "def load_member_Th(sim, n):\n",
    "    \"\"\"Load T and h data for given simulation type and ensemble member\"\"\"\n",
    "\n",
    "    ## shared arguments\n",
    "    kwargs = dict(sim=sim, n=n)\n",
    "\n",
    "    ## load data\n",
    "    sst = load_member(\"ts\", **kwargs)\n",
    "    ssh = load_member(\"ssh\", **kwargs)\n",
    "\n",
    "    ## compute indices\n",
    "    return xr.merge([compute_T_indices(sst), compute_h_indices(ssh)])\n",
    "\n",
    "\n",
    "def compute_ensemble_Th(save_dir=DATA_FP / \"temp\"):\n",
    "    \"\"\"function to compute and save Th for each ensemble member\"\"\"\n",
    "\n",
    "    for sim in [\"historical\", \"ssp585\"]:\n",
    "        for n in tqdm.tqdm(range(1, 51, 1)):\n",
    "\n",
    "            ## get save filepath\n",
    "            save_fp = save_dir / f\"Th_{sim}_{n:02d}.nc\"\n",
    "\n",
    "            ## check if file exists\n",
    "            if save_fp.is_file():\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                ## compute indices for given member\n",
    "                Th_ = load_member_Th(sim=sim, n=n).compute()\n",
    "\n",
    "                ## save to file\n",
    "                Th_.to_netcdf(save_fp)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def load_member_spatial(name, n):\n",
    "    \"\"\"Load data for given variable and ensemble member\"\"\"\n",
    "\n",
    "    ## shared arguments\n",
    "    kwargs = dict(name=name, n=n)\n",
    "\n",
    "    ## load data\n",
    "    hist = load_member(sim=\"historical\", **kwargs)\n",
    "    ssp585 = load_member(sim=\"ssp585\", **kwargs)\n",
    "\n",
    "    ## update varname for sst\n",
    "    varname = \"sst\" if (name == \"ts\") else name\n",
    "\n",
    "    ## compute indices\n",
    "    return xr.concat([hist, ssp585], dim=\"time\")[varname]\n",
    "\n",
    "\n",
    "def load_ensemble_spatial(name, n_array=np.arange(1, 51)):\n",
    "    \"\"\"Load data for given variable and ensemble members\"\"\"\n",
    "\n",
    "    ## new dimension: ensemble member\n",
    "    member_dim = pd.Index(n_array, name=\"member\")\n",
    "\n",
    "    return xr.concat(\n",
    "        [load_member_spatial(name, n) for n in tqdm.tqdm(n_array)], dim=member_dim\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_ensemble_Th(load_dir, save_dir, sim):\n",
    "    \"\"\"merge files from individual ensemble members into one\"\"\"\n",
    "\n",
    "    ## get filepath for saving\n",
    "    save_fp = save_dir / f\"Th_{sim}.nc\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if save_fp.is_dir():\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Load data\n",
    "        Th = xr.open_mfdataset(\n",
    "            sorted(list(load_dir.glob(f\"*{sim}*.nc\"))),\n",
    "            combine=\"nested\",\n",
    "            concat_dim=\"member\",\n",
    "        )\n",
    "\n",
    "        ## assign values to member dimension\n",
    "        Th = Th.assign_coords({\"member\": pd.Index(np.arange(1, 51))})\n",
    "\n",
    "        ## remove encoding setting which prevents saving\n",
    "        for name in [\"sst_trop\", \"ts_glob\", \"ssh_trop\", \"ssh_glob\"]:\n",
    "            del Th[name].encoding[\"_FillValue\"]\n",
    "\n",
    "        ## save to file\n",
    "        Th.to_netcdf(save_fp)\n",
    "\n",
    "    return Th\n",
    "\n",
    "\n",
    "def preprocess(Th, save_dir=DATA_FP / \"mpi_Th\"):\n",
    "    \"\"\"preprocess T and h data\"\"\"\n",
    "\n",
    "    ## compute ensemble mean and anomalies\n",
    "    Th_emean = Th.mean(\"member\")\n",
    "    Th_anom = Th - Th_emean\n",
    "\n",
    "    ## define filepaths for saving\n",
    "    save_fp_emean = pathlib.Path(save_dir, \"Th_ensemble_mean.nc\")\n",
    "    save_fp_anom = pathlib.Path(save_dir, \"Th.nc\")\n",
    "\n",
    "    ## save to file if not already\n",
    "    if not save_fp_emean.is_file():\n",
    "        Th_emean.to_netcdf(save_fp_emean)\n",
    "\n",
    "    if not save_fp_anom.is_file():\n",
    "        Th_anom.to_netcdf(save_fp_anom)\n",
    "\n",
    "    return Th_emean, Th_anom\n",
    "\n",
    "\n",
    "class eof:\n",
    "    def __init__(self, data):\n",
    "\n",
    "        ## stack latitude and longitude into one dimension\n",
    "        data_stacked = data.stack(posn=[\"latitude\", \"longitude\"])\n",
    "\n",
    "        ## find nan values\n",
    "        nan_mask = np.isnan(data_stacked.isel(time=0))\n",
    "\n",
    "        ## filter out NaNs and compute SVD\n",
    "        data_nonan = data_stacked.isel(posn=~nan_mask.values)\n",
    "\n",
    "        ## compute SVD\n",
    "        self.u, self.s, self.vt = np.linalg.svd(data_nonan.values, full_matrices=False)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db226dc7-c922-4be3-b83b-cf3199e5cb93",
   "metadata": {},
   "source": [
    "## Compute $T$, $h$ variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382c4d4-519d-4e84-b0bb-903d06038bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get directory for saving temporary results\n",
    "temp_dir = DATA_FP / \"temp\"\n",
    "\n",
    "## compute T & h for each ensemble member\n",
    "compute_ensemble_Th(save_dir=temp_dir)\n",
    "\n",
    "## merge data into single ensemble\n",
    "kwargs = dict(load_dir=temp_dir, save_dir=DATA_FP / \"mpi_Th\")\n",
    "Th_hist = merge_ensemble_Th(sim=\"historical\", **kwargs)\n",
    "Th_ssp = merge_ensemble_Th(sim=\"ssp585\", **kwargs)\n",
    "\n",
    "## merge hist. and ssp simulations\n",
    "Th = xr.concat([Th_hist, Th_ssp], dim=\"time\")\n",
    "\n",
    "## preprocess\n",
    "Th_emean, Th = preprocess(Th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f4253-40c6-4177-bb05-200210a48c0d",
   "metadata": {},
   "source": [
    "### Look at output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331dc8ab-41fb-4c4d-a548-cf330c2930dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data into memory\n",
    "Th_emean.load()\n",
    "\n",
    "## function to deseason data\n",
    "deseason = lambda x: x.groupby(\"time.month\") - x.groupby(\"time.month\").mean()\n",
    "\n",
    "## remove seasonal cycle but add back time-mean\n",
    "Th_emean_deseasoned = deseason(Th_emean) + Th_emean.mean(\"time\")\n",
    "\n",
    "## set up plot\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6, 4.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "axs[0].plot(Th_emean.time, Th_emean[\"T_3\"], lw=2, c=\"k\", label=\"Ens. mean\")\n",
    "axs[0].plot(\n",
    "    Th_emean.time,\n",
    "    Th_emean_deseasoned[\"T_3\"],\n",
    "    lw=2,\n",
    "    c=\"r\",\n",
    "    label=\"Ens. mean (de-seasoned)\",\n",
    ")\n",
    "\n",
    "## label\n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"Niño 3 (Hist. & SSP585)\")\n",
    "axs[0].set_ylabel(r\"$^{\\circ}C$\")\n",
    "\n",
    "## plot 5 ensemble members\n",
    "for i in range(1, 6):\n",
    "    axs[1].plot(Th.time, Th[\"T_3\"].sel(member=i), lw=1, c=\"k\", alpha=0.5)\n",
    "\n",
    "axs[1].set_title(\"Internal variability (5 ensemble members)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb515825-a6ca-4dd1-be1b-a8b05ab52a78",
   "metadata": {},
   "source": [
    "## Data compression with EOFs (**to-do**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad2458-4372-484d-9d1e-72f8f64f9e5c",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Compute spatial patterns\n",
    "2. Compress data\n",
    "3. Check compression (compare recon of random ensemble to actual)\n",
    "4. Remove ensemble mean (external forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2934994-1ed5-4ba6-80f2-0cfa294f280d",
   "metadata": {},
   "source": [
    "### Function to compute/save/load EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d309a-c2d0-4ca9-9313-c63f9b161287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eofs(eofs_fp, varname, **eofs_kwargs):\n",
    "\n",
    "    ## get filename\n",
    "    filename = eofs_fp / f\"{varname}.nc\"\n",
    "\n",
    "    ## initialize EOF model\n",
    "    eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "    ## Load pre-computed model if it exists\n",
    "    if pathlib.Path(filename).is_file():\n",
    "        eofs = eofs.load(filename, engine=\"netcdf4\")\n",
    "\n",
    "    else:\n",
    "        ## load data\n",
    "        data = load_ensemble_spatial(name=name, n_array=np.arange(1, 3)).isel(\n",
    "            time=slice(None, 230)\n",
    "        )\n",
    "\n",
    "        ## fit model\n",
    "        eofs.fit(data, dim=[\"time\", \"member\"])\n",
    "\n",
    "        ## save to file\n",
    "        eofs.save(filename, engine=\"netcdf4\")\n",
    "\n",
    "    return eofs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6161d1-80f9-4ab6-9ee1-8897393395c2",
   "metadata": {},
   "source": [
    "### Do the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dfaea-6ddf-4dad-9fb8-d57dc4efb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save filepaths for saving EOF results\n",
    "eofs_fp = DATA_FP / \"mpi\" / \"eofs\"\n",
    "\n",
    "## specify EOF specs\n",
    "eofs_kwargs = dict(n_modes=150, standardize=False, use_coslat=True, center=False)\n",
    "\n",
    "print(\"Computing EOFs for SST...\")\n",
    "t0 = time.time()\n",
    "eofs_sst = load_eofs(eofs_fp, \"ts\", **eofs_kwargs)\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(tf-t0)/60:.1f} minutes\\n\")\n",
    "\n",
    "print(\"Computing EOFs for SSH...\")\n",
    "t0 = time.time()\n",
    "eofs_ssh = load_eofs(eofs_fp, \"ssh\", **eofs_kwargs)\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(tf-t0)/60:.1f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
