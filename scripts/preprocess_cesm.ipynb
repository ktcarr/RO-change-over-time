{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287d082a-1ad3-4544-b5d8-25ad7a9da4e9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a29b8-4a30-45c8-99c2-7822bb9738b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import xeofs as xe\n",
    "import time\n",
    "import src.utils\n",
    "\n",
    "## specify filepath for data\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI for presentation\n",
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ee97b-5871-40d3-b923-bbf84af00c1a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23d1ad-616f-4b0d-9a45-d97095655d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(varname):\n",
    "    \"\"\"get files for given variable name\"\"\"\n",
    "    mmlea_fp = pathlib.Path(\"/glade/campaign/collections/rda/data/d651039\")\n",
    "    cesm2_fp = mmlea_fp / pathlib.Path(\"cesm2_lens/Omon\")\n",
    "\n",
    "    return sorted((cesm2_fp / varname).glob(\"*.nc\"))\n",
    "\n",
    "\n",
    "def check_member_file(i):\n",
    "    \"\"\"check zos and tos files match for given member idx\"\"\"\n",
    "    return str(get_files(\"tos\")[i])[-71:] == str(get_files(\"zos\")[i])[-71:]\n",
    "\n",
    "\n",
    "def check_member_files():\n",
    "    \"\"\"check all files match\"\"\"\n",
    "\n",
    "    checks = np.array([check_member_file(i) for i in range(100)])\n",
    "    return np.all(checks)\n",
    "\n",
    "\n",
    "def load_member_varname(member_idx, varname):\n",
    "    \"\"\"load ensemble member. Args:\n",
    "    - member_idx: integer in [0,99]\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get list of files\n",
    "    files = get_files(varname)\n",
    "\n",
    "    ## open data\n",
    "    data = xr.open_dataset(files[member_idx])\n",
    "\n",
    "    ## remove un-needed coords\n",
    "    data = data[varname].squeeze(drop=True)\n",
    "\n",
    "    ## rename lon/lat\n",
    "    data = data.rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_member_Th(member_idx):\n",
    "    \"\"\"Load T and h data for given member index\"\"\"\n",
    "\n",
    "    ## compute indices\n",
    "    T_idxs = src.utils.get_RO_T_indices(load_member_varname(member_idx, \"tos\"))\n",
    "    h_idxs = src.utils.get_RO_h_indices(load_member_varname(member_idx, \"zos\"))\n",
    "\n",
    "    ## compute indices\n",
    "    return xr.merge([T_idxs, h_idxs])\n",
    "\n",
    "\n",
    "def load_ensemble_Th(save_fp):\n",
    "    \"\"\"Load all ensemble members\"\"\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if save_fp.is_file():\n",
    "\n",
    "        data = xr.open_dataset(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## new dimension: ensemble member\n",
    "        member_dim = pd.Index(np.arange(100), name=\"member\")\n",
    "\n",
    "        ## do computation\n",
    "        data = xr.concat(\n",
    "            [load_member_Th(i) for i in tqdm.tqdm(member_dim)],\n",
    "            dim=member_dim,\n",
    "        )\n",
    "\n",
    "        ## save to file\n",
    "        data.to_netcdf(save_fp)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_Th(Th, save_dir):\n",
    "    \"\"\"pre-process Th data (compute ensemble mean and anomalies\"\"\"\n",
    "\n",
    "    ## define filepaths for saving\n",
    "    save_fp_emean = pathlib.Path(save_dir, \"Th_emean.nc\")\n",
    "    save_fp_anom = pathlib.Path(save_dir, \"Th_anom.nc\")\n",
    "\n",
    "    ## compute ensemble mean and anomalies\n",
    "    Th_emean = Th.mean(\"member\")\n",
    "    Th_anom = Th - Th_emean\n",
    "\n",
    "    ## save to file if not already\n",
    "    if not save_fp_emean.is_file():\n",
    "        Th_emean.to_netcdf(save_fp_emean)\n",
    "\n",
    "    if not save_fp_anom.is_file():\n",
    "        Th_anom.to_netcdf(save_fp_anom)\n",
    "\n",
    "    return Th_emean, Th_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ccc04f-88a3-4dbd-8f9f-b60e7969da3b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754e570-3e6e-49bb-92e7-562f82190cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save file paths\n",
    "save_dir = DATA_FP / \"cesm\"\n",
    "\n",
    "## load data\n",
    "Th = load_ensemble_Th(save_dir / \"Th.nc\")\n",
    "\n",
    "## compute ensemble stats/anomalies\n",
    "Th_emean, Th_anom = preprocess_Th(Th, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c78cf-6d75-4f5f-b813-baf7c4dbab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_member_spatial(name, n):\n",
    "    \"\"\"Load data for given variable and ensemble member\"\"\"\n",
    "\n",
    "    ## shared arguments\n",
    "    kwargs = dict(name=name, n=n)\n",
    "\n",
    "    ## load data\n",
    "    hist = load_member(sim=\"historical\", **kwargs)\n",
    "    ssp585 = load_member(sim=\"ssp585\", **kwargs)\n",
    "\n",
    "    ## update varname for sst\n",
    "    varname = \"sst\" if (name == \"ts\") else name\n",
    "\n",
    "    ## compute indices\n",
    "    return xr.concat([hist, ssp585], dim=\"time\")[varname]\n",
    "\n",
    "\n",
    "def load_ensemble_spatial(name, n_array=np.arange(1, 51)):\n",
    "    \"\"\"Load data for given variable and ensemble members\"\"\"\n",
    "\n",
    "    ## new dimension: ensemble member\n",
    "    member_dim = pd.Index(n_array, name=\"member\")\n",
    "\n",
    "    return xr.concat(\n",
    "        [load_member_spatial(name, n).compute() for n in tqdm.tqdm(n_array)],\n",
    "        dim=member_dim,\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_ensemble_Th(load_dir, save_dir, sim):\n",
    "    \"\"\"merge files from individual ensemble members into one\"\"\"\n",
    "\n",
    "    ## get filepath for saving\n",
    "    save_fp = save_dir / f\"Th_{sim}.nc\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if save_fp.is_dir():\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Load data\n",
    "        Th = xr.open_mfdataset(\n",
    "            sorted(list(load_dir.glob(f\"*{sim}*.nc\"))),\n",
    "            combine=\"nested\",\n",
    "            concat_dim=\"member\",\n",
    "        )\n",
    "\n",
    "        ## assign values to member dimension\n",
    "        Th = Th.assign_coords({\"member\": pd.Index(np.arange(1, 51))})\n",
    "\n",
    "        ## remove encoding setting which prevents saving\n",
    "        for name in [\"sst_trop\", \"ts_glob\", \"ssh_trop\", \"ssh_glob\"]:\n",
    "            del Th[name].encoding[\"_FillValue\"]\n",
    "\n",
    "        ## save to file\n",
    "        Th.to_netcdf(save_fp)\n",
    "\n",
    "    return Th\n",
    "\n",
    "\n",
    "def preprocess(Th, save_dir=DATA_FP / \"mpi_Th\"):\n",
    "    \"\"\"preprocess T and h data\"\"\"\n",
    "\n",
    "    ## compute ensemble mean and anomalies\n",
    "    Th_emean = Th.mean(\"member\")\n",
    "    Th_anom = Th - Th_emean\n",
    "\n",
    "    ## define filepaths for saving\n",
    "    save_fp_emean = pathlib.Path(save_dir, \"Th_ensemble_mean.nc\")\n",
    "    save_fp_anom = pathlib.Path(save_dir, \"Th.nc\")\n",
    "\n",
    "    ## save to file if not already\n",
    "    if not save_fp_emean.is_file():\n",
    "        Th_emean.to_netcdf(save_fp_emean)\n",
    "\n",
    "    if not save_fp_anom.is_file():\n",
    "        Th_anom.to_netcdf(save_fp_anom)\n",
    "\n",
    "    return Th_emean, Th_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db226dc7-c922-4be3-b83b-cf3199e5cb93",
   "metadata": {},
   "source": [
    "## Compute $T$, $h$ variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382c4d4-519d-4e84-b0bb-903d06038bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get directory for saving temporary results\n",
    "temp_dir = DATA_FP / \"temp\"\n",
    "\n",
    "## compute T & h for each ensemble member\n",
    "compute_ensemble_Th(save_dir=temp_dir)\n",
    "\n",
    "## merge data into single ensemble\n",
    "kwargs = dict(load_dir=temp_dir, save_dir=DATA_FP / \"mpi_Th\")\n",
    "Th_hist = merge_ensemble_Th(sim=\"historical\", **kwargs)\n",
    "Th_ssp = merge_ensemble_Th(sim=\"ssp585\", **kwargs)\n",
    "\n",
    "## merge hist. and ssp simulations\n",
    "Th = xr.concat([Th_hist, Th_ssp], dim=\"time\")\n",
    "\n",
    "## preprocess\n",
    "Th_emean, Th = preprocess(Th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f4253-40c6-4177-bb05-200210a48c0d",
   "metadata": {},
   "source": [
    "### Look at output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331dc8ab-41fb-4c4d-a548-cf330c2930dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data into memory\n",
    "Th_emean.load()\n",
    "\n",
    "## function to deseason data\n",
    "deseason = lambda x: x.groupby(\"time.month\") - x.groupby(\"time.month\").mean()\n",
    "\n",
    "## remove seasonal cycle but add back time-mean\n",
    "Th_emean_deseasoned = deseason(Th_emean) + Th_emean.mean(\"time\")\n",
    "\n",
    "## set up plot\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6, 4.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "axs[0].plot(Th_emean.time, Th_emean[\"T_3\"], lw=2, c=\"k\", label=\"Ens. mean\")\n",
    "axs[0].plot(\n",
    "    Th_emean.time,\n",
    "    Th_emean_deseasoned[\"T_3\"],\n",
    "    lw=2,\n",
    "    c=\"r\",\n",
    "    label=\"Ens. mean (de-seasoned)\",\n",
    ")\n",
    "\n",
    "## label\n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"Niño 3 (Hist. & SSP585)\")\n",
    "axs[0].set_ylabel(r\"$^{\\circ}C$\")\n",
    "\n",
    "## plot 5 ensemble members\n",
    "for i in range(1, 6):\n",
    "    axs[1].plot(Th.time, Th[\"T_3\"].sel(member=i), lw=1, c=\"k\", alpha=0.5)\n",
    "\n",
    "axs[1].set_title(\"Internal variability (5 ensemble members)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb515825-a6ca-4dd1-be1b-a8b05ab52a78",
   "metadata": {},
   "source": [
    "## Data compression with EOFs (**to-do**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad2458-4372-484d-9d1e-72f8f64f9e5c",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Compute spatial patterns\n",
    "2. Compress data\n",
    "3. Check compression (compare recon of random ensemble to actual)\n",
    "4. Remove ensemble mean (external forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2934994-1ed5-4ba6-80f2-0cfa294f280d",
   "metadata": {},
   "source": [
    "### Function to compute/save/load EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d309a-c2d0-4ca9-9313-c63f9b161287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eofs(eofs_fp, varname, **eofs_kwargs):\n",
    "\n",
    "    ## get filename\n",
    "    filename = eofs_fp / f\"{varname}.nc\"\n",
    "\n",
    "    ## initialize EOF model\n",
    "    eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "    ## Load pre-computed model if it exists\n",
    "    if pathlib.Path(filename).is_file():\n",
    "        eofs = eofs.load(filename, engine=\"netcdf4\")\n",
    "\n",
    "    else:\n",
    "        ## load data\n",
    "        data = load_ensemble_spatial(name=varname, n_array=np.arange(1, 51))\n",
    "\n",
    "        ## fit model\n",
    "        eofs.fit(data, dim=[\"time\", \"member\"])\n",
    "\n",
    "        ## save to file\n",
    "        eofs.save(filename, engine=\"netcdf4\")\n",
    "\n",
    "    return eofs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6161d1-80f9-4ab6-9ee1-8897393395c2",
   "metadata": {},
   "source": [
    "### Do the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dfaea-6ddf-4dad-9fb8-d57dc4efb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save filepaths for saving EOF results\n",
    "eofs_fp = DATA_FP / \"mpi\" / \"eofs300\"\n",
    "\n",
    "## specify EOF specs\n",
    "eofs_kwargs = dict(n_modes=300, standardize=False, use_coslat=True, center=False)\n",
    "\n",
    "print(\"Computing EOFs for SST...\")\n",
    "t0 = time.time()\n",
    "eofs_sst = load_eofs(eofs_fp, \"ts\", **eofs_kwargs)\n",
    "tf = time.time()\n",
    "print(f\"Elapsed time: {(tf-t0)/60:.1f} minutes\\n\")\n",
    "\n",
    "print(\"Computing EOFs for SSH...\")\n",
    "t0 = time.time()\n",
    "eofs_ssh = load_eofs(eofs_fp, \"ssh\", **eofs_kwargs)\n",
    "tf = time.time()\n",
    "print(f\"Elapsed time: {(tf-t0)/60:.1f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
