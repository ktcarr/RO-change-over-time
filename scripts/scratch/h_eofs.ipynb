{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597e1a27-e24f-4652-810f-2e88f33276d0",
   "metadata": {},
   "source": [
    "# RO reference\n",
    "Fit RO on observations to get \"ground truth\" behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7fa21-6df5-4876-925c-a3cb75e71a54",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ac922-8f5c-4019-9893-e5a8bcf434f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import copy\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pathlib\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats\n",
    "import xeofs as xe\n",
    "import src.lim\n",
    "\n",
    "# Import custom modules\n",
    "import src.XRO\n",
    "import src.XRO_utils\n",
    "import src.utils\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "SAVE_FP = pathlib.Path(os.environ[\"SAVE_FP\"])\n",
    "\n",
    "## get RNG\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62138e3-f1a9-4c9d-9536-e0290c8b6abd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75abc3-d092-4d6d-b226-9622af9f2618",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify filepaths\n",
    "oras_fp = DATA_FP / \"oras5\"\n",
    "\n",
    "## load data\n",
    "data = src.utils.load_oras_spatial_extended(oras_fp, varnames=[\"tos\", \"d20\"])\n",
    "\n",
    "## compute indices\n",
    "idx_total = src.utils.get_RO_indices(data, h_var=\"d20\")\n",
    "\n",
    "## compute \"wide\" hbar\n",
    "idx_total[\"h_\"] = src.utils.spatial_avg(\n",
    "    data[\"d20\"].sel(longitude=slice(120, 280), latitude=slice(-15, 15))\n",
    ")\n",
    "idx_total[\"h__\"] = src.utils.spatial_avg(\n",
    "    data[\"d20\"].sel(longitude=slice(120, 210), latitude=slice(-15, 15))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d5539-8130-4f46-bd98-bc5b2d09aea8",
   "metadata": {},
   "source": [
    "## Detrend / pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87f13e-28be-47fd-9bd6-7b303ee92e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimate forced signal by removing 2nd-order polynomial from each calendar month\n",
    "detrend_fn = lambda x: src.utils.detrend_dim(x, dim=\"time\", deg=3)\n",
    "idx = idx_total.groupby(\"time.month\").map(detrend_fn)\n",
    "idx_forced = idx_total - idx\n",
    "\n",
    "## standardize for convenience\n",
    "idx /= idx.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd5635-cd60-4f5d-b57a-8a0e42c073e5",
   "metadata": {},
   "source": [
    "## Cross correlation stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a765ef-b10b-48a6-bdcc-edfdf0320fb1",
   "metadata": {},
   "source": [
    "Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba43a6-f0ea-4835-9069-02e1c52f9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_xcorr_ax(ax):\n",
    "    \"\"\"make xcorr plot look nice\"\"\"\n",
    "\n",
    "    axis_kwargs = dict(c=\"k\", lw=0.5, alpha=0.5)\n",
    "    ax.axhline(0, **axis_kwargs)\n",
    "    ax.axvline(0, **axis_kwargs)\n",
    "    ax.set_ylim([-0.9, 1.1])\n",
    "    ax.set_xlabel(\"Lag (years)\")\n",
    "    ax.set_xticks([-24, -12, 0, 12, 24], labels=[-2, -1, 0, 1, 2])\n",
    "    ax.set_yticks([-0.5, 0, 0.5, 1])\n",
    "    ax.set_ylabel(\"Correlation\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f66150-10ec-4af0-8d55-0f3f483a9412",
   "metadata": {},
   "source": [
    "Make the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3864f-ffd9-46e8-8ce9-9702fea10f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute cross-corr\n",
    "xcorr = src.XRO.xcorr(idx, idx[\"T_3\"], maxlags=36)\n",
    "\n",
    "## plot result\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "\n",
    "## plot data\n",
    "ax.plot(xcorr.lag, xcorr[\"T_3\"], label=r\"$T_3$\", c=\"k\")\n",
    "ax.plot(xcorr.lag, xcorr[\"T_34\"], label=r\"$T_{3.4}$\", c=\"k\", ls=\"--\")\n",
    "ax.plot(xcorr.lag, xcorr[\"h\"], label=r\"$h$\")\n",
    "ax.plot(xcorr.lag, xcorr[\"h_w\"], label=r\"$h_w$\")\n",
    "ax.plot(xcorr.lag, xcorr[\"h_\"], label=r\"$h_{wide}$\")\n",
    "\n",
    "## format plot\n",
    "ax.set_title(\"Corr. with Niño 3\")\n",
    "ax.legend()\n",
    "format_xcorr_ax(ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93348d38-4b72-4629-9de9-527ecd090d63",
   "metadata": {},
   "source": [
    "## Fit RO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7f537-f562-47e9-bb2c-eecaed29821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify order of annual cycle, mask parameters\n",
    "ac_order = 3\n",
    "ac_mask_idx = [(1, 1)]  # epsilon\n",
    "# ac_mask_idx = [(1,0), (1, 1)] # epsilon and F2\n",
    "# ac_mask_idx = [(0,1),(1,0),(1, 1)] # all except R\n",
    "# ac_mask_idx = None\n",
    "\n",
    "## initialize model\n",
    "model = src.XRO.XRO(ncycle=12, ac_order=ac_order, is_forward=True)\n",
    "\n",
    "## get fit for reanalysis\n",
    "fit_h = model.fit_matrix(idx[[\"T_34\", \"h\"]], ac_mask_idx=ac_mask_idx)\n",
    "fit_hw = model.fit_matrix(idx[[\"T_34\", \"h_\"]], ac_mask_idx=ac_mask_idx)\n",
    "\n",
    "## extract params\n",
    "p_h = model.get_RO_parameters(fit_h)\n",
    "p_hw = model.get_RO_parameters(fit_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa096f-e3bc-4a2b-a607-5722b4b15a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4.5, 2), layout=\"constrained\")\n",
    "\n",
    "for i, (ax, n) in enumerate(zip(axs, [\"R\", \"BJ_ac\"])):\n",
    "    ax.plot(p_h.cycle, p_h[n], label=r\"$h$\")\n",
    "    ax.plot(p_hw.cycle, p_hw[n], label=r\"$h_w$\")\n",
    "\n",
    "    ## format\n",
    "    ax.axhline(0, ls=\"-\", c=\"k\", lw=0.5)\n",
    "    ax.set_xticks([1, 7, 12], labels=[\"Jan\", \"Jul\", \"Dec\"])\n",
    "\n",
    "## plot epsilon values as well\n",
    "kwargs = dict(lw=1, ls=\"--\")\n",
    "axs[0].plot(p_h.cycle, p_h[\"epsilon\"], c=sns.color_palette()[0], **kwargs)\n",
    "axs[0].plot(p_h.cycle, p_hw[\"epsilon\"], c=sns.color_palette()[1], **kwargs)\n",
    "\n",
    "## label\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([-4, -2, 0, 2])\n",
    "axs[0].set_title(r\"$R$\")\n",
    "axs[1].set_title(r\"$2\\left(R-\\varepsilon\\right)$\")\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "axs[0].set_ylim([-6, 3])\n",
    "axs[1].set_ylim(0.5 * np.array(axs[0].get_ylim()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156b1e5-b570-4c78-9f1f-214b23b87c44",
   "metadata": {},
   "source": [
    "## check stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d21b52-ed30-43e3-9bdc-1618c7584ad5",
   "metadata": {},
   "source": [
    "Generate simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffbfc6-6c9c-44e2-bfd0-d04c0ed4ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify random IC\n",
    "x0 = idx.isel(time=rng.choice(np.arange(len(idx.time))))\n",
    "\n",
    "## simulation specs\n",
    "simulation_kwargs = dict(\n",
    "    nyear=63,\n",
    "    ncopy=1000,\n",
    "    is_xi_stdac=False,\n",
    ")\n",
    "\n",
    "## do simulations\n",
    "kwargs_h = dict(simulation_kwargs, fit_ds=fit_h, X0_ds=x0[[\"T_34\", \"h\"]])\n",
    "X_h = model.simulate(**kwargs_h)\n",
    "\n",
    "kwargs_hw = dict(simulation_kwargs, fit_ds=fit_hw, X0_ds=x0[[\"T_34\", \"h_\"]])\n",
    "X_hw = model.simulate(**kwargs_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd976eb-e15e-4920-be35-ebc23d8f1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(4.5, 2), layout=\"constrained\")\n",
    "\n",
    "## plot RO with h (early period)\n",
    "plot_data_early = src.utils.plot_seasonal_comp(\n",
    "    axs[0],\n",
    "    x0=idx.expand_dims(\"member\"),\n",
    "    x1=X_h,\n",
    "    plot_kwargs0=dict(label=\"ORAS\"),\n",
    "    plot_kwargs1=dict(label=\"RO\"),\n",
    "    varname=\"T_34\",\n",
    "    use_quantile=True,\n",
    ")\n",
    "\n",
    "## plot RO with h (early period)\n",
    "plot_data_early = src.utils.plot_seasonal_comp(\n",
    "    axs[1],\n",
    "    x0=idx.expand_dims(\"member\"),\n",
    "    x1=X_hw,\n",
    "    plot_kwargs0=dict(label=\"ORAS\"),\n",
    "    plot_kwargs1=dict(label=\"RO\"),\n",
    "    varname=\"T_34\",\n",
    "    use_quantile=True,\n",
    ")\n",
    "\n",
    "axs[1].legend(prop=dict(size=8))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim([0, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641e1e9-e41a-49fe-8de7-5ae7176a950b",
   "metadata": {},
   "source": [
    "## Compute $R$ explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec4d19-ec4c-494c-9dd6-e3de371998c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute gradients\n",
    "grads = src.XRO.gradient(src.XRO._convert_to_numpy(idx))\n",
    "\n",
    "## add to array\n",
    "for i, n in enumerate(list(idx)):\n",
    "    idx.update({f\"{n}_grad\": xr.DataArray(grads[i], coords=dict(time=idx.time))})\n",
    "\n",
    "\n",
    "def get_stats(T_var, h_var, month):\n",
    "    \"\"\"Get statistics needed to compute R\"\"\"\n",
    "\n",
    "    ## indexer\n",
    "    t_idx = dict(time=idx.time.dt.month == month)\n",
    "\n",
    "    ## get subset of array\n",
    "    sel_vars = [T_var, h_var, f\"{T_var}_grad\", f\"{h_var}_grad\"]\n",
    "    names = {\n",
    "        T_var: \"T\",\n",
    "        h_var: \"h\",\n",
    "        f\"{T_var}_grad\": \"T_grad\",\n",
    "        f\"{h_var}_grad\": \"h_grad\",\n",
    "    }\n",
    "    X = idx.isel(t_idx)[sel_vars].rename(names)\n",
    "\n",
    "    ## compute stats\n",
    "    sigma_T = np.std(X[\"T\"].values)\n",
    "    sigma_h = np.std(X[\"h\"].values)\n",
    "    r = scipy.stats.pearsonr(X[\"T\"].values, X[\"h\"].values)[0]\n",
    "\n",
    "    ## compute covariance\n",
    "    TtT = np.mean(X[\"T_grad\"] * X[\"T\"]).values.item() * np.pow(sigma_T, -2)\n",
    "    Tth = (\n",
    "        np.mean(X[\"T_grad\"] * X[\"h\"]).values.item()\n",
    "        * np.pow(sigma_T, -1)\n",
    "        * np.pow(sigma_h, -1)\n",
    "    )\n",
    "\n",
    "    return dict(r=r, TtT=TtT, Tth=Tth)\n",
    "\n",
    "\n",
    "def get_R(T_var, h_var, month):\n",
    "    \"\"\"function to compute estimate of R for given variables and month\"\"\"\n",
    "\n",
    "    ## compute stats\n",
    "    stats = get_stats(T_var=T_var, h_var=h_var, month=month)\n",
    "    r = stats[\"r\"]\n",
    "    TtT = stats[\"TtT\"]\n",
    "    Tth = stats[\"Tth\"]\n",
    "\n",
    "    ## compute estimate for R\n",
    "    Rhat = 1 / (1 - r**2) * (TtT - r * Tth)\n",
    "\n",
    "    return Rhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a0090-d169-46d7-ad6a-a1aeeca587bc",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    R &= \\frac{\\sigma_T^{-1}}{1-r^2}\\left[\\left<T_t,\\tilde{T}\\right> - r\\left<T_t,\\tilde{h}\\right>\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc41ed-2d02-44fa-a6b5-e36532888cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### compute\n",
    "## kwargs\n",
    "kwargs_h = dict(T_var=\"T_34\", h_var=\"h\")\n",
    "kwargs_hw = dict(T_var=\"T_34\", h_var=\"h_\")\n",
    "\n",
    "## compute estimates\n",
    "Rhats_h = np.array([get_R(month=m, **kwargs_h) for m in np.arange(1, 13)])\n",
    "Rhats_hw = np.array([get_R(month=m, **kwargs_hw) for m in np.arange(1, 13)])\n",
    "\n",
    "\n",
    "#### plot\n",
    "colors = sns.color_palette()\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "## plot first version\n",
    "ax.plot(p_h.cycle, Rhats_h, c=colors[0], ls=\"--\")\n",
    "ax.plot(p_h.cycle, p_h[\"R\"], c=colors[0], label=r\"$h$\")\n",
    "\n",
    "## plot second version\n",
    "ax.plot(p_h.cycle, Rhats_hw, c=colors[1], ls=\"--\")\n",
    "ax.plot(p_h.cycle, p_hw[\"R\"], c=colors[1], label=r\"$h_w$\")\n",
    "\n",
    "## label\n",
    "ax.legend(prop=dict(size=8))\n",
    "ax.axhline(0, lw=1, c=\"k\", zorder=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530b6af-d4fc-4396-ade5-32a62b517f3f",
   "metadata": {},
   "source": [
    "## Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f0b08-821f-407a-b9b0-7916827db6bd",
   "metadata": {},
   "source": [
    "Look at relationship between $T_e$ and $\\overline{h}-h_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca30886-b6ac-4169-8c23-64ff13fe8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "t_idx = dict(time=idx.time.dt.month == m)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.scatter(\n",
    "    # idx[\"h\"].isel(t_idx) - idx[\"h_w\"].isel(t_idx),\n",
    "    # idx[\"T_3\"].isel(t_idx),\n",
    "    idx[\"T_34\"].isel(t_idx),\n",
    "    # idx[\"h_\"].isel(t_idx),# - idx[\"h\"].isel(t_idx),\n",
    "    idx[\"h\"].isel(t_idx),\n",
    "    # idx[\"h_\"].isel(t_idx), idx[\"h\"].isel(t_idx)\n",
    ")\n",
    "\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(r\"$\\overline{h}_{wide} - \\overline{h}$\")\n",
    "ax.set_xlabel(r\"$T_e$\")\n",
    "kwargs = dict(c=\"k\", lw=0.8, zorder=0.5)\n",
    "ax.axvline(0, **kwargs)\n",
    "ax.axhline(0, **kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b48b2-908e-456f-9070-6311dd014759",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 11\n",
    "t_idx = dict(time=idx.time.dt.month == m)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axs[0].scatter(\n",
    "    idx[\"T_3\"].isel(t_idx),\n",
    "    idx[\"h\"].isel(t_idx) - idx[\"h_w\"].isel(t_idx),\n",
    ")\n",
    "\n",
    "axs[1].scatter(\n",
    "    idx[\"T_3\"].isel(t_idx),\n",
    "    idx[\"h_\"].isel(t_idx) - idx[\"h_w\"].isel(t_idx),\n",
    ")\n",
    "\n",
    "\n",
    "## label\n",
    "axs[0].set_ylabel(r\"$\\Delta h$\")\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_title(r\"$\\overline{h}-h_w$\")\n",
    "axs[1].set_title(r\"$\\overline{h}_{wide}-h_w$\")\n",
    "kwargs = dict(c=\"k\", lw=0.8, zorder=0.5)\n",
    "axs[1].set_ylim(axs[0].get_ylim())\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axvline(0, **kwargs)\n",
    "    ax.axhline(0, **kwargs)\n",
    "    ax.set_xlabel(r\"$T_e$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0edf94-8f8c-4aaf-be44-a8052c28073e",
   "metadata": {},
   "source": [
    "## Compute EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7235521-3d85-4c52-894a-4281ff88fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sst_dependence(ds, sst_idx, remove_from_sst=False):\n",
    "    \"\"\"function to remove linear dependence of variables on SST\"\"\"\n",
    "\n",
    "    ## get h-variables and T-variables\n",
    "    if remove_from_sst:\n",
    "        h_vars = list(ds)\n",
    "        T_vars = []\n",
    "    else:\n",
    "        h_vars = [n for n in list(ds) if (\"h\" in n) or (\"d20\" in n)]\n",
    "        T_vars = list(set(list(ds)) - set(h_vars))\n",
    "\n",
    "    ## create array to hold results\n",
    "    ds_hat = copy.deepcopy(ds[h_vars])\n",
    "\n",
    "    ## add SST index to array\n",
    "    ds_hat = ds_hat.assign_coords(dict(sst_idx=(\"time\", sst_idx.data)))\n",
    "\n",
    "    ## function to remove linear dependence\n",
    "    fn = lambda x: src.utils.detrend_dim(x, deg=1, dim=\"sst_idx\")\n",
    "\n",
    "    ## remove linear dependence for each month separately\n",
    "    ds_hat = ds_hat.groupby(\"time.month\").map(fn)\n",
    "\n",
    "    ## drop sst index as dim and add as variable\n",
    "    ds_hat = ds_hat.drop_vars(\"sst_idx\")\n",
    "\n",
    "    ## merge with T-data\n",
    "    ds_hat = xr.merge([ds_hat, ds[T_vars]])\n",
    "\n",
    "    return ds_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d306c-e73b-4a38-b301-3c1e1426d01e",
   "metadata": {},
   "source": [
    "get detrended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e90ebc-1478-4aab-ba0a-f1fdf17c85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddt(ds):\n",
    "    \"\"\"compute time derivative for each variable in dataset\"\"\"\n",
    "\n",
    "    ## transpose so time is last dimension\n",
    "    ds = ds.transpose(..., \"time\")\n",
    "\n",
    "    ## loop through variables\n",
    "    for n in list(ds):\n",
    "\n",
    "        ## create empty variable and fill with gradient\n",
    "        ds[f\"ddt_{n}\"] = xr.zeros_like(ds[n])\n",
    "        ds[f\"ddt_{n}\"].values = src.XRO.gradient(ds[n].values)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbd103-5f58-4a45-9fb1-d9d4c5335bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get subset of data\n",
    "data_ = data[[\"sst\", \"d20\"]].groupby(\"time.month\").map(detrend_fn)\n",
    "data_ = data_.sel(longitude=slice(120, 280))\n",
    "\n",
    "## get version with no Niño 3.4 dependence\n",
    "data_hat = remove_sst_dependence(data_, idx[\"T_34\"])\n",
    "idx_hat = remove_sst_dependence(idx, idx[\"T_34\"])\n",
    "\n",
    "## compute gradients\n",
    "data_ = get_ddt(data_)\n",
    "data_hat = get_ddt(data_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ec194-7789-401c-a1fc-04b3f755ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify time index for EOFs\n",
    "t_idx = dict(time=slice(None, None, None))\n",
    "\n",
    "## specify latitude range for EOFs\n",
    "lat_idx = dict(latitude=slice(-5, 5))\n",
    "\n",
    "## define subsetting operator\n",
    "subset = lambda x: x.isel(t_idx).sel(lat_idx)\n",
    "\n",
    "## fit EOFs\n",
    "model_d20 = xe.single.EOF(use_coslat=True, n_modes=10)\n",
    "model_d20.fit(subset(data_[\"d20\"]), dim=\"time\")\n",
    "\n",
    "model_sst = xe.single.EOF(use_coslat=True, n_modes=10)\n",
    "model_sst.fit(subset(data_[\"sst\"]), dim=\"time\")\n",
    "\n",
    "## get weights for each mode\n",
    "s = np.sqrt(model_d20.explained_variance())\n",
    "\n",
    "## get patterns\n",
    "patterns = model_d20.components() * s\n",
    "\n",
    "## plot leading modes\n",
    "fig = plt.figure(figsize=(8, 2.5), layout=\"constrained\")\n",
    "axs = src.utils.subplots_with_proj(\n",
    "    fig, nrows=2, ncols=1, format_func=src.utils.plot_setup_pac\n",
    ")\n",
    "\n",
    "## shared arguments for plotting\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    levels=src.utils.make_cb_range(16, 2),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cp = axs[0, 0].contourf(\n",
    "    patterns.longitude,\n",
    "    patterns.latitude,\n",
    "    patterns.isel(mode=0),\n",
    "    **kwargs,\n",
    ")\n",
    "cb = fig.colorbar(cp)\n",
    "\n",
    "cp = axs[1, 0].contourf(\n",
    "    patterns.longitude,\n",
    "    patterns.latitude,\n",
    "    patterns.isel(mode=1),\n",
    "    **kwargs,\n",
    ")\n",
    "kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_extent([120, 280, -20, 20], crs=ccrs.PlateCarree())\n",
    "    ax.axhline(-5, **kwargs)\n",
    "    ax.axhline(5, **kwargs)\n",
    "\n",
    "cb = fig.colorbar(cp)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97d09f-a9cb-428f-a837-0d5091a4bdb9",
   "metadata": {},
   "source": [
    "## Look at regression with Niño 3.4 index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c652763-adf1-4003-a2c7-a3ddaea28651",
   "metadata": {},
   "source": [
    "Create hovmollers of this by season?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e59c4-d58f-4880-ae10-32688adda166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### specify regression to plot\n",
    "use_hat = True\n",
    "# idx_var = \"T_34\"\n",
    "# spatial_var = \"ddt_sst\"\n",
    "idx_var = \"T_34\"\n",
    "spatial_var = \"ddt_d20\"\n",
    "month = 4\n",
    "t_idx = dict(time=slice(month - 1, None, 12))\n",
    "\n",
    "## get data to use\n",
    "if use_hat:\n",
    "    spatial_data = data_hat[spatial_var]\n",
    "    idx_data = idx_hat[idx_var]\n",
    "\n",
    "else:\n",
    "    spatial_data = data_[spatial_var]\n",
    "    idx_data = idx[idx_var]\n",
    "\n",
    "## compute correlation coefs\n",
    "coefs = src.utils.rho_xr(Y_data=spatial_data.isel(t_idx), idx=idx_data.isel(t_idx))\n",
    "\n",
    "## plot leading modes\n",
    "fig = plt.figure(figsize=(6, 1.25), layout=\"constrained\")\n",
    "axs = src.utils.subplots_with_proj(\n",
    "    fig, nrows=1, ncols=1, format_func=src.utils.plot_setup_pac\n",
    ")\n",
    "\n",
    "# ## shared arguments for plotting\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    # levels=src.utils.make_cb_range(16, 2),\n",
    "    levels=src.utils.make_cb_range(0.75, 0.15),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cp = axs[0, 0].contourf(\n",
    "    coefs.longitude,\n",
    "    coefs.latitude,\n",
    "    coefs,\n",
    "    **kwargs,\n",
    ")\n",
    "cb = fig.colorbar(cp)\n",
    "\n",
    "kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_extent([120, 280, -20, 20], crs=ccrs.PlateCarree())\n",
    "    ax.axhline(-5, **kwargs)\n",
    "    ax.axhline(5, **kwargs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d418a-0b78-4a2d-a779-651ab40e938e",
   "metadata": {},
   "source": [
    "## LIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd64b7e-23b7-488d-9c96-7350bf0064ee",
   "metadata": {},
   "source": [
    "#### Put data in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d7b3e-a490-4395-a055-b76301528647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(scores, other_coord=None):\n",
    "    \"\"\"reconstruct projected data\"\"\"\n",
    "\n",
    "    ## get reconstructions\n",
    "    kwargs = dict(other_coord=other_coord)\n",
    "    T_recon = src.utils.reconstruct_helper(scores[:10], model=model_sst, **kwargs)\n",
    "    h_recon = src.utils.reconstruct_helper(scores[10:], model=model_d20, **kwargs)\n",
    "\n",
    "    return xr.merge([T_recon.rename(\"T\"), h_recon.rename(\"h\")]).real\n",
    "\n",
    "\n",
    "## apply to projected data\n",
    "get_weighted_scores = lambda model: model.scores() * src.utils.get_weight(model).values\n",
    "\n",
    "## reshape\n",
    "XY_np = np.concatenate(\n",
    "    [\n",
    "        get_weighted_scores(model_sst).rename(\"sst\").values,\n",
    "        get_weighted_scores(model_d20).rename(\"d20\").values,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "## get month labels\n",
    "month_idx = model_sst.scores().time.dt.month.values - 1\n",
    "\n",
    "## fit LIM\n",
    "lim = src.lim.LIM_CS(X=XY_np[:, :-1], Y=XY_np[:, 1:], month_labels=month_idx[:-1])\n",
    "\n",
    "## get spectrum\n",
    "sigma = 12 * lim.sigma\n",
    "omega = 12 / (2 * np.pi) * lim.omega\n",
    "\n",
    "## check reconstruction works\n",
    "print(\n",
    "    np.allclose(\n",
    "        model_d20.inverse_transform(model_d20.scores()).values,\n",
    "        reconstruct(XY_np)[\"h\"].values,\n",
    "        equal_nan=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "## fit LIM reference\n",
    "XY_idx = np.stack([idx[\"T_34\"].values, idx[\"h\"].values], axis=0)\n",
    "RO = src.lim.LIM_CS(X=XY_idx[:, :-1], Y=XY_idx[:, 1:], month_labels=month_idx[:-1])\n",
    "sigma_RO = 12 * RO.sigma\n",
    "omega_RO = 12 / (2 * np.pi) * RO.omega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf4019-77c3-4d2e-9bad-05702875355d",
   "metadata": {},
   "source": [
    "Plot spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22618751-b948-416b-8284-9e826688e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot spectrum\n",
    "fig, ax = plt.subplots(figsize=(3, 2.5))\n",
    "\n",
    "## plot data\n",
    "ax.scatter(sigma, omega)\n",
    "\n",
    "## plot RO as reference\n",
    "ax.scatter(sigma_RO, omega_RO)\n",
    "\n",
    "## label / guidelines\n",
    "kwargs = dict(c=\"k\", zorder=0.5, lw=1, ls=\"--\")\n",
    "for yt in [-0.25, 0, 0.25]:\n",
    "    ax.axhline(yt, **kwargs)\n",
    "ax.set_yticks([-1 / 4, 0, 1 / 4], labels=[r\"1/4\", \"0\", \"1/4\"])\n",
    "ax.set_xticks([-1, -0.5, 0])\n",
    "ax.set_xlim([-1, 0])\n",
    "ax.set_xlabel(r\"$\\sigma$ (year$^{-1}$)\")\n",
    "ax.set_ylabel(r\"$\\omega$ (year$^{-1}$)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937cd23-7369-4110-a068-f07a9b0a0492",
   "metadata": {},
   "source": [
    "#### evaluate eigenfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da567a-bc01-4258-b48f-345cf78dc53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify eigenfunction index for ENSO\n",
    "enso_idx = 0\n",
    "enso_idxs = np.array([enso_idx, enso_idx + 1])\n",
    "\n",
    "## get reduced eigendecomp\n",
    "Uk = copy.deepcopy(lim.U[..., enso_idxs])\n",
    "gammak = copy.deepcopy(lim.gamma[enso_idxs])\n",
    "Vk = copy.deepcopy(lim.V[..., enso_idxs])\n",
    "\n",
    "## evaluate ENSO eigenfunction\n",
    "varphi = np.einsum(\"nmk,mn->nk\", Vk[month_idx], XY_np)\n",
    "\n",
    "## same, but in RO\n",
    "varphi_RO = np.einsum(\"nmk,mn->nk\", RO.V[month_idx], XY_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f376bd-2c5a-472a-92d3-b8c8692523d2",
   "metadata": {},
   "source": [
    "Find phase of \"peak\" ENSO for Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a1793-a34c-4265-82ca-3cf62623865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify month to find peak index\n",
    "peak_month_idx = 0\n",
    "\n",
    "## get test pts\n",
    "theta_test = np.arange(0, 2 * np.pi, np.pi / 32)\n",
    "varphi_test = varphi.std() * np.exp(1j * theta_test)\n",
    "VtX = np.stack([varphi_test, np.conj(varphi_test)], axis=0)\n",
    "\n",
    "## Get recon (EOF space)\n",
    "recon = Uk[peak_month_idx] @ VtX\n",
    "\n",
    "## Get recon (real space)\n",
    "recon_xr = reconstruct(recon, other_coord=pd.Index(theta_test, name=\"theta\"))\n",
    "nino_recon = src.utils.get_nino34(recon_xr[\"T\"])\n",
    "\n",
    "## get theta for maximimum Niño in peak month\n",
    "theta_max = recon_xr.theta.isel(theta=nino_recon.argmax(\"theta\")).values.item()\n",
    "\n",
    "print(theta_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ea938-b1f6-4406-b5d9-c19c964268b1",
   "metadata": {},
   "source": [
    "#### Look at evolution of \"peak\" event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba5afe-6666-41f7-ae63-7bdda2c6c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get difference from max\n",
    "lags_months = np.arange(-12, 13)\n",
    "lags_years = lags_months / 12\n",
    "delta_theta = 2 * np.pi * omega[enso_idx] * lags_years\n",
    "\n",
    "## get data\n",
    "month_idx_test = np.mod(peak_month_idx + lags_months, 12)\n",
    "theta_test = np.mod(theta_max + delta_theta, 2 * np.pi)\n",
    "varphi_test = 1.25 * varphi.std() * np.exp(1j * theta_test)\n",
    "\n",
    "## get complex conjugate\n",
    "varphi_test = np.stack([varphi_test, np.conj(varphi_test)], axis=0)\n",
    "\n",
    "## Get recon (EOF space)\n",
    "recon = np.einsum(\n",
    "    \"nmk,kn->mn\",\n",
    "    Uk[month_idx_test],\n",
    "    varphi_test,\n",
    ")\n",
    "\n",
    "## Get recon (real space)\n",
    "recon_xr = reconstruct(recon, other_coord=pd.Index(lags_months, name=\"lag\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef51875-e45a-428a-8daa-73826701b781",
   "metadata": {},
   "source": [
    "Same, but with composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6fd98-e8fc-44ad-80bc-6e3f16f55526",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove dependence on SST as well (optional)\n",
    "data_hat = remove_sst_dependence(data_, idx[\"T_34\"], remove_from_sst=False)\n",
    "\n",
    "## make composite\n",
    "comp = src.utils.make_composite(\n",
    "    idx=idx[\"T_34\"],\n",
    "    data=data_,\n",
    "    peak_month=12,\n",
    "    q=0.85,\n",
    "    check_cutoff=lambda x, cut: x > cut,\n",
    ").rename({\"sst\": \"T\", \"d20\": \"h\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a9f5e-e1ba-4ab0-996b-a713045be430",
   "metadata": {},
   "source": [
    "#### Hövmöller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cdab24-bfd0-4c22-a68f-728d9a24aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get meridional means\n",
    "lat = dict(latitude=slice(-5, 5))\n",
    "recon_merimean = recon_xr.sel(lat).mean(\"latitude\")\n",
    "comp_merimean = comp.sel(lat).mean(\"latitude\")\n",
    "\n",
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3), layout=\"constrained\")\n",
    "\n",
    "for ax, merimean in zip(axs, [recon_merimean, comp_merimean]):\n",
    "\n",
    "    ## SST\n",
    "    ax.contourf(\n",
    "        merimean.longitude,\n",
    "        merimean.lag,\n",
    "        merimean[\"T\"],\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(3, 0.3),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    ## thermocline\n",
    "    ax.contour(\n",
    "        merimean.longitude,\n",
    "        merimean.lag,\n",
    "        merimean[\"h\"],\n",
    "        colors=\"k\",\n",
    "        levels=src.utils.make_cb_range(40, 8),\n",
    "        extend=\"both\",\n",
    "        linewidths=1,\n",
    "    )\n",
    "\n",
    "    ## label x axis\n",
    "    ax.set_xticks([190, 240])\n",
    "\n",
    "## label\n",
    "axs[0].set_yticks([-12, 0, 12], labels=[\"Jan(-1)\", \"Jan(0)\", \"Jan(+1)\"])\n",
    "axs[1].set_yticks([])\n",
    "ax.set_xticks([190, 240])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf007c37-48ae-4ea6-afe2-b69aafa294c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate eigenfuncs\n",
    "varphi_all = np.einsum(\"nmk,mn->nk\", lim.V[month_idx], XY_np)\n",
    "\n",
    "## get magnitude\n",
    "mag = np.abs(varphi_all[:, enso_idx])\n",
    "is_large = mag > np.percentile(mag, 70)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.scatter(\n",
    "    src.utils.get_angle(varphi_all[is_large, enso_idx]),\n",
    "    src.utils.get_angle(varphi_all[is_large, 4]),\n",
    "    s=10,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9978b07-21d4-45d9-ab74-638560934aa7",
   "metadata": {},
   "source": [
    "#### Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334192ce-f2b8-43df-9028-326d921651a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify plot data (LIM recon or comp)\n",
    "plot_data = recon_xr\n",
    "# plot_data = comp\n",
    "\n",
    "for lag in plot_data.lag[::2]:\n",
    "\n",
    "    ## plot leading modes\n",
    "    fig = plt.figure(figsize=(8, 2.5), layout=\"constrained\")\n",
    "    axs = src.utils.subplots_with_proj(\n",
    "        fig, nrows=2, ncols=1, format_func=src.utils.plot_setup_pac\n",
    "    )\n",
    "\n",
    "    ## shared arguments for plotting\n",
    "    kwargs = dict(\n",
    "        cmap=\"cmo.balance\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    cp = axs[0, 0].contourf(\n",
    "        plot_data.longitude,\n",
    "        plot_data.latitude,\n",
    "        plot_data[\"T\"].sel(lag=lag),\n",
    "        levels=src.utils.make_cb_range(3, 0.3),\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    cp = axs[1, 0].contourf(\n",
    "        plot_data.longitude,\n",
    "        plot_data.latitude,\n",
    "        plot_data[\"h\"].sel(lag=lag),\n",
    "        levels=src.utils.make_cb_range(40, 4),\n",
    "        **kwargs,\n",
    "    )\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_extent([120, 280, -20, 20], crs=ccrs.PlateCarree())\n",
    "        ax.axhline(-5, **kwargs)\n",
    "        ax.axhline(5, **kwargs)\n",
    "\n",
    "    axs[0, 0].set_title(f\"Lag = {lag.values.item()} months\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e7886-e33f-41dc-9ed6-65a39b8fad16",
   "metadata": {},
   "source": [
    "#### Compare RO eigenmode to LIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1abd88d-dac1-4e9e-9a9c-8492a88d61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_corr(x0, x1):\n",
    "    \"\"\"function to compute cross correlation\"\"\"\n",
    "\n",
    "    ## compute cross correlation\n",
    "    cov = scipy.signal.correlate(x0, x1, mode=\"same\")\n",
    "    var0 = scipy.signal.correlate(x0, x0, mode=\"valid\")\n",
    "    var1 = scipy.signal.correlate(x1, x1, mode=\"valid\")\n",
    "\n",
    "    ## get lags\n",
    "    lags = scipy.signal.correlation_lags(len(x0), len(x0), mode=\"same\")\n",
    "\n",
    "    return cov / np.sqrt(var0 * var1), lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f3cbd-8811-402d-92d8-baac11329335",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this works for T_34/h combination\n",
    "theta = 1 * np.pi / 8\n",
    "\n",
    "## get phase shift\n",
    "phi = np.exp(1j * theta)\n",
    "\n",
    "xcorr, lags = cross_corr(phi * varphi_RO[:, 0], varphi[:, 0])\n",
    "xcorr0, _ = cross_corr(varphi_RO[:, 0], varphi_RO[:, 0])\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.plot(lags, xcorr.real)\n",
    "ax.plot(lags, xcorr.imag)\n",
    "ax.plot(lags, xcorr0.real, c=sns.color_palette()[0], ls=\"--\")\n",
    "ax.axvline(0, c=\"k\")\n",
    "ax.set_xlim([-36, 36])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
