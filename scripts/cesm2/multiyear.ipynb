{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f37b317-6514-4f0c-a712-2b90657ce08e",
   "metadata": {},
   "source": [
    "# Multiyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d519e1-6924-4db0-85cf-c42575f796f9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42677974-a7b9-4cc2-9d89-0de5d124b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pathlib\n",
    "import cmocean\n",
    "import os\n",
    "import cartopy.util\n",
    "import copy\n",
    "\n",
    "# Import custom modules\n",
    "import src.utils\n",
    "from src.XRO import XRO, xcorr\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "SAVE_FP = pathlib.Path(os.environ[\"SAVE_FP\"])\n",
    "\n",
    "## random number generator\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa908ac-be46-4946-af0d-c32b1ef7a09f",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd4070-7e52-4401-96e1-bd41e2ce3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function for padding array\n",
    "pad = lambda x, n: np.pad(x, pad_width=(0, n), constant_values=False)\n",
    "\n",
    "\n",
    "def get_multiyr_idx(bool_arr, n):\n",
    "    ## get indices of \"true\"\n",
    "    idx = np.where(bool_arr)[-1]\n",
    "\n",
    "    return np.array([[i + j for j in range(n)] for i in idx]).flatten()\n",
    "\n",
    "\n",
    "def get_multiyr_mask(mask_raw, n):\n",
    "    ## get indices of event starts\n",
    "    start_idx = np.where(mask_raw)[-1]\n",
    "\n",
    "    ## get indices included in events\n",
    "    idx = np.array([[i + j for j in range(n)] for i in start_idx]).flatten()\n",
    "\n",
    "    ## fill out new mask\n",
    "    mask = np.zeros_like(mask_raw)\n",
    "\n",
    "    if len(idx) > 0:\n",
    "        mask[idx] = True\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_events_per_year(mask, n):\n",
    "    \"\"\"Convert from boolean 'is an event happening?' to float\n",
    "    number of events per year\"\"\"\n",
    "    return mask.astype(float) * 1 / n\n",
    "\n",
    "\n",
    "def mask_multiyear_events(x):\n",
    "    \"\"\"count number of multiyear events up to 'n' years.\n",
    "    To-do: implement the 'n' thing (up to 'n'-year events).\"\"\"\n",
    "\n",
    "    ## make copy to avoid mutation\n",
    "    single_mask = copy.deepcopy(x)\n",
    "\n",
    "    ## get mask of double and triple events\n",
    "    double_mask = single_mask[:-1] & single_mask[1:]\n",
    "    triple_mask = double_mask[:-1] & single_mask[2:]\n",
    "    # quadru_mask = triple_mask[:-1] & single_mask[3:]\n",
    "\n",
    "    ## pad them so arrays are same length\n",
    "    double_mask = pad(double_mask, 1)\n",
    "    triple_mask = pad(triple_mask, 2)\n",
    "\n",
    "    ## Get indices of events\n",
    "    double_idx = get_multiyr_idx(double_mask, n=2)\n",
    "    triple_idx = get_multiyr_idx(triple_mask, n=3)\n",
    "\n",
    "    ## Get updated masks\n",
    "    double_mask = get_multiyr_mask(double_mask, n=2)\n",
    "    triple_mask = get_multiyr_mask(triple_mask, n=3)\n",
    "\n",
    "    # ## remove duplicates\n",
    "    double_mask[triple_mask] = False\n",
    "    single_mask[triple_mask | double_mask] = False\n",
    "\n",
    "    ## to-do: convert to events per year\n",
    "    single_mask = get_events_per_year(single_mask, 1)\n",
    "    double_mask = get_events_per_year(double_mask, 2)\n",
    "    triple_mask = get_events_per_year(triple_mask, 3)\n",
    "\n",
    "    ## Get total mask\n",
    "    mask = np.stack([single_mask, double_mask, triple_mask], axis=0)\n",
    "\n",
    "    ## filter out events at end of record (to avoid biasing towards single-year)\n",
    "    # mask[:, -2:] = False\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_multiyear_events_geng(n34, month_idx, thresh, is_warm):\n",
    "    \"\"\"mask wintertime multiyear La Niñas, following Geng et al. (2023)\"\"\"\n",
    "\n",
    "    ## get rolling Niño 3.4 index\n",
    "    n34_rolling = np.convolve(n34, 1 / 5 * np.ones(5), mode=\"same\")\n",
    "\n",
    "    ## get winter n34 (centered on december)\n",
    "    is_winter = month_idx == 11\n",
    "    n34_winter = n34_rolling[is_winter]\n",
    "\n",
    "    ## set threshold for ENSO event if not specified\n",
    "    if thresh is None:\n",
    "        thresh = n34_winter[:80].std() * 0.5\n",
    "\n",
    "    ## find El NIño / La Niñas (following Geng, base on ONDJF Niño std dev)\n",
    "    if is_warm:\n",
    "        is_event = n34_winter > thresh\n",
    "\n",
    "    else:\n",
    "        is_event = n34_winter < -thresh\n",
    "\n",
    "    ## find multiyear La Niñas\n",
    "    return mask_multiyear_events(is_event)\n",
    "\n",
    "\n",
    "def count_multiyear_laninas(n34, month_idx, thresh=None, is_warm=False, window=41):\n",
    "    \"\"\"count frequency of multiyear La Niñas, following Geng et al. (2023)\"\"\"\n",
    "\n",
    "    ## find multiyear La Niñas\n",
    "    kwargs = dict(n34=n34, month_idx=month_idx, thresh=thresh, is_warm=is_warm)\n",
    "    peak_mask_winter = mask_multiyear_events_geng(**kwargs)\n",
    "\n",
    "    ## function to count La Niñas in single boolean sequence\n",
    "    conv_filter = 100 / window * np.ones(window)\n",
    "    count_single = lambda x: np.convolve(conv_filter, x, mode=\"valid\")\n",
    "\n",
    "    return np.apply_along_axis(func1d=count_single, axis=1, arr=peak_mask_winter)\n",
    "\n",
    "\n",
    "def count_multiyear_laninas_ensemble(T, is_warm=False, thresh=0.57, window=41):\n",
    "    \"\"\"apply to each ensemble member. To-do: compute threshold using all ensemble memberes\"\"\"\n",
    "\n",
    "    ## array to hold counts\n",
    "    counts = []\n",
    "\n",
    "    ## get month index\n",
    "    month_idx = T.time.dt.month.values - 1\n",
    "\n",
    "    ## iterate over ensemble axis\n",
    "    for m in T.member:\n",
    "        ## get single ensemble member\n",
    "        kwargs = dict(\n",
    "            n34=T.sel(member=m).values,\n",
    "            month_idx=month_idx,\n",
    "            thresh=thresh,\n",
    "            is_warm=is_warm,\n",
    "            window=window,\n",
    "        )\n",
    "\n",
    "        ## count in given ensemble member\n",
    "        counts.append(count_multiyear_laninas(**kwargs))\n",
    "\n",
    "    return np.stack(counts, axis=2)\n",
    "\n",
    "\n",
    "def get_rolling_std(data, n=20):\n",
    "    \"\"\"\n",
    "    Get standard deviation, computing over time and ensemble member. To increase\n",
    "    sample size for variance estimate, compute over time window of 2n+1\n",
    "    years, centered at given year.\n",
    "    \"\"\"\n",
    "\n",
    "    ## do the computation\n",
    "    kwargs = dict(fn=np.std, n=n, reduce_ensemble_dim=True)\n",
    "    data_std = src.utils.get_rolling_fn_bymonth(data, **kwargs)\n",
    "\n",
    "    ## unstack year and month\n",
    "    data_std = src.utils.unstack_month_and_year(data_std)\n",
    "\n",
    "    return data_std\n",
    "\n",
    "\n",
    "def postprocess_counts(counts):\n",
    "    \"\"\"Compute some stats on multiyear counts\"\"\"\n",
    "\n",
    "    ## get number of years in La Niña state\n",
    "    nyears = counts[\"n\"] * counts\n",
    "\n",
    "    ## get fractional data\n",
    "    frac_count = counts.mean(\"member\").sel(n=2) / counts.mean(\"member\").sum(\"n\")\n",
    "    frac_nyear = nyears.mean(\"member\").sel(n=2) / nyears.mean(\"member\").sum(\"n\")\n",
    "    frac_event = nyears.sum(\"n\").mean(\"member\") / 100\n",
    "\n",
    "    return xr.merge(\n",
    "        [\n",
    "            counts.rename(\"counts\"),\n",
    "            nyears.rename(\"nyears\"),\n",
    "            frac_count.rename(\"frac_count\"),\n",
    "            frac_nyear.rename(\"frac_nyear\"),\n",
    "            frac_event.rename(\"frac_event\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_simulations(\n",
    "    model,\n",
    "    params,\n",
    "    X0_ds,\n",
    "    save_fp,\n",
    "    nyear=3000,\n",
    "):\n",
    "    \"\"\"generate simulations for given parameter set, and save to file\"\"\"\n",
    "\n",
    "    ## try opening pre-computed\n",
    "    if save_fp.is_file():\n",
    "        time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "        sims = xr.open_dataset(save_fp, decode_times=time_coder)\n",
    "\n",
    "    ## otherwise, run simulations\n",
    "    else:\n",
    "\n",
    "        ## empty list to hold simulations\n",
    "        sims = []\n",
    "\n",
    "        ## loop thru years in parameter set\n",
    "        for y in tqdm.tqdm(params.year):\n",
    "\n",
    "            ## get initial condition\n",
    "            X0 = X0_ds.sel(member=RNG.choice(X0_ds.member), time=RNG.choice(X0_ds.time))\n",
    "\n",
    "            ## simulate\n",
    "            sim = model.simulate(\n",
    "                fit_ds=params.sel(year=y), nyear=nyear, ncopy=100, X0_ds=X0\n",
    "            )\n",
    "\n",
    "            ## append\n",
    "            sims.append(sim)\n",
    "\n",
    "        ## save to xarray\n",
    "        sims = xr.concat(sims, dim=params.year)\n",
    "\n",
    "        ## save\n",
    "        sims.to_netcdf(save_fp)\n",
    "\n",
    "    return sims\n",
    "\n",
    "\n",
    "def count_RO_multi_over_time(\n",
    "    sims,\n",
    "    thresh=0.73,\n",
    "    is_warm=True,\n",
    "    varname=\"T_34\",\n",
    "    nyear=3000,\n",
    "):\n",
    "    \"\"\"Compute stats over time\"\"\"\n",
    "\n",
    "    ## empty list to hold result\n",
    "    counts = []\n",
    "\n",
    "    ## loop through years\n",
    "    for y in tqdm.tqdm(sims.year):\n",
    "\n",
    "        ## get simulation for given year\n",
    "        sim = sims.sel(year=y)\n",
    "\n",
    "        ## count multiyear events\n",
    "        counts_for_period = count_multiyear_laninas_ensemble(\n",
    "            T=sim[varname], is_warm=is_warm, thresh=thresh, window=nyear\n",
    "        )\n",
    "\n",
    "        ## put in xarray\n",
    "        counts_for_period = xr.DataArray(\n",
    "            data=counts_for_period,\n",
    "            coords=dict(n=[1, 2, 3], year=[y], member=sim.member.values),\n",
    "            dims=[\"n\", \"year\", \"member\"],\n",
    "        )\n",
    "\n",
    "        counts.append(counts_for_period)\n",
    "\n",
    "    ## put back in xarray\n",
    "    counts = xr.concat(counts, dim=sims.year)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d635e77-0fc1-4f6c-8154-a69db7e3f1a1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d3046-7a1c-4bc3-bd0b-afc36c178593",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open data\n",
    "Th = src.utils.load_cesm_indices(load_z20=True)\n",
    "\n",
    "## rename indices for convenience\n",
    "Th = Th.rename(\n",
    "    {\n",
    "        \"north_tropical_atlantic\": \"natl\",\n",
    "        \"atlantic_nino\": \"nino_atl\",\n",
    "        \"tropical_indian_ocean\": \"iobm\",\n",
    "        \"indian_ocean_dipole\": \"iod\",\n",
    "        \"north_pacific_meridional_mode\": \"npmm\",\n",
    "        \"south_pacific_meridional_mode\": \"spmm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "## load scale factor\n",
    "hbar_scale = xr.open_dataarray(\n",
    "    pathlib.Path(SAVE_FP, \"cesm_Hbar_scale_v2.nc\"),\n",
    ")\n",
    "\n",
    "## compute\n",
    "Th[\"h_w_Hbar-scaled\"] = Th[\"h_w\"] * hbar_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61556dad-b21c-4d39-a37b-e96748425cc8",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92399132-5470-4149-b06e-71ef878d583a",
   "metadata": {},
   "source": [
    "### CESM diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84f2ad-d8ad-4a8a-a371-bb29ed676806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify varname\n",
    "VARNAME = \"T_34\"\n",
    "\n",
    "## warm or cold\n",
    "IS_WARM = False\n",
    "\n",
    "## specify whether to use fixed cutoff to define event\n",
    "use_fixed_thresh = True\n",
    "\n",
    "if use_fixed_thresh:\n",
    "    ## use 1/2 std dev of early period\n",
    "    Th_early = Th[VARNAME].sel(time=slice(\"1850\", \"1910\"))\n",
    "    sigma_early = Th_early.groupby(\"time.month\").std([\"time\", \"member\"])\n",
    "    THRESH = 0.5 * sigma_early.sel(month=12).values.item()\n",
    "else:\n",
    "    ## get rolling standard dev\n",
    "    half_sigma_rolling = 0.5 * get_rolling_std(Th[VARNAME]).sel(month=12).values\n",
    "\n",
    "    ## get threshold array\n",
    "    thresh = np.nan * np.zeros(2101 - 1850)\n",
    "    thresh[20:-20] = half_sigma_rolling\n",
    "    thresh[:20] = half_sigma_rolling[0]\n",
    "    thresh[-20:] = half_sigma_rolling[-1]\n",
    "\n",
    "## count multiyear events\n",
    "counts = count_multiyear_laninas_ensemble(T=Th[VARNAME], is_warm=IS_WARM, thresh=THRESH)\n",
    "\n",
    "## put in xarray\n",
    "counts = xr.DataArray(\n",
    "    data=counts,\n",
    "    coords=dict(n=[1, 2, 3], year=np.arange(1870, 2081), member=Th.member.values),\n",
    "    dims=[\"n\", \"year\", \"member\"],\n",
    ")\n",
    "\n",
    "## Compute stats\n",
    "stats_cesm = postprocess_counts(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522ce90-764f-4d43-b3ef-4f7882503d9d",
   "metadata": {},
   "source": [
    "### RO experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262666c7-090f-4917-9f4b-201b1db4c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save filpath\n",
    "sims_fname = \"T3_hw_Hbar_scaled.nc\"\n",
    "\n",
    "## set variables\n",
    "fp = pathlib.Path(os.environ[\"SAVE_FP\"], \"fits_cesm/T3_h_w_Hbar_scaled_ac-order3\")\n",
    "X0_ds = Th[[\"T_3\", \"h_w_Hbar-scaled\"]].isel(year=0)\n",
    "sim_save_fp = pathlib.Path(DATA_FP, \"RO_stoc\", sims_fname)\n",
    "\n",
    "## load parameters (and perturb them)\n",
    "params = xr.open_dataset(fp)\n",
    "pparams_bj_noise = src.utils.get_perturbed_multi(\n",
    "    params=params,\n",
    "    idxs=[(0, 0), (1, 1)],\n",
    "    fix_others=False,\n",
    "    fix_noise=False,\n",
    ")\n",
    "pparams_wyrtki = src.utils.get_perturbed_multi(\n",
    "    params=params,\n",
    "    idxs=[(0, 1)],\n",
    "    fix_others=False,\n",
    "    fix_noise=False,\n",
    ")\n",
    "\n",
    "## specify model\n",
    "model = src.XRO.XRO(ncycle=12, ac_order=3, is_forward=True)\n",
    "\n",
    "## generate simulations\n",
    "sims = generate_simulations(\n",
    "    model=model, params=params, X0_ds=X0_ds, save_fp=sim_save_fp\n",
    ")\n",
    "sims_bj = generate_simulations(\n",
    "    model=model,\n",
    "    params=pparams_bj_noise,\n",
    "    X0_ds=X0_ds,\n",
    "    save_fp=sim_save_fp.parent / f\"{sims_fname[:-3]}_bj.nc\",\n",
    ")\n",
    "sims_wy = generate_simulations(\n",
    "    model=model,\n",
    "    params=pparams_wyrtki,\n",
    "    X0_ds=X0_ds,\n",
    "    save_fp=sim_save_fp.parent / f\"{sims_fname[:-3]}_wy.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f1229-7fc8-4c9e-a010-cb10343bc88d",
   "metadata": {},
   "source": [
    "Count events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d5312-c291-46cc-9296-d61bfe7a8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute stats\n",
    "counts_RO = count_RO_multi_over_time(\n",
    "    sims=sims_wy, is_warm=IS_WARM, thresh=THRESH, varname=list(X0_ds)[0]\n",
    ")\n",
    "stats_RO = postprocess_counts(counts_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9da343-6851-4d21-a2ac-9b138f32e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute stats\n",
    "counts_RO = []\n",
    "stats_RO = []\n",
    "for sims_ in [sims, sims_bj, sims_wy]:\n",
    "    counts_ = count_RO_multi_over_time(\n",
    "        sims=sims_, is_warm=IS_WARM, thresh=THRESH, varname=list(X0_ds)[0]\n",
    "    )\n",
    "    counts_RO.append(counts_)\n",
    "    stats_RO.append(postprocess_counts(counts_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368b189-6586-4fa4-96e5-d836984222e4",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a895dc-f786-40d3-8575-adcfe104fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get control experiment\n",
    "counts_RO_control = counts_RO[0]\n",
    "stats_RO_control = stats_RO[0]\n",
    "\n",
    "## colors for plot\n",
    "colors = sns.color_palette(\"colorblind\")\n",
    "\n",
    "## set up the plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "## plot each curve\n",
    "for c, n, label in zip(colors, counts_RO_control.n, [\"1 yr\", \"2 yr\", \"3 yr\"]):\n",
    "    for j, (counts_, ls) in enumerate(zip([counts, counts_RO_control], [\"-\", \"--\"])):\n",
    "\n",
    "        ## plot args\n",
    "        plot_kwargs = dict(ls=ls, c=c, label=(label if j == 0 else None))\n",
    "\n",
    "        ## plot data\n",
    "        ax.plot(counts_.year, counts_.sel(n=n).mean(\"member\"), **plot_kwargs)\n",
    "\n",
    "## label\n",
    "ax.legend(prop={\"size\": 8})\n",
    "ax.set_ylabel(\"# per century\")\n",
    "ax.set_ylim([-2, 25])\n",
    "ax.set_yticks([0, 10, 20])\n",
    "ax.axvline(2010, ls=\"--\", c=\"k\", lw=0.8)\n",
    "ax.set_xticks([1880, 2010, 2080])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf1197-7b25-4104-b568-e4b9e8e5e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels\n",
    "labels = [\"La Niña winters / total winters\", \"2-year La Niña / total La Niñas\"]\n",
    "varnames = [\"frac_event\", \"frac_count\"]\n",
    "\n",
    "## set up the plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "for c, n, label_ in zip([\"k\", colors[1]], varnames, labels):\n",
    "    for j, (stats, ls) in enumerate(zip([stats_cesm, stats_RO_control], [\"-\", \"--\"])):\n",
    "\n",
    "        ## plot args\n",
    "        plot_kwargs = dict(ls=ls, c=c, label=(label_ if j == 0 else None))\n",
    "\n",
    "        ## plot data\n",
    "        ax.plot(stats.year, stats[n], **plot_kwargs)\n",
    "\n",
    "## label\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"fraction\")\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_yticks([0, 0.2, 0.4])\n",
    "ax.axvline(2010, ls=\"--\", c=\"k\", lw=0.8)\n",
    "ax.set_xticks([1880, 2010, 2080])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0da60-4bdd-48bb-9bec-1652a452503f",
   "metadata": {},
   "source": [
    "### Compare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95578186-3616-426c-9f2d-0b5284daa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels\n",
    "labels = [\"La Niña winters / total winters\", \"2-year La Niña / total La Niñas\"]\n",
    "varnames = [\"frac_event\", \"frac_count\"]\n",
    "\n",
    "## set up the plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "for stats, c, label in zip(\n",
    "    stats_RO, [\"k\", *colors[1:3]], [\"Control\", \"fix Bjerknes\", \"fix Wyrtki\"]\n",
    "):\n",
    "\n",
    "    ## plot args\n",
    "    # plot_kwargs = dict(ls=ls, c=c)\n",
    "\n",
    "    ## plot data\n",
    "    ax.plot(stats.year, stats[\"frac_count\"], c=c, lw=2, label=label)\n",
    "\n",
    "## label\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"fraction\")\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_yticks([0, 0.2, 0.4])\n",
    "ax.axvline(2010, ls=\"--\", c=\"k\", lw=0.8)\n",
    "ax.set_xticks([1880, 2010, 2080])\n",
    "ax.set_title(\"2-year La Niña / total La Niñas (RO)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
