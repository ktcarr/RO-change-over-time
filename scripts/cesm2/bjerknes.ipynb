{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22516693-2eb8-45f7-b9d4-4511a195a408",
   "metadata": {},
   "source": [
    "# Bjerknes feedback changes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e795c63-4ea6-4623-b0a2-e33656d4c420",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d155a1-2906-4d88-9022-b7996ecf7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pathlib\n",
    "import cmocean\n",
    "import os\n",
    "import cartopy.util\n",
    "import copy\n",
    "\n",
    "# Import custom modules\n",
    "import src.utils\n",
    "from src.XRO import XRO, xcorr\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "SAVE_FP = pathlib.Path(os.environ[\"SAVE_FP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382b7b8-eac8-4cf0-8ad1-4632a36727b9",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874f9c6-8fd1-4c20-abb1-98e3e4962768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hov(ax, data, amp, label=None):\n",
    "    \"\"\"Plot hovmoller of longitude vs. year\"\"\"\n",
    "\n",
    "    # kwargs = dict(levels=src.utils.make_cb_range(3, 0.3), cmap=\"cmo.balance\", extend=\"both\")\n",
    "    plot_data = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.year,\n",
    "        data.T,\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"both\",\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "    )\n",
    "    cb = fig.colorbar(\n",
    "        plot_data, orientation=\"horizontal\", ticks=[-amp, 0, amp], label=label\n",
    "    )\n",
    "\n",
    "    ## label\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_xticks([190, 240])\n",
    "        ax.set_yticks([])\n",
    "        ax.axvline(190, **kwargs)\n",
    "        ax.axvline(240, **kwargs)\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_hov2(ax, data, amp, label=None):\n",
    "    \"\"\"Plot hovmoller of longitude vs. year\"\"\"\n",
    "\n",
    "    # kwargs = dict(levels=src.utils.make_cb_range(3, 0.3), cmap=\"cmo.balance\", extend=\"both\")\n",
    "    plot_data = ax.contourf(\n",
    "        data.month,\n",
    "        data.year,\n",
    "        data.T,\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"max\",\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "    )\n",
    "    cb = fig.colorbar(\n",
    "        plot_data,\n",
    "        orientation=\"horizontal\",\n",
    "        ticks=[-amp, 0, amp],\n",
    "        label=label,\n",
    "        # plot_data, orientation=\"horizontal\", ticks=[], label=None\n",
    "    )\n",
    "\n",
    "    ## label\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs:\n",
    "        # ax.set_xlabel(\"Month\")\n",
    "        # ax.set_xticks([1, 12])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_rolling_var(data, n=10):\n",
    "    \"\"\"\n",
    "    Get variance, computing over time and ensemble member. To increase\n",
    "    sample size for variance estimate, compute over time window of 2n+1\n",
    "    years, centered at given year.\n",
    "    \"\"\"\n",
    "\n",
    "    return src.utils.get_rolling_fn_bymonth(data, fn=np.var, n=n)\n",
    "\n",
    "\n",
    "def get_ml_avg(data, Hm, delta=5, H0=None):\n",
    "    \"\"\"func to average data from surface to Hm + delta\"\"\"\n",
    "\n",
    "    ## interpolate MLD onto data grid\n",
    "    Hm_ = Hm.rename({\"longitude\": \"lon\"}).interp({\"lon\": data.lon})\n",
    "\n",
    "    ## tweak integration bounds\n",
    "    if H0 is None:\n",
    "        Hm_ = Hm_ + delta\n",
    "\n",
    "    else:\n",
    "        Hm_ = H0 * xr.ones_like(Hm_)\n",
    "\n",
    "    ## average over everything above the mixed layer\n",
    "    return data.where(data.z_t <= Hm_).mean(\"z_t\")\n",
    "\n",
    "\n",
    "def get_ml_avg_wrapper(data, Hm, delta=5, H0=None):\n",
    "    \"\"\"wrapper function to format data for plotting\"\"\"\n",
    "\n",
    "    ## first, compute mixed layer average\n",
    "    ml_avg = get_ml_avg(data=data, Hm=Hm, delta=delta, H0=H0)\n",
    "\n",
    "    ## rename coord and tranpose\n",
    "    return ml_avg.rename({\"lon\": \"longitude\"}).transpose(\"month\", ...)\n",
    "\n",
    "\n",
    "def plot_mld_bounds(ax, clim, m):\n",
    "    \"\"\"Plot MLD climatology and ± bounds\"\"\"\n",
    "\n",
    "    ## clim\n",
    "    ax.plot(clim.longitude, clim, c=\"k\")\n",
    "\n",
    "    ## El Niño\n",
    "    ax.plot(clim.longitude, clim + m, c=\"r\")\n",
    "\n",
    "    ## La Niña\n",
    "    ax.plot(clim.longitude, clim - m, c=\"b\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_wT(w, T):\n",
    "    \"\"\"function to get vertical flux (handles diff. w/T grids)\"\"\"\n",
    "\n",
    "    ## rename w grid\n",
    "    w_ = copy.deepcopy(w).rename({\"z_w_top\": \"z_t\"})\n",
    "    w_ = w_.assign_coords({\"z_t\": T.z_t})\n",
    "\n",
    "    return w_ * T\n",
    "\n",
    "\n",
    "def get_wdTdz(w, T):\n",
    "    \"\"\"function to get vertical flux (handles diff. w/T grids)\"\"\"\n",
    "\n",
    "    ## rename w grid\n",
    "    w_ = copy.deepcopy(w).rename({\"z_w_top\": \"z_t\"})\n",
    "    w_ = w_.assign_coords({\"z_t\": T.z_t})\n",
    "\n",
    "    ## get dTdz (convert from 1/cm to 1/m)\n",
    "    dTdz = T.differentiate(\"z_t\")\n",
    "\n",
    "    return w_ * dTdz\n",
    "\n",
    "\n",
    "def get_udTdx(u, T):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dlon_deg = T.lon.values[1] - T.lon.values[0]\n",
    "    lat_deg = 0.0\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_m = get_dx(lat_deg=lat_deg, dlon_deg=dlon_deg)\n",
    "\n",
    "    ## differentiate\n",
    "    u_dfdx_ = u * T.differentiate(\"lon\") * 1 / dx_m\n",
    "\n",
    "    return u_dfdx_\n",
    "\n",
    "\n",
    "def get_u_adv(u, T):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dlon_deg = T.lon.values[1] - T.lon.values[0]\n",
    "    lat_deg = 0.0\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_m = get_dx(lat_deg=lat_deg, dlon_deg=dlon_deg)\n",
    "\n",
    "    ## differentiate and convert units to K/yr\n",
    "    mo_per_yr = 12\n",
    "    u_dfdx_ = u * T.differentiate(\"lon\") * 1 / dx_m * mo_per_yr\n",
    "\n",
    "    return -u_dfdx_\n",
    "\n",
    "\n",
    "def recon_clim(data, components, varname=\"sst\"):\n",
    "    \"\"\"reconstruct climatology for data\"\"\"\n",
    "\n",
    "    ## get climatolgoy in PC space\n",
    "    monthly_clim = data.groupby(\"time.month\").mean()\n",
    "\n",
    "    ## function to compute equatorial mean\n",
    "    equatorial_mean = lambda x: x.sel(latitude=slice(-2, 2)).mean(\"latitude\")\n",
    "\n",
    "    ## reconstruct\n",
    "    recon = src.utils.reconstruct_fn(\n",
    "        components[varname], monthly_clim[varname], fn=equatorial_mean\n",
    "    )\n",
    "\n",
    "    ## fill zero values with NaN\n",
    "    recon.values[recon.values == 0] = np.nan\n",
    "\n",
    "    return recon\n",
    "\n",
    "\n",
    "def get_monthly_eli(t_bnds):\n",
    "\n",
    "    ## get eli for period\n",
    "    eli_ = eli_forced.isel(time=slice(*t_bnds)).groupby(\"time.month\").mean()\n",
    "\n",
    "    return eli_\n",
    "\n",
    "\n",
    "def get_monthly_eli_std(t_bnds):\n",
    "\n",
    "    ## get eli for period\n",
    "    eli_ = (\n",
    "        eli_anom.isel(time=slice(*t_bnds)).groupby(\"time.month\").std([\"time\", \"member\"])\n",
    "    )\n",
    "\n",
    "    return eli_\n",
    "\n",
    "\n",
    "def plot_cyclic(ax, data, sigma=None, **kwargs):\n",
    "    \"\"\"plot data on hovmoller with cyclic dependence on month\"\"\"\n",
    "\n",
    "    ## add cyclic point\n",
    "    data_cyclic, dim_cyclic = cartopy.util.add_cyclic_point(data, data.month, axis=0)\n",
    "\n",
    "    ## plot data\n",
    "    ax.plot(data_cyclic, dim_cyclic, **kwargs)\n",
    "\n",
    "    ## plot bounds if they exist\n",
    "    if sigma is not None:\n",
    "        sigma_cyclic, _ = cartopy.util.add_cyclic_point(sigma, data.month, axis=0)\n",
    "\n",
    "        ## plot data\n",
    "        ax.plot(data_cyclic + sigma_cyclic, dim_cyclic, **kwargs, lw=0.8)\n",
    "        ax.plot(data_cyclic - sigma_cyclic, dim_cyclic, **kwargs, lw=0.8)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_cyclic_quantiles(ax, data, quantiles=[0.5, 0.15, 0.85], **kwargs):\n",
    "    \"\"\"plot data on hovmoller with cyclic dependence on month\"\"\"\n",
    "\n",
    "    ## compute quantiles\n",
    "    q = data.groupby(\"time.month\").quantile(q=quantiles, dim=[\"time\", \"member\"])\n",
    "    # q = q.rename({\"quantile\":\"q\"})\n",
    "\n",
    "    ## convert to numpy\n",
    "    month = q.month.values\n",
    "    q = q.transpose(\"quantile\", \"month\").values\n",
    "\n",
    "    ## add cyclic point\n",
    "    q_cyclic, dim_cyclic = cartopy.util.add_cyclic_point(q, month, axis=1)\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(q_cyclic[0], dim_cyclic, **kwargs)\n",
    "\n",
    "    ## plot other quantiles\n",
    "    if len(quantiles) > 1:\n",
    "        for j in range(1, len(quantiles)):\n",
    "            ax.plot(q_cyclic[j], dim_cyclic, lw=0.8, **kwargs)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def format_subsurf_axs(axs):\n",
    "    \"\"\"add labels/formatting to 3-panel axs\"\"\"\n",
    "\n",
    "    ## loop thru axs\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(ax.get_ylim()[::-1])\n",
    "        ax.set_xlim([None, 281])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "    axs[0].set_yticks([300, 150, 0])\n",
    "    axs[0].set_ylabel(\"Depth (m)\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def format_hov_axs(axs):\n",
    "    \"\"\"put hovmoller axs in standardized format\"\"\"\n",
    "\n",
    "    ## set fontsize\n",
    "    font_kwargs = dict(size=8)\n",
    "    axs[0].set_ylabel(\"Month\", **font_kwargs)\n",
    "    axs[0].set_title(\"Early\", **font_kwargs)\n",
    "    axs[1].set_title(\"Late\", **font_kwargs)\n",
    "    axs[2].set_title(\"Difference (x2)\", **font_kwargs)\n",
    "\n",
    "    axs[1].set_yticks([])\n",
    "    axs[2].set_yticks([])\n",
    "    axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "\n",
    "    for ax in axs:\n",
    "        # ax.set_xlim([190, None])\n",
    "        ax.set_xticks([190, 240])\n",
    "        ax.axvline(240, ls=\"--\", c=\"w\", lw=1)\n",
    "        ax.axvline(190, ls=\"--\", c=\"w\", lw=1)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_w_int(w):\n",
    "    \"\"\"get vertical velocity integrated over top 200 m\"\"\"\n",
    "    return w.sel(z_w_top=slice(None, 200)).mean(\"z_w_top\")\n",
    "\n",
    "\n",
    "def get_dTdz(Tsub):\n",
    "    \"\"\"get vertical velocity integrated over top 200 m\"\"\"\n",
    "    T_surf = Tsub.sel(z_t=0, method=\"nearest\").squeeze(drop=True)\n",
    "    T_subsurf = Tsub.sel(z_t=200, method=\"nearest\").squeeze(drop=True)\n",
    "\n",
    "    return T_surf - T_subsurf\n",
    "\n",
    "\n",
    "def get_diags(data):\n",
    "    \"\"\"get diagnostics\"\"\"\n",
    "    diags = xr.merge(\n",
    "        [get_dTdz(data[\"T\"]).rename(\"dTdz\"), get_w_int(data[\"w\"]).rename(\"w_int\")]\n",
    "    )\n",
    "    return diags.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "\n",
    "def get_dT_sub(Tsub, mld, delta=25):\n",
    "    \"\"\"get temperature difference b/n mixed layer and entrainment zone\"\"\"\n",
    "\n",
    "    ## interpolate mld to match w\n",
    "    mld_interp = mld.interp({\"longitude\": Tsub.lon.values}).rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    ## subset for non-NaN coords\n",
    "    valid_lon_idx = ~np.isnan(mld_interp).all(\"month\")\n",
    "    mld_interp = mld_interp.isel(lon=valid_lon_idx)\n",
    "    Tsub = Tsub.isel(lon=valid_lon_idx)\n",
    "\n",
    "    ## find indices in ML and entrainment zone (ez)\n",
    "    in_ml = Tsub.z_t <= mld_interp\n",
    "    in_ez = (Tsub.z_t > mld_interp) & (Tsub.z_t < (delta + mld_interp))\n",
    "\n",
    "    ## get Tbar and Tplus (following Frankignoul et al paper)\n",
    "    Tbar = Tsub.where(in_ml).mean(\"z_t\")\n",
    "    Tplus = Tsub.where(in_ez).mean(\"z_t\")\n",
    "\n",
    "    ## get gradient\n",
    "    dT = Tbar - Tplus\n",
    "\n",
    "    return dT.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "\n",
    "def get_dTdz_sub(Tsub, mld, delta=25):\n",
    "    \"\"\"get velocity at base of mixed layer\"\"\"\n",
    "\n",
    "    ## get temperature difference\n",
    "    dT = get_dT_sub(Tsub=Tsub, mld=mld, delta=delta)\n",
    "\n",
    "    ## interpolate mld to match w\n",
    "    mld_interp = mld.interp({\"longitude\": Tsub.lon.values}).rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    ## subset for non-NaN coords\n",
    "    valid_lon_idx = ~np.isnan(mld_interp).all(\"month\")\n",
    "    mld_interp = mld_interp.isel(lon=valid_lon_idx)\n",
    "\n",
    "    ## get gradient\n",
    "    dTdz = dT / mld_interp.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "    return dTdz\n",
    "\n",
    "\n",
    "def get_nino34(data):\n",
    "    return data.sel(lon=slice(190, 240)).mean(\"lon\")\n",
    "\n",
    "\n",
    "def get_w_int_idx(data):\n",
    "    \"\"\"get nino3.4 w-int\"\"\"\n",
    "    return get_nino34(get_w_int(data))\n",
    "\n",
    "\n",
    "def get_dTdz_idx(data):\n",
    "    \"\"\"get nino3.4 w-int\"\"\"\n",
    "    return get_nino34(get_dTdz(data))\n",
    "\n",
    "\n",
    "def eq_avg(x):\n",
    "    return x.sel(latitude=slice(-5, 5), longitude=slice(125, 279)).mean(\"latitude\")\n",
    "\n",
    "\n",
    "def avg_mon_range(data, m0, m1):\n",
    "    \"\"\"average data each year over specified month range\"\"\"\n",
    "\n",
    "    ## find indices for month range\n",
    "    month = data.time.dt.month\n",
    "    is_season = (month >= m0) & (month <= m1)\n",
    "\n",
    "    ## get avg avg\n",
    "    data_season = data.isel(time=is_season).groupby(\"time.year\").mean()\n",
    "\n",
    "    return data_season.rename({\"year\": \"time\"})\n",
    "\n",
    "\n",
    "def get_mam(data):\n",
    "    \"\"\"subset for MAM months\"\"\"\n",
    "\n",
    "    return avg_mon_range(data, m0=3, m1=5)\n",
    "\n",
    "\n",
    "def set_ylims(axs):\n",
    "    lims = np.stack([ax.get_ylim() for ax in axs.flatten()], axis=0)\n",
    "\n",
    "    lb = lims[:, 0].min()\n",
    "    ub = lims[:, 1].max()\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_ylim([lb, ub])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def set_xlims(axs):\n",
    "    lims = np.stack([ax.get_xlim() for ax in axs.flatten()], axis=0)\n",
    "\n",
    "    lb = lims[:, 0].min()\n",
    "    ub = lims[:, 1].max()\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlim([lb, ub])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_dy(dlat_deg):\n",
    "    \"\"\"get spacing between latitudes in meters\"\"\"\n",
    "\n",
    "    ## convert from degrees to radians\n",
    "    dlat_rad = dlat / 180.0 * np.pi\n",
    "\n",
    "    ## multiply by radius of earth\n",
    "    R = 6.378e8  # earth radius (centimeters)\n",
    "    dlat_meters = R * dlat_rad\n",
    "\n",
    "    return dlat_meters\n",
    "\n",
    "\n",
    "def get_dx(lat_deg, dlon_deg):\n",
    "    \"\"\"get spacing between longitudes in meters\"\"\"\n",
    "\n",
    "    ## convert from degrees to radians\n",
    "    dlon_rad = dlon_deg / 180.0 * np.pi\n",
    "    lat_rad = lat_deg / 180 * np.pi\n",
    "\n",
    "    ## multiply by radius of earth\n",
    "    R = 6.378e6  # earth radius (meters)\n",
    "    dlon_meters = R * np.cos(lat_rad) * dlon_rad\n",
    "\n",
    "    return dlon_meters\n",
    "\n",
    "\n",
    "def get_dydx(data):\n",
    "    \"\"\"get dy and dx for given data\"\"\"\n",
    "\n",
    "    ## empty array to hold result\n",
    "    grid = xr.Dataset(\n",
    "        coords=dict(\n",
    "            latitude=data[\"latitude\"].values,\n",
    "            longitude=data[\"longitude\"].values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    grid[\"dlat\"] = grid[\"latitude\"].values[1] - grid[\"latitude\"].values[0]\n",
    "    grid[\"dlon\"] = grid[\"longitude\"].values[1] - grid[\"longitude\"].values[0]\n",
    "\n",
    "    grid[\"dlat_rad\"] = grid[\"dlat\"] / 180.0 * np.pi\n",
    "    grid[\"dlon_rad\"] = grid[\"dlon\"] / 180.0 * np.pi\n",
    "    R = 6.378e8  # earth radius (centimeters)\n",
    "\n",
    "    ## height of gridcell doesn't depend on longitude\n",
    "    grid[\"dy\"] = R * grid[\"dlat_rad\"]  # unit: meters\n",
    "    grid[\"dy\"] = grid[\"dy\"] * xr.ones_like(grid[\"latitude\"])\n",
    "\n",
    "    ## Compute width of gridcell\n",
    "    grid[\"lat_rad\"] = grid[\"latitude\"] / 180 * np.pi  # latitude in radians\n",
    "    grid[\"dx\"] = R * np.cos(grid[\"lat_rad\"]) * grid[\"dlon_rad\"]\n",
    "\n",
    "    return grid[[\"dy\", \"dx\"]]\n",
    "\n",
    "\n",
    "def u_dfdx(u, f):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_cm = get_dydx(f)[\"dx\"]\n",
    "    sec_per_year = 86400 * 365\n",
    "    factor = sec_per_year / dx_cm\n",
    "\n",
    "    u_dfdx_ = u * f.differentiate(\"longitude\") * factor\n",
    "\n",
    "    return u_dfdx_\n",
    "\n",
    "\n",
    "def v_dfdy(v, f):\n",
    "    \"\"\"meridional advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dy_cm = get_dydx(f)[\"dy\"]\n",
    "    sec_per_year = 86400 * 365\n",
    "    factor = sec_per_year / dy_cm\n",
    "\n",
    "    v_dfdy_ = v * f.differentiate(\"latitude\") * factor\n",
    "\n",
    "    return v_dfdy_\n",
    "\n",
    "\n",
    "def get_adv(uv, T):\n",
    "    \"\"\"\n",
    "    Compute T tendency from horizontal advection.\n",
    "    Equal to:\n",
    "        (u,v) dot grad(-T)\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute grad T\n",
    "    u_dTdx = u_dfdx(u=uv[\"uvel\"], f=T)\n",
    "    v_dTdy = v_dfdy(v=uv[\"vvel\"], f=T)\n",
    "\n",
    "    ## get\n",
    "\n",
    "    return -(u_dTdx + v_dTdy)\n",
    "\n",
    "\n",
    "def merimean(x):\n",
    "    return x.sel(longitude=slice(140, 285), latitude=slice(-5, 5)).mean(\"latitude\")\n",
    "\n",
    "\n",
    "def plot_cycle_hov(ax, data, amp, is_filled=True, xticks=[190, 240]):\n",
    "    \"\"\"plot data on ax object\"\"\"\n",
    "\n",
    "    ## specify shared kwargs\n",
    "    shared_kwargs = dict(levels=src.utils.make_cb_range(amp, amp / 5), extend=\"both\")\n",
    "\n",
    "    ## specify kwargs\n",
    "    if is_filled:\n",
    "        plot_fn = ax.contourf\n",
    "        kwargs = dict(cmap=\"cmo.balance\")\n",
    "\n",
    "    else:\n",
    "        plot_fn = ax.contour\n",
    "        kwargs = dict(colors=\"k\", linewidths=0.8)\n",
    "\n",
    "    ## average over latitudes (if necessary)\n",
    "    if \"latitude\" in data.coords:\n",
    "        plot_data = merimean(data)\n",
    "    else:\n",
    "        plot_data = data\n",
    "\n",
    "    ## do the plotting\n",
    "    cp = plot_fn(\n",
    "        plot_data.longitude,\n",
    "        plot_data.month,\n",
    "        plot_data,\n",
    "        **kwargs,\n",
    "        **shared_kwargs,\n",
    "    )\n",
    "\n",
    "    ## format ax object\n",
    "    kwargs = dict(c=\"w\", ls=\"--\", lw=1)\n",
    "    ax.set_xlim([145, 280])\n",
    "    ax.set_xlabel(\"Lon\")\n",
    "    ax.set_xticks(xticks)\n",
    "    for tick in xticks:\n",
    "        ax.axvline(tick, **kwargs)\n",
    "\n",
    "    return cp\n",
    "\n",
    "\n",
    "def prep(data):\n",
    "    \"\"\"remove sst dependence and compute tendencies\"\"\"\n",
    "\n",
    "    ## remove SST dependence from SSH field\n",
    "    if \"ssh\" in list(data):\n",
    "        data[\"ssh_hat\"] = src.utils.remove_sst_dependence_v2(\n",
    "            data, h_var=\"ssh\", T_var=\"T_34\"\n",
    "        )\n",
    "        data[\"ssh_hat_comp\"] = data[\"ssh_comp\"]\n",
    "\n",
    "    ## remove from h indices\n",
    "    for h_idx in [\"h_w\", \"h\"]:\n",
    "        data[f\"{h_idx}_hat\"] = src.utils.remove_sst_dependence_v2(\n",
    "            data, h_var=h_idx, T_var=\"T_34\"\n",
    "        )\n",
    "\n",
    "    ## compute tendencies\n",
    "    data = src.utils.get_ddt(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a80a98-3a71-430f-b3ab-d4a6a43afe9d",
   "metadata": {},
   "source": [
    "## initialize cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679fe2a-c229-4d32-8601-2c6cc9ece182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import LocalCluster, Client\n",
    "\n",
    "# cluster = LocalCluster(n_workers=4)\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6f806-7cb2-446a-a9c1-63adc1930685",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81b793-263e-47ed-8a47-72859ffcbe5f",
   "metadata": {},
   "source": [
    "### $T$, $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc268a-e60d-45bb-b68d-acd3860e5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open data\n",
    "Th = src.utils.load_cesm_indices()\n",
    "\n",
    "## rename indices for convenience\n",
    "Th = Th.rename(\n",
    "    {\n",
    "        \"north_tropical_atlantic\": \"natl\",\n",
    "        \"atlantic_nino\": \"nino_atl\",\n",
    "        \"tropical_indian_ocean\": \"iobm\",\n",
    "        \"indian_ocean_dipole\": \"iod\",\n",
    "        \"north_pacific_meridional_mode\": \"npmm\",\n",
    "        \"south_pacific_meridional_mode\": \"spmm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "## load tropical SST avg\n",
    "trop_sst = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/trop_sst.nc\"))\n",
    "\n",
    "## Load T,h (total)\n",
    "Th_total = xr.open_dataset(DATA_FP / \"cesm\" / \"Th.nc\")\n",
    "\n",
    "## compute relative sst\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\"]:\n",
    "    Th[f\"{n}_rel\"] = Th_total[n] - trop_sst[\"trop_sst_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021c452-b3f9-4dbb-bec5-706376791de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ELI data\n",
    "eli = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/eli.nc\"))\n",
    "\n",
    "## get forced/anomalous component\n",
    "eli_forced, eli_anom = src.utils.separate_forced(eli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f711ba-bc31-42a3-9154-6ef25c986fb3",
   "metadata": {},
   "source": [
    "### Spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a20d-d8f0-43dd-9c05-fca1f596d79b",
   "metadata": {},
   "source": [
    "#### MMLEA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62809ad8-327d-4215-af03-7ac255d72a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to EOF data\n",
    "eofs_fp = pathlib.Path(DATA_FP, \"cesm\")\n",
    "\n",
    "## variables to load (and how to rename them)\n",
    "names = [\n",
    "    \"tos\",\n",
    "    \"mlotst\",\n",
    "    \"tauu\",\n",
    "    \"nhf\",\n",
    "]\n",
    "newnames = [\"sst\", \"mld\", \"taux\", \"nhf\"]\n",
    "\n",
    "# ## load the EOFs\n",
    "load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "eofs = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "## for convenience, put spatial patterns / components in single dataset\n",
    "components = xr.merge([eofs_.components().rename(y) for (y, eofs_) in eofs.items()])\n",
    "\n",
    "# reset member dimension so they all match (NHF labeled differently...)\n",
    "member_coord = dict(member=np.arange(100))\n",
    "get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "scores = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs.items()])\n",
    "\n",
    "## convert from stress on atm to stress on ocn\n",
    "scores[\"taux\"].values *= -1\n",
    "\n",
    "## convert MLD from cm to m\n",
    "scores[\"mld\"] = scores[\"mld\"] / 100\n",
    "\n",
    "# ## get forced/anomalous component\n",
    "forced, anom = src.utils.separate_forced(scores)\n",
    "\n",
    "## add T,h information\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\", \"h\", \"h_w\"]:\n",
    "    anom[n] = Th[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc9525-f2f9-404d-bf0a-4a208b90f51a",
   "metadata": {},
   "source": [
    "#### Surface velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba0f94-7dea-4775-9843-aae07d09fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load advection data\n",
    "# uvel_eofs = xr.open_dataset(eofs_fp / \"eofs_uvel.nc\")\n",
    "# vvel_eofs = xr.open_dataset(eofs_fp / \"eofs_vvel.nc\")\n",
    "\n",
    "# ## func to merge u and v data\n",
    "# merge = lambda u, v: xr.merge(\n",
    "#     [\n",
    "#         x.rename(n).drop_vars([\"variable\", \"z_t\"])\n",
    "#         for x, n in zip([u, v], [\"uvel\", \"vvel\"])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ## merge component data\n",
    "# vel_comps = merge(uvel_eofs.components, vvel_eofs.components)\n",
    "# vel_comps = vel_comps.rename({\"uvel\": \"uvel_comp\", \"vvel\": \"vvel_comp\"})\n",
    "\n",
    "# ## interpolate to SST grid for ease\n",
    "# rename_dict = dict(lat=\"latitude\", lon=\"longitude\")\n",
    "# vel_comps = vel_comps.rename(rename_dict).interp_like(components[\"sst\"])\n",
    "\n",
    "# ## merge scores\n",
    "# vel_scores = merge(uvel_eofs.scores, vvel_eofs.scores)\n",
    "# vel_scores = vel_scores.rename({\"member_id\": \"member\"})\n",
    "# vel_scores = vel_scores.assign_coords(dict(member=np.arange(100)))\n",
    "\n",
    "# ## separate forced and anom\n",
    "# vel_forced, vel_anom = src.utils.separate_forced(vel_scores)\n",
    "\n",
    "# ## merge with other data\n",
    "# anom = xr.merge([anom, vel_anom, vel_comps])\n",
    "# forced = xr.merge([forced, vel_forced])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a379a7e-bf35-4100-84c1-7b325b24bb54",
   "metadata": {},
   "source": [
    "#### Subsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a780a-4ded-401d-81d7-465baf4f51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lon_coord(data_sub):\n",
    "    \"\"\"fix longitude coordinate on subsurface data\"\"\"\n",
    "\n",
    "    data_sub = data_sub.assign_coords({\"nlon\": data_sub.lon.isel(z_t=0).values})\n",
    "    data_sub = data_sub.drop_vars(\"lon\").rename({\"nlon\": \"lon\"})\n",
    "\n",
    "    return data_sub\n",
    "\n",
    "\n",
    "def convert_cm_to_m_helper(data, z_coord_name):\n",
    "    \"\"\"convert z-coord from cm to m\"\"\"\n",
    "    return data.assign_coords({z_coord_name: data[z_coord_name].values / 100})\n",
    "\n",
    "\n",
    "def convert_cm_to_m(data):\n",
    "    \"\"\"convert all z-coords from cm to m\"\"\"\n",
    "\n",
    "    ## convert both z-coordinates\n",
    "    for z_coord in [\"z_t\", \"z_w_top\"]:\n",
    "        data = convert_cm_to_m_helper(data, z_coord_name=z_coord)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f9e8e-07ff-4e52-b482-bb80538ac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to EOF data\n",
    "eofs_fp = pathlib.Path(DATA_FP, \"cesm\")\n",
    "\n",
    "## variables to load (and how to rename them)\n",
    "names = [\n",
    "    \"temp\",\n",
    "    \"wvel\",\n",
    "    \"uvel_sub\",\n",
    "]\n",
    "newnames = [\"T\", \"w\", \"u\"]\n",
    "\n",
    "## load the EOFs\n",
    "load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "eofs_sub = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "## for convenience, put spatial patterns / components in single dataset\n",
    "components_sub = xr.merge(\n",
    "    [eofs_.components().rename(y) for (y, eofs_) in eofs_sub.items()]\n",
    ")\n",
    "\n",
    "## fix longitude coord\n",
    "components_sub = fix_lon_coord(components_sub)\n",
    "\n",
    "# reset member dimension so they all match (NHF labeled differently...)\n",
    "member_coord = dict(member_id=np.arange(100))\n",
    "get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "scores_sub = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs_sub.items()])\n",
    "\n",
    "## convert z coords from cm to m\n",
    "components_sub = convert_cm_to_m(components_sub)\n",
    "\n",
    "## convert u and w from cm/s to m/month\n",
    "\n",
    "# conversion factors\n",
    "m_per_cm = 1 / 100\n",
    "s_per_day = 86400\n",
    "s_per_month = s_per_day * 30\n",
    "\n",
    "# do conversion\n",
    "scores_sub[\"w\"] = scores_sub[\"w\"] * m_per_cm * s_per_month\n",
    "scores_sub[\"u\"] = scores_sub[\"u\"] * m_per_cm * s_per_month\n",
    "\n",
    "## get forced/anomalous component\n",
    "forced_sub, anom_sub = src.utils.separate_forced(\n",
    "    scores_sub.rename({\"member_id\": \"member\"})\n",
    ")\n",
    "\n",
    "## add T,h information\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\", \"h\", \"h_w\"]:\n",
    "    anom_sub[n] = Th[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbb125-dac9-4aea-ae0f-6bb5011e3dbc",
   "metadata": {},
   "source": [
    "### Bjerknes coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8eba95-1518-4147-9e7d-bcdec53b18be",
   "metadata": {},
   "source": [
    "#### prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44503c-687d-4ffa-bb70-caa4aede6d45",
   "metadata": {},
   "source": [
    "Add EOF info to surface data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827999b-6078-4e25-a750-2d520f5f06b9",
   "metadata": {},
   "source": [
    "Add eof data to subsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a176d-04f9-497c-a175-0fe877c4235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in list(components):\n",
    "    if f\"{v}_comp\" not in list(anom):\n",
    "        anom[f\"{v}_comp\"] = components[v]\n",
    "\n",
    "## add components to dataset\n",
    "for v in list(components_sub):\n",
    "    if f\"{v}_comp\" not in list(anom_sub):\n",
    "        anom_sub[f\"{v}_comp\"] = components_sub[v]\n",
    "\n",
    "## add sst to dataset\n",
    "if \"sst\" not in list(anom_sub):\n",
    "    anom_sub[\"sst\"] = anom[\"sst\"].isel(time=slice(1, None))\n",
    "    anom_sub[\"sst_comp\"] = anom[\"sst_comp\"]\n",
    "\n",
    "## add taux to dataset\n",
    "if \"taux\" not in list(anom_sub):\n",
    "    anom_sub[\"taux\"] = anom[\"taux\"].isel(time=slice(1, None))\n",
    "    anom_sub[\"taux_comp\"] = anom[\"taux_comp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e6dbb-7d50-4c9a-97f2-996737ea9506",
   "metadata": {},
   "source": [
    "Split into early/late, and compute tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6c536-b8c5-4277-96d7-8840513ec5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into early/late periods\n",
    "t_early = dict(time=slice(\"1851\", \"1880\"))\n",
    "t_late = dict(time=slice(\"2071\", \"2100\"))\n",
    "\n",
    "## split surface data\n",
    "anom_early = anom.sel(t_early)\n",
    "anom_late = anom.sel(t_late)\n",
    "\n",
    "## split subsurface data\n",
    "anom_sub_early = anom_sub.sel(t_early)\n",
    "anom_sub_late = anom_sub.sel(t_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e324d-e82e-496b-b6ef-6ff3647950a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute time derivatives\n",
    "anom_early = prep(anom_early)\n",
    "anom_late = prep(anom_late)\n",
    "\n",
    "anom_sub_early = prep(anom_sub_early)\n",
    "anom_sub_late = prep(anom_sub_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d0029-1362-4e4c-a5a8-1a235edb8d77",
   "metadata": {},
   "source": [
    "#### Mixed layer info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08373b-887d-4a78-ac52-6b866715250e",
   "metadata": {},
   "source": [
    "Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d8346-9fec-4696-a987-f98872b4fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mld_bounds(ax, clim, m):\n",
    "    \"\"\"Plot MLD climatology and ± bounds\"\"\"\n",
    "\n",
    "    ## clim\n",
    "    ax.plot(clim.longitude, clim, c=\"k\")\n",
    "\n",
    "    ## El Niño\n",
    "    ax.plot(clim.longitude, clim + m, c=\"r\")\n",
    "\n",
    "    ## La Niña\n",
    "    ax.plot(clim.longitude, clim - m, c=\"b\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_eq_mld(data):\n",
    "    \"\"\"Get equatorial mixed layer depth\"\"\"\n",
    "\n",
    "    data_ = data.sel(latitude=slice(-1.5, 1.5)).mean(\"latitude\")\n",
    "\n",
    "    return data_.sel(longitude=slice(140, 280))\n",
    "\n",
    "\n",
    "def recon_eq_mld(time_dict):\n",
    "    \"\"\"reconstruct equatorial MLD\"\"\"\n",
    "    return src.utils.reconstruct_fn(\n",
    "        scores=forced[\"mld\"].sel(time_dict).groupby(\"time.month\").mean(),\n",
    "        components=components[\"mld\"],\n",
    "        fn=get_eq_mld,\n",
    "    )\n",
    "\n",
    "\n",
    "## function to plot MLDs\n",
    "def plot_mlds(axs, sel):\n",
    "    axs[0].plot(mld_early.longitude, sel(mld_early), c=\"k\")\n",
    "    axs[1].plot(mld_late.longitude, sel(mld_late), c=\"k\", ls=\"--\")\n",
    "    axs[2].plot(mld_early.longitude, sel(mld_early), c=\"k\")\n",
    "    axs[2].plot(mld_late.longitude, sel(mld_late), c=\"k\", ls=\"--\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81038b96-ca89-47ee-ac47-cf5548ad6ff3",
   "metadata": {},
   "source": [
    "Get mixed layer for early/late periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666b568-5b85-45a8-a7de-b7538c2435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_early = recon_eq_mld(t_early)\n",
    "mld_late = recon_eq_mld(t_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40f01f-d96c-4170-83bc-1f8d95ec47c0",
   "metadata": {},
   "source": [
    "#### Get Tsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b68fc5-428c-4ea0-9df9-bea8431ffab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tsub_early(T):\n",
    "    \"\"\"\n",
    "    get subsurface temperature for early period\n",
    "    \"\"\"\n",
    "    return get_dT_sub(T, mld=mld_early, delta=20)\n",
    "\n",
    "\n",
    "def get_Tsub_recon(data):\n",
    "    \"\"\"get subsurface reconstruction\"\"\"\n",
    "\n",
    "    Tsub = src.utils.reconstruct_fn(\n",
    "        scores=data[\"T\"],\n",
    "        fn=get_Tsub_early,\n",
    "        components=data[\"T_comp\"],\n",
    "    )\n",
    "\n",
    "    return Tsub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8590c-6ece-48e7-87cf-756dd7d0ddb6",
   "metadata": {},
   "source": [
    "## Plot BJ couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6bcbb-8cca-4137-b049-dcaad89de08e",
   "metadata": {},
   "source": [
    "### $\\frac{d T}{d t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774cbf4-502a-4609-85b7-ef1a83f761e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(x_vars=[\"T_34\", \"h_w_hat\"], y_var=\"ddt_T\")\n",
    "\n",
    "m_early = src.utils.multi_regress_bymonth(anom_sub_early, **kwargs)[\"T_34\"]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_sub_late, **kwargs)[\"T_34\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4d431-8406-4f86-b115-b79805eb87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=6)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(10, 1),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(10, 1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-10, 0, 10], label=r\"$K~\\text{yr}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9940a57-390e-40c2-942c-f062770635f2",
   "metadata": {},
   "source": [
    "### Niño 3.4 - SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4299c-a0c1-4278-b1fc-5515cdbc8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared args\n",
    "kwargs = dict(x_vars=[\"T_34\"], y_var=\"sst\")\n",
    "\n",
    "## compute coefs\n",
    "m_early = src.utils.multi_regress_bymonth(anom_early, **kwargs).to_dataarray().squeeze()\n",
    "m_late = src.utils.multi_regress_bymonth(anom_late, **kwargs).to_dataarray().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6b4ee-c481-462a-8665-dd2e3173535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early, amp=1.5)\n",
    "plot_cycle_hov(axs[0], data=m_late, amp=1.5, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late - m_early, amp=0.5)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"Niño 3.4-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(6, c=\"k\", ls=\"--\", lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67ce4a-337f-4d3a-a2ea-fa1a16d52d6b",
   "metadata": {},
   "source": [
    "### SST - NHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf17f54-ac93-461a-b389-8fa9cd9cf7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared args\n",
    "T_var = \"T_34\"\n",
    "kwargs = dict(x_vars=[T_var, \"h_w_hat\"], y_var=\"nhf\")\n",
    "# kwargs = dict(x_vars=[T_var], y_var=\"taux\")\n",
    "\n",
    "## compute coefs\n",
    "m_early = src.utils.multi_regress_bymonth(anom_early, **kwargs)[T_var]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_late, **kwargs)[T_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74150f88-371f-45d2-bc09-66aac7a30ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early, amp=40)\n",
    "plot_cycle_hov(axs[0], data=m_late, amp=40, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late - m_early, amp=20)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"$\\tau_x$-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(7, c=\"k\", ls=\"--\", lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85c11f-9505-4ed7-b691-6b57f81b6baa",
   "metadata": {},
   "source": [
    "### SST-$\\tau_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600dedf-f8b0-41a4-89b2-350b609f5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared args\n",
    "T_var = \"T_34\"\n",
    "kwargs = dict(x_vars=[T_var, \"h_w_hat\"], y_var=\"taux\")\n",
    "# kwargs = dict(x_vars=[T_var], y_var=\"taux\")\n",
    "\n",
    "## compute coefs\n",
    "m_early = src.utils.multi_regress_bymonth(anom_early, **kwargs)[T_var]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_late, **kwargs)[T_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98ff0f-f592-4775-b80e-c9fa346a774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early, amp=0.015)\n",
    "plot_cycle_hov(axs[0], data=m_late, amp=0.015, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late - m_early, amp=0.0075)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"$\\tau_x$-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(6, c=\"k\", ls=\"--\", lw=1)\n",
    "    ax.axvline(160, ls=\"--\", c=\"w\")\n",
    "    ax.axvline(210, ls=\"--\", c=\"w\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab5769-9c9c-4aeb-a3d4-73bc0cd8f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = lambda x: x.sel(month=6, latitude=slice(-5, 5)).mean(\"latitude\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2.5))\n",
    "# ax.plot(m_early.longitude, sel(m_early))\n",
    "# ax.plot(m_early.longitude, sel(m_late))\n",
    "ax.plot(m_early.longitude, sel(m_late - m_early))\n",
    "ax.axhline(0, ls=\"--\", c=\"k\", lw=0.8)\n",
    "ax.set_xlim([140, 280])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd8239-9dca-4e97-af5d-0925d7afc859",
   "metadata": {},
   "source": [
    "### $\\tau_x-T_{sub}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e61df8-01d9-4e00-94c8-723324be6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify T variable\n",
    "T_var = \"T_34\"\n",
    "\n",
    "kwargs = dict(x_vars=[T_var, \"h_w_hat\"], y_var=\"T\")\n",
    "# kwargs = dict(x_vars=[\"nino34\"],  y_var=\"T\")\n",
    "\n",
    "m_early = src.utils.multi_regress_bymonth(anom_sub_early, **kwargs)[T_var]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_sub_late, **kwargs)[T_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc874c7b-027b-4daa-9de5-97f8a7d852f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify max depth for entrainment zone (relative to base of ML)\n",
    "ez_depth = 20\n",
    "\n",
    "## get vertical grad\n",
    "# dT_early = -get_dT_sub(Tsub=m_early, mld=mld_early, delta=ez_depth)\n",
    "# dT_late = -get_dT_sub(Tsub=m_late, mld=mld_late, delta=ez_depth)\n",
    "\n",
    "dT_early = -get_dT_sub(Tsub=m_early, mld=50 * xr.ones_like(mld_early), delta=ez_depth)\n",
    "dT_late = -get_dT_sub(Tsub=m_late, mld=50 * xr.ones_like(mld_early), delta=ez_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d52ef-e941-4cc7-a8ce-031d01ca71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make hövmöllers\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 5), layout=\"constrained\")\n",
    "\n",
    "## kwargs\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\", levels=src.utils.make_cb_range(1e0, 1e-1), extend=\"both\"\n",
    ")\n",
    "cb_kwargs = dict(ticks=[-1, 0, 1], label=r\"$K~/~K$\")\n",
    "\n",
    "## plot early\n",
    "cp0 = src.utils.plot_cycle_hov(axs[0], dT_early, **kwargs)\n",
    "cb0 = fig.colorbar(cp0, ax=axs[0], **cb_kwargs)\n",
    "\n",
    "# ## plot late\n",
    "cp1 = src.utils.plot_cycle_hov(axs[1], dT_late, **kwargs)\n",
    "cb1 = fig.colorbar(cp1, ax=axs[1], **cb_kwargs)\n",
    "\n",
    "## plot difference\n",
    "cp2 = src.utils.plot_cycle_hov(\n",
    "    axs[2],\n",
    "    dT_late - dT_early,\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(0.5e0, 0.5e-1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb2 = fig.colorbar(cp2, ax=axs[2], ticks=[-0.5, 0, 0.5], label=r\"$K~/~K$\")\n",
    "\n",
    "## label\n",
    "axs[0].set_title(\"Early\")\n",
    "axs[1].set_title(\"Late\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "axs[-1].set_xlabel(\"Longitude\")\n",
    "axs[-1].set_xticks([140, 190, 240])\n",
    "axs[-1].axhline(7, c=\"k\", lw=0.8, ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65b5e5-8c3f-4aa0-be70-e858788c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared kwargs\n",
    "kwargs = dict(x_var=\"taux\", y_var=\"T\")\n",
    "\n",
    "## function to get slope\n",
    "get_slope = lambda x, fn_x: x.groupby(\"time.month\").map(\n",
    "    src.utils.regress_proj, fn_x=fn_x, **kwargs\n",
    ")\n",
    "\n",
    "## then, reconstruct regression coefficient\n",
    "# m_early = get_slope(anom_sub_early, fn_x=src.utils.get_nino34)\n",
    "# m_late = get_slope(anom_sub_late, fn_x=src.utils.get_nino34)\n",
    "m_early = get_slope(anom_sub_early, fn_x=src.utils.get_nino4)\n",
    "m_late = get_slope(anom_sub_late, fn_x=src.utils.get_nino4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05e390-47f2-405a-9f3b-44e670f6033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=7)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(200, 20),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(100, 10),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-10, 0, 10], label=r\"$K~\\text{Pa}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51286f7e-0838-4b8c-8be8-326fb5e0e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify max depth for entrainment zone (relative to base of ML)\n",
    "ez_depth = 20\n",
    "\n",
    "## get vertical grad\n",
    "# dT_early = -get_dT_sub(Tsub=m_early, mld=mld_early, delta=ez_depth)\n",
    "# dT_late = -get_dT_sub(Tsub=m_late, mld=mld_late, delta=ez_depth)\n",
    "dT_early = -get_dT_sub(Tsub=m_early, mld=50 * xr.ones_like(mld_early), delta=ez_depth)\n",
    "dT_late = -get_dT_sub(Tsub=m_late, mld=50 * xr.ones_like(mld_early), delta=ez_depth)\n",
    "\n",
    "# dT_early = -get_dT_sub(Tsub=m_early, mld=mld_early, delta=ez_depth)\n",
    "# dT_late = -get_dT_sub(Tsub=m_late, mld=mld_early, delta=ez_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01411c2f-2948-478c-9e3e-fc7e72e20a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make hövmöllers\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 5), layout=\"constrained\")\n",
    "\n",
    "## kwargs\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\", levels=src.utils.make_cb_range(1e2, 1e1), extend=\"both\"\n",
    ")\n",
    "cb_kwargs = dict(ticks=[-100, 0, 100], label=r\"$K~/~Pa$\")\n",
    "\n",
    "## plot early\n",
    "cp0 = src.utils.plot_cycle_hov(axs[0], dT_early, **kwargs)\n",
    "cb0 = fig.colorbar(cp0, ax=axs[0], **cb_kwargs)\n",
    "\n",
    "# ## plot late\n",
    "cp1 = src.utils.plot_cycle_hov(axs[1], dT_late, **kwargs)\n",
    "cb1 = fig.colorbar(cp1, ax=axs[1], **cb_kwargs)\n",
    "\n",
    "## plot difference\n",
    "cp2 = src.utils.plot_cycle_hov(\n",
    "    axs[2],\n",
    "    dT_late - dT_early,\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(5e1, 5e0),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb2 = fig.colorbar(cp2, ax=axs[2], ticks=[-50, 0, 50], label=r\"$K~/~Pa$\")\n",
    "\n",
    "## label\n",
    "axs[0].set_title(\"Early\")\n",
    "axs[1].set_title(\"Late\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "axs[-1].set_xlabel(\"Longitude\")\n",
    "axs[-1].set_xticks([140, 190, 240])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e7e74-9ba9-46f4-ad0a-9c99ed14634b",
   "metadata": {},
   "source": [
    "#### $\\overline{w}~\\frac{\\partial T'}{\\partial z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ad2cb-5276-467f-88bf-cc074523db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clim_sub(t_bnds):\n",
    "    \"\"\"Get climatology for given period\"\"\"\n",
    "\n",
    "    ## get climatology by month\n",
    "    clim_proj = forced_sub.isel(time=slice(*t_bnds)).groupby(\"time.month\").mean()\n",
    "\n",
    "    clim = src.utils.reconstruct_fn(\n",
    "        components=components_sub,\n",
    "        scores=clim_proj,\n",
    "        fn=lambda x: x,\n",
    "    )\n",
    "\n",
    "    return clim\n",
    "\n",
    "\n",
    "clim_sub_early = get_clim_sub((None, 360))\n",
    "clim_sub_late = get_clim_sub((-360, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51afd41-8998-4e23-a1f4-50d545182b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(x_vars=[\"T_34\", \"h_w_hat\"], y_var=\"T\")\n",
    "\n",
    "m_early = src.utils.multi_regress_bymonth(anom_sub_early, **kwargs)[\"T_34\"]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_sub_late, **kwargs)[\"T_34\"]\n",
    "\n",
    "adv_early = get_wdTdz(w=clim_sub_early[\"w\"], T=m_early)\n",
    "adv_late = get_wdTdz(w=clim_sub_late[\"w\"], T=m_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caed31f-ea66-4f38-b61f-c8112af21814",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "sel = lambda x: x.sel(month=6)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, adv in zip(axs[:2], [adv_early, adv_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        adv.lon,\n",
    "        adv.z_t,\n",
    "        sel(adv),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(2, 0.2),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    adv.lon,\n",
    "    adv.z_t,\n",
    "    sel(adv_late - adv_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(1, 0.1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "## plot MLD\n",
    "plot_mlds(axs, sel=sel)\n",
    "\n",
    "## set ax limit and plot Niño 3.4 bounds\n",
    "cb = fig.colorbar(\n",
    "    cp, ax=axs[2], ticks=[-2, 0, 2], label=r\"$K~\\left(\\text{month}\\right)^{-1}$\"\n",
    ")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72b538-14f1-4efd-a4e1-783044f5d874",
   "metadata": {},
   "source": [
    "Integrate over mixed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdf37b-ce4f-4561-8254-3c97e7774f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify MLD\n",
    "H0 = 50\n",
    "\n",
    "## compute\n",
    "# ml_avg_early = get_ml_avg_wrapper(adv_early, mld_early, delta=10)\n",
    "# ml_avg_late = get_ml_avg_wrapper(adv_late, mld_late, delta=10)\n",
    "\n",
    "ml_avg_early = get_ml_avg_wrapper(adv_early, H0 * xr.ones_like(mld_early))\n",
    "ml_avg_late = get_ml_avg_wrapper(adv_late, H0 * xr.ones_like(mld_early))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=ml_avg_early, amp=1)\n",
    "cp1 = plot_cycle_hov(axs[1], data=ml_avg_late, amp=1)\n",
    "cp2 = plot_cycle_hov(axs[2], data=ml_avg_late - ml_avg_early, amp=0.5)\n",
    "\n",
    "## make it look nicer\n",
    "cb = fig.colorbar(\n",
    "    cp0, ax=axs[2], ticks=[-0.4, 0, 0.4], label=r\"$K~\\left(\\text{month}\\right)^{-1}$\"\n",
    ")\n",
    "format_hov_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.axhline(7, ls=\"--\", c=\"k\", lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0607567-6545-4177-840d-17dc21efda6b",
   "metadata": {},
   "source": [
    "#### $w'~\\frac{\\partial \\overline{T}}{\\partial z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64aa347-dfc7-4976-a8e3-5c44fcf2015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(x_vars=[\"T_34\", \"h_w_hat\"], y_var=\"w\")\n",
    "\n",
    "m_early = src.utils.multi_regress_bymonth(anom_sub_early, **kwargs)[\"T_34\"]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_sub_late, **kwargs)[\"T_34\"]\n",
    "\n",
    "adv_early = get_wdTdz(T=clim_sub_early[\"T\"], w=m_early)\n",
    "adv_late = get_wdTdz(T=clim_sub_late[\"T\"], w=m_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9641d-1081-4177-94bc-d11806e4d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify MLD\n",
    "H0 = 50\n",
    "\n",
    "## compute\n",
    "# ml_avg_early = get_ml_avg_wrapper(adv_early, mld_early, delta=10)\n",
    "# ml_avg_late = get_ml_avg_wrapper(adv_late, mld_late, delta=10)\n",
    "\n",
    "ml_avg_early = get_ml_avg_wrapper(adv_early, H0 * xr.ones_like(mld_early), delta=10)\n",
    "ml_avg_late = get_ml_avg_wrapper(adv_late, H0 * xr.ones_like(mld_early), delta=10)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=ml_avg_early, amp=1)\n",
    "cp1 = plot_cycle_hov(axs[1], data=ml_avg_late, amp=1)\n",
    "cp2 = plot_cycle_hov(axs[2], data=ml_avg_late - ml_avg_early, amp=0.5)\n",
    "\n",
    "## make it look nicer\n",
    "cb = fig.colorbar(\n",
    "    cp0, ax=axs[2], ticks=[-0.4, 0, 0.4], label=r\"$K~\\left(\\text{month}\\right)^{-1}$\"\n",
    ")\n",
    "format_hov_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.axhline(6, c=\"k\", ls=\"--\", lw=0.8)\n",
    "    ax.axhline(3, c=\"k\", ls=\"--\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90d4ae-09bb-4072-8639-0a05a8997307",
   "metadata": {},
   "source": [
    "## Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d294509-0588-40b7-8204-6ad0d4cc97c1",
   "metadata": {},
   "source": [
    "### Load heat budget data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597a97d-d7eb-4263-9cc6-fafd5a1f642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to cesm data\n",
    "CESM_FP = DATA_FP / \"cesm\"\n",
    "\n",
    "\n",
    "def load_var(varname):\n",
    "    \"\"\"load variable from prepped folder\"\"\"\n",
    "\n",
    "    data = xr.open_mfdataset(\n",
    "        sorted(list(pathlib.Path(CESM_FP, f\"{varname}_temp\").glob(\"*.nc\"))),\n",
    "        concat_dim=\"member\",\n",
    "        combine=\"nested\",\n",
    "        parallel=True,\n",
    "    )\n",
    "\n",
    "    return data.assign_coords({\"member\": np.arange(100)})\n",
    "\n",
    "\n",
    "## load data\n",
    "# data = xr.merge([load_var(v) for v in [\"uet\", \"adv\", \"wtt\"]])\n",
    "data = xr.merge([load_var(v) for v in [\"adv\", \"ddt_T\"]])\n",
    "\n",
    "# ## update z-coord in WTT\n",
    "# data[\"WTT\"] = (\n",
    "#     data[\"WTT\"].rename({\"z_w_top\": \"z_t\"}).assign_coords({\"z_t\": data.z_t.values})\n",
    "# )\n",
    "# data = data.drop_vars(\"z_w_top\")\n",
    "\n",
    "## convert from cm to m\n",
    "data = data.assign_coords({\"z_t\": data.z_t / 100})\n",
    "\n",
    "## convert from K/s to K/mo\n",
    "SEC_PER_MO = 8.64e4 * 30\n",
    "data[\"ADV_3D_TEMP\"] = data[\"ADV_3D_TEMP\"] * SEC_PER_MO\n",
    "data[\"TEND_TEMP\"] = data[\"TEND_TEMP\"] * SEC_PER_MO\n",
    "data[\"diff\"] = data[\"TEND_TEMP\"] - data[\"ADV_3D_TEMP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c4a95-2912-4925-ba96-f563eaee92cc",
   "metadata": {},
   "source": [
    "### Merge and get forced component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e91e3-b2fa-4f28-83e2-0f1b999a80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge\n",
    "data = xr.merge([data, Th])\n",
    "\n",
    "## get early/late\n",
    "data_early = data.sel(time=slice(\"1850\", \"1879\")).compute()\n",
    "# data_late = data.sel(time=slice(\"1990\", \"2019\")).compute()\n",
    "# data_late = data.sel(time=slice(\"2030\", \"2059\")).compute()\n",
    "data_late = data.sel(time=slice(\"2071\", \"2100\")).compute()\n",
    "\n",
    "## get forced component\n",
    "bud_forced_early, bud_anom_early = src.utils.separate_forced(data_early)\n",
    "bud_forced_late, bud_anom_late = src.utils.separate_forced(data_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099960a8-aa49-4c0d-8be5-22cebc79ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove sst dependence on h variable\n",
    "bud_anom_early = prep(bud_anom_early)\n",
    "bud_anom_late = prep(bud_anom_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21481d8-2036-4a8b-890a-748f10352491",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91421830-7bae-4d9c-91e8-35df4a34332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress(data, y_var, x_vars):\n",
    "    \"\"\"multiple linear regression\"\"\"\n",
    "\n",
    "    ## Get covariates and targets\n",
    "    X = data[x_vars].to_dataarray(dim=\"i\")\n",
    "    Y = data[y_var]\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    YXt = xr.cov(Y, X, dim=[\"member\", \"time\"])\n",
    "    XXt = xr.cov(X, X.rename({\"i\": \"j\"}), dim=[\"member\", \"time\"])\n",
    "\n",
    "    ## invert XX^T\n",
    "    XXt_inv = xr.zeros_like(XXt)\n",
    "    XXt_inv.values = np.linalg.inv(XXt.values)\n",
    "\n",
    "    ## get least-squares fit, YX^T @ (XX^T)^{-1}\n",
    "    m = (YXt * XXt_inv).sum(\"i\")\n",
    "\n",
    "    return m.to_dataset(dim=\"j\")\n",
    "\n",
    "\n",
    "def regress_bymonth(data, y_var, x_vars):\n",
    "    \"\"\"do multiple linear regression for each month separately\"\"\"\n",
    "    return data.groupby(\"time.month\").map(regress, y_var=y_var, x_vars=x_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec34248-31d6-4013-916b-138c92872dd2",
   "metadata": {},
   "source": [
    "#### Temperature tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad87a22-b644-4399-a419-948c0c75cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_VAR = \"T_34\"\n",
    "kwargs = dict(x_vars=[T_VAR, \"h_w_hat\"], y_var=\"TEND_TEMP\")\n",
    "\n",
    "m_early = regress_bymonth(bud_anom_early, **kwargs)[T_VAR]\n",
    "m_late = regress_bymonth(bud_anom_late, **kwargs)[T_VAR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf11ca1-ef53-4e57-80cc-31cd19beece6",
   "metadata": {},
   "source": [
    "Note: this is flux, not divergence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7b9e3-7a7d-4781-9fb3-b5674d9e87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(1.5, 0.15),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(1.5, 0.15),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-1, 0, 1], label=r\"$K~\\text{mo}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de945922-92d8-45be-9b22-60d218953cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_avg_early = get_ml_avg_wrapper(m_early, mld_early, delta=10, H0=50)\n",
    "ml_avg_late = get_ml_avg_wrapper(m_late, mld_late, delta=10, H0=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ffd4b-4e42-4105-b1f2-adac6fda5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=ml_avg_early, amp=1)\n",
    "plot_cycle_hov(axs[0], data=ml_avg_late, amp=1, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=ml_avg_late - ml_avg_early, amp=0.5)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"Temperature tendency\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(3, c=\"k\", ls=\"--\", lw=0.8)\n",
    "    ax.axhline(7, c=\"k\", ls=\"--\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d767b-a0d3-4c3c-8e4e-339e8b3719d1",
   "metadata": {},
   "source": [
    "#### Advective tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5ccfe-28d0-4b9b-a294-e3b7d59547e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_VAR = \"T_34\"\n",
    "\n",
    "kwargs = dict(x_vars=[T_VAR, \"h_w_hat\"], y_var=\"ADV_3D_TEMP\")\n",
    "# kwargs = dict(x_vars=[T_VAR,\"h_w_hat\"], y_var=\"diff\")\n",
    "\n",
    "m_early = regress_bymonth(bud_anom_early, **kwargs)[T_VAR]\n",
    "m_late = regress_bymonth(bud_anom_late, **kwargs)[T_VAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130afbb-dcf1-4caa-86eb-9785947330af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=7)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(2, 0.2),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(2, 0.2),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-1.5, 0, 1.5], label=r\"$K~\\text{mo}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec8d76-17f1-4b94-a50b-3f73abdb3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_avg_early = get_ml_avg_wrapper(m_early, mld_early, delta=0, H0=50)\n",
    "ml_avg_late = get_ml_avg_wrapper(m_late, mld_late, delta=0, H0=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974af49d-316c-40dc-af52-6b38314fcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=ml_avg_early, amp=1)\n",
    "plot_cycle_hov(axs[0], data=ml_avg_late, amp=1, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=ml_avg_late - ml_avg_early, amp=0.5)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"Advection tendency\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(7, c=\"k\", ls=\"--\", lw=0.8)\n",
    "    ax.axhline(3, c=\"k\", ls=\"--\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
