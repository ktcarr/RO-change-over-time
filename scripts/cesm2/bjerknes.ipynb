{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22516693-2eb8-45f7-b9d4-4511a195a408",
   "metadata": {},
   "source": [
    "# Bjerknes feedback changes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e795c63-4ea6-4623-b0a2-e33656d4c420",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d155a1-2906-4d88-9022-b7996ecf7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pathlib\n",
    "import cmocean\n",
    "import os\n",
    "import cartopy.util\n",
    "import copy\n",
    "\n",
    "# Import custom modules\n",
    "import src.utils\n",
    "from src.XRO import XRO, xcorr\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "SAVE_FP = pathlib.Path(os.environ[\"SAVE_FP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382b7b8-eac8-4cf0-8ad1-4632a36727b9",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874f9c6-8fd1-4c20-abb1-98e3e4962768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hov(ax, data, amp, label=None):\n",
    "    \"\"\"Plot hovmoller of longitude vs. year\"\"\"\n",
    "\n",
    "    # kwargs = dict(levels=src.utils.make_cb_range(3, 0.3), cmap=\"cmo.balance\", extend=\"both\")\n",
    "    plot_data = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.year,\n",
    "        data.T,\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"both\",\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "    )\n",
    "    cb = fig.colorbar(\n",
    "        plot_data, orientation=\"horizontal\", ticks=[-amp, 0, amp], label=label\n",
    "    )\n",
    "\n",
    "    ## label\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_xticks([190, 240])\n",
    "        ax.set_yticks([])\n",
    "        ax.axvline(190, **kwargs)\n",
    "        ax.axvline(240, **kwargs)\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_hov2(ax, data, amp, label=None):\n",
    "    \"\"\"Plot hovmoller of longitude vs. year\"\"\"\n",
    "\n",
    "    # kwargs = dict(levels=src.utils.make_cb_range(3, 0.3), cmap=\"cmo.balance\", extend=\"both\")\n",
    "    plot_data = ax.contourf(\n",
    "        data.month,\n",
    "        data.year,\n",
    "        data.T,\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"max\",\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "    )\n",
    "    cb = fig.colorbar(\n",
    "        plot_data,\n",
    "        orientation=\"horizontal\",\n",
    "        ticks=[-amp, 0, amp],\n",
    "        label=label,\n",
    "        # plot_data, orientation=\"horizontal\", ticks=[], label=None\n",
    "    )\n",
    "\n",
    "    ## label\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs:\n",
    "        # ax.set_xlabel(\"Month\")\n",
    "        # ax.set_xticks([1, 12])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_rolling_var(data, n=10):\n",
    "    \"\"\"\n",
    "    Get variance, computing over time and ensemble member. To increase\n",
    "    sample size for variance estimate, compute over time window of 2n+1\n",
    "    years, centered at given year.\n",
    "    \"\"\"\n",
    "\n",
    "    return src.utils.get_rolling_fn_bymonth(data, fn=np.var, n=n)\n",
    "\n",
    "\n",
    "def get_ml_avg(data, Hm, delta=5, H0=None):\n",
    "    \"\"\"func to average data from surface to Hm + delta\"\"\"\n",
    "\n",
    "    ## interpolate MLD onto data grid\n",
    "    Hm_ = Hm.rename({\"longitude\": \"lon\"}).interp({\"lon\": data.lon})\n",
    "\n",
    "    ## tweak integration bounds\n",
    "    if H0 is None:\n",
    "        Hm_ = Hm_ + delta\n",
    "\n",
    "    else:\n",
    "        Hm_ = H0 * xr.ones_like(Hm_)\n",
    "\n",
    "    ## average over everything above the mixed layer\n",
    "    return data.where(data.z_t <= Hm_).mean(\"z_t\")\n",
    "\n",
    "\n",
    "def get_ml_avg_wrapper(data, Hm, delta=5, H0=None):\n",
    "    \"\"\"wrapper function to format data for plotting\"\"\"\n",
    "\n",
    "    ## first, compute mixed layer average\n",
    "    ml_avg = get_ml_avg(data=data, Hm=Hm, delta=delta, H0=H0)\n",
    "\n",
    "    ## rename coord and tranpose\n",
    "    return ml_avg.rename({\"lon\": \"longitude\"}).transpose(\"month\", ...)\n",
    "\n",
    "\n",
    "def plot_mld_bounds(ax, clim, m):\n",
    "    \"\"\"Plot MLD climatology and ± bounds\"\"\"\n",
    "\n",
    "    ## clim\n",
    "    ax.plot(clim.longitude, clim, c=\"k\")\n",
    "\n",
    "    ## El Niño\n",
    "    ax.plot(clim.longitude, clim + m, c=\"r\")\n",
    "\n",
    "    ## La Niña\n",
    "    ax.plot(clim.longitude, clim - m, c=\"b\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_wT(w, T):\n",
    "    \"\"\"function to get vertical flux (handles diff. w/T grids)\"\"\"\n",
    "\n",
    "    ## rename w grid\n",
    "    w_ = copy.deepcopy(w).rename({\"z_w_top\": \"z_t\"})\n",
    "    w_ = w_.assign_coords({\"z_t\": T.z_t})\n",
    "\n",
    "    return w_ * T\n",
    "\n",
    "\n",
    "def get_wdTdz(w, T):\n",
    "    \"\"\"function to get vertical flux (handles diff. w/T grids)\"\"\"\n",
    "\n",
    "    ## rename w grid\n",
    "    w_ = copy.deepcopy(w).rename({\"z_w_top\": \"z_t\"})\n",
    "    w_ = w_.assign_coords({\"z_t\": T.z_t})\n",
    "\n",
    "    ## get dTdz (convert from 1/cm to 1/m)\n",
    "    dTdz = T.differentiate(\"z_t\")\n",
    "\n",
    "    return w_ * dTdz\n",
    "\n",
    "\n",
    "def get_udTdx(u, T):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dlon_deg = T.lon.values[1] - T.lon.values[0]\n",
    "    lat_deg = 0.0\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_m = get_dx(lat_deg=lat_deg, dlon_deg=dlon_deg)\n",
    "\n",
    "    ## differentiate\n",
    "    u_dfdx_ = u * T.differentiate(\"lon\") * 1 / dx_m\n",
    "\n",
    "    return u_dfdx_\n",
    "\n",
    "\n",
    "def get_u_adv(u, T):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dlon_deg = T.lon.values[1] - T.lon.values[0]\n",
    "    lat_deg = 0.0\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_m = get_dx(lat_deg=lat_deg, dlon_deg=dlon_deg)\n",
    "\n",
    "    ## differentiate and convert units to K/yr\n",
    "    u_dfdx_ = u * T.differentiate(\"lon\") * 1 / dx_m\n",
    "\n",
    "    return -u_dfdx_\n",
    "\n",
    "\n",
    "def recon_clim(data, components, varname=\"sst\"):\n",
    "    \"\"\"reconstruct climatology for data\"\"\"\n",
    "\n",
    "    ## get climatolgoy in PC space\n",
    "    monthly_clim = data.groupby(\"time.month\").mean()\n",
    "\n",
    "    ## function to compute equatorial mean\n",
    "    equatorial_mean = lambda x: x.sel(latitude=slice(-2, 2)).mean(\"latitude\")\n",
    "\n",
    "    ## reconstruct\n",
    "    recon = src.utils.reconstruct_fn(\n",
    "        components[varname], monthly_clim[varname], fn=equatorial_mean\n",
    "    )\n",
    "\n",
    "    ## fill zero values with NaN\n",
    "    recon.values[recon.values == 0] = np.nan\n",
    "\n",
    "    return recon\n",
    "\n",
    "\n",
    "def get_monthly_eli(t_bnds):\n",
    "\n",
    "    ## get eli for period\n",
    "    eli_ = eli_forced.isel(time=slice(*t_bnds)).groupby(\"time.month\").mean()\n",
    "\n",
    "    return eli_\n",
    "\n",
    "\n",
    "def get_monthly_eli_std(t_bnds):\n",
    "\n",
    "    ## get eli for period\n",
    "    eli_ = (\n",
    "        eli_anom.isel(time=slice(*t_bnds)).groupby(\"time.month\").std([\"time\", \"member\"])\n",
    "    )\n",
    "\n",
    "    return eli_\n",
    "\n",
    "\n",
    "def plot_cyclic(ax, data, sigma=None, **kwargs):\n",
    "    \"\"\"plot data on hovmoller with cyclic dependence on month\"\"\"\n",
    "\n",
    "    ## add cyclic point\n",
    "    data_cyclic, dim_cyclic = cartopy.util.add_cyclic_point(data, data.month, axis=0)\n",
    "\n",
    "    ## plot data\n",
    "    ax.plot(data_cyclic, dim_cyclic, **kwargs)\n",
    "\n",
    "    ## plot bounds if they exist\n",
    "    if sigma is not None:\n",
    "        sigma_cyclic, _ = cartopy.util.add_cyclic_point(sigma, data.month, axis=0)\n",
    "\n",
    "        ## plot data\n",
    "        ax.plot(data_cyclic + sigma_cyclic, dim_cyclic, **kwargs, lw=0.8)\n",
    "        ax.plot(data_cyclic - sigma_cyclic, dim_cyclic, **kwargs, lw=0.8)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_cyclic_quantiles(ax, data, quantiles=[0.5, 0.15, 0.85], **kwargs):\n",
    "    \"\"\"plot data on hovmoller with cyclic dependence on month\"\"\"\n",
    "\n",
    "    ## compute quantiles\n",
    "    q = data.groupby(\"time.month\").quantile(q=quantiles, dim=[\"time\", \"member\"])\n",
    "    # q = q.rename({\"quantile\":\"q\"})\n",
    "\n",
    "    ## convert to numpy\n",
    "    month = q.month.values\n",
    "    q = q.transpose(\"quantile\", \"month\").values\n",
    "\n",
    "    ## add cyclic point\n",
    "    q_cyclic, dim_cyclic = cartopy.util.add_cyclic_point(q, month, axis=1)\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(q_cyclic[0], dim_cyclic, **kwargs)\n",
    "\n",
    "    ## plot other quantiles\n",
    "    if len(quantiles) > 1:\n",
    "        for j in range(1, len(quantiles)):\n",
    "            ax.plot(q_cyclic[j], dim_cyclic, lw=0.8, **kwargs)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def format_subsurf_axs(axs):\n",
    "    \"\"\"add labels/formatting to 3-panel axs\"\"\"\n",
    "\n",
    "    ## loop thru axs\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(ax.get_ylim()[::-1])\n",
    "        ax.set_xlim([None, 281])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "    axs[0].set_yticks([300, 150, 0])\n",
    "    axs[0].set_ylabel(\"Depth (m)\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def format_hov_axs(axs):\n",
    "    \"\"\"put hovmoller axs in standardized format\"\"\"\n",
    "\n",
    "    ## set fontsize\n",
    "    font_kwargs = dict(size=8)\n",
    "    axs[0].set_ylabel(\"Month\", **font_kwargs)\n",
    "    axs[0].set_title(\"Early\", **font_kwargs)\n",
    "    axs[1].set_title(\"Late\", **font_kwargs)\n",
    "    axs[2].set_title(\"Difference (x2)\", **font_kwargs)\n",
    "\n",
    "    axs[1].set_yticks([])\n",
    "    axs[2].set_yticks([])\n",
    "    axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "\n",
    "    for ax in axs:\n",
    "        # ax.set_xlim([190, None])\n",
    "        ax.set_xticks([190, 240])\n",
    "        ax.axvline(240, ls=\"--\", c=\"w\", lw=1)\n",
    "        ax.axvline(190, ls=\"--\", c=\"w\", lw=1)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_w_int(w):\n",
    "    \"\"\"get vertical velocity integrated over top 200 m\"\"\"\n",
    "    return w.sel(z_w_top=slice(None, 200)).mean(\"z_w_top\")\n",
    "\n",
    "\n",
    "def get_dTdz(Tsub):\n",
    "    \"\"\"get vertical velocity integrated over top 200 m\"\"\"\n",
    "    T_surf = Tsub.sel(z_t=0, method=\"nearest\").squeeze(drop=True)\n",
    "    T_subsurf = Tsub.sel(z_t=200, method=\"nearest\").squeeze(drop=True)\n",
    "\n",
    "    return T_surf - T_subsurf\n",
    "\n",
    "\n",
    "def get_diags(data):\n",
    "    \"\"\"get diagnostics\"\"\"\n",
    "    diags = xr.merge(\n",
    "        [get_dTdz(data[\"T\"]).rename(\"dTdz\"), get_w_int(data[\"w\"]).rename(\"w_int\")]\n",
    "    )\n",
    "    return diags.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "\n",
    "def get_dT_sub(Tsub, mld, delta=25):\n",
    "    \"\"\"get temperature difference b/n mixed layer and entrainment zone\"\"\"\n",
    "\n",
    "    ## interpolate mld to match w\n",
    "    mld_interp = mld.interp({\"longitude\": Tsub.lon.values}).rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    ## subset for non-NaN coords\n",
    "    valid_lon_idx = ~np.isnan(mld_interp).all(\"month\")\n",
    "    mld_interp = mld_interp.isel(lon=valid_lon_idx)\n",
    "    Tsub = Tsub.isel(lon=valid_lon_idx)\n",
    "\n",
    "    ## find indices in ML and entrainment zone (ez)\n",
    "    in_ml = Tsub.z_t <= mld_interp\n",
    "    in_ez = (Tsub.z_t > mld_interp) & (Tsub.z_t < (delta + mld_interp))\n",
    "\n",
    "    ## get Tbar and Tplus (following Frankignoul et al paper)\n",
    "    Tbar = Tsub.where(in_ml).mean(\"z_t\")\n",
    "    Tplus = Tsub.where(in_ez).mean(\"z_t\")\n",
    "\n",
    "    ## get gradient\n",
    "    dT = Tbar - Tplus\n",
    "\n",
    "    return dT.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "\n",
    "def get_dTdz_sub(Tsub, mld, delta=25):\n",
    "    \"\"\"get velocity at base of mixed layer\"\"\"\n",
    "\n",
    "    ## get temperature difference\n",
    "    dT = get_dT_sub(Tsub=Tsub, mld=mld, delta=delta)\n",
    "\n",
    "    ## interpolate mld to match w\n",
    "    mld_interp = mld.interp({\"longitude\": Tsub.lon.values}).rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    ## subset for non-NaN coords\n",
    "    valid_lon_idx = ~np.isnan(mld_interp).all(\"month\")\n",
    "    mld_interp = mld_interp.isel(lon=valid_lon_idx)\n",
    "\n",
    "    ## get gradient\n",
    "    dTdz = dT / mld_interp.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "    return dTdz\n",
    "\n",
    "\n",
    "def get_nino34(data):\n",
    "    return data.sel(lon=slice(190, 240)).mean(\"lon\")\n",
    "\n",
    "\n",
    "def get_w_int_idx(data):\n",
    "    \"\"\"get nino3.4 w-int\"\"\"\n",
    "    return get_nino34(get_w_int(data))\n",
    "\n",
    "\n",
    "def get_dTdz_idx(data):\n",
    "    \"\"\"get nino3.4 w-int\"\"\"\n",
    "    return get_nino34(get_dTdz(data))\n",
    "\n",
    "\n",
    "def eq_avg(x):\n",
    "    return x.sel(latitude=slice(-5, 5), longitude=slice(125, 279)).mean(\"latitude\")\n",
    "\n",
    "\n",
    "def avg_mon_range(data, m0, m1):\n",
    "    \"\"\"average data each year over specified month range\"\"\"\n",
    "\n",
    "    ## find indices for month range\n",
    "    month = data.time.dt.month\n",
    "    is_season = (month >= m0) & (month <= m1)\n",
    "\n",
    "    ## get avg avg\n",
    "    data_season = data.isel(time=is_season).groupby(\"time.year\").mean()\n",
    "\n",
    "    return data_season.rename({\"year\": \"time\"})\n",
    "\n",
    "\n",
    "def get_mam(data):\n",
    "    \"\"\"subset for MAM months\"\"\"\n",
    "\n",
    "    return avg_mon_range(data, m0=3, m1=5)\n",
    "\n",
    "\n",
    "def set_ylims(axs):\n",
    "    lims = np.stack([ax.get_ylim() for ax in axs.flatten()], axis=0)\n",
    "\n",
    "    lb = lims[:, 0].min()\n",
    "    ub = lims[:, 1].max()\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_ylim([lb, ub])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def set_xlims(axs):\n",
    "    lims = np.stack([ax.get_xlim() for ax in axs.flatten()], axis=0)\n",
    "\n",
    "    lb = lims[:, 0].min()\n",
    "    ub = lims[:, 1].max()\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlim([lb, ub])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_dy(dlat_deg):\n",
    "    \"\"\"get spacing between latitudes in meters\"\"\"\n",
    "\n",
    "    ## convert from degrees to radians\n",
    "    dlat_rad = dlat / 180.0 * np.pi\n",
    "\n",
    "    ## multiply by radius of earth\n",
    "    R = 6.378e8  # earth radius (centimeters)\n",
    "    dlat_meters = R * dlat_rad\n",
    "\n",
    "    return dlat_meters\n",
    "\n",
    "\n",
    "def get_dx(lat_deg, dlon_deg):\n",
    "    \"\"\"get spacing between longitudes in meters\"\"\"\n",
    "\n",
    "    ## convert from degrees to radians\n",
    "    dlon_rad = dlon_deg / 180.0 * np.pi\n",
    "    lat_rad = lat_deg / 180 * np.pi\n",
    "\n",
    "    ## multiply by radius of earth\n",
    "    R = 6.378e6  # earth radius (meters)\n",
    "    dlon_meters = R * np.cos(lat_rad) * dlon_rad\n",
    "\n",
    "    return dlon_meters\n",
    "\n",
    "\n",
    "def get_dydx(data):\n",
    "    \"\"\"get dy and dx for given data\"\"\"\n",
    "\n",
    "    ## empty array to hold result\n",
    "    grid = xr.Dataset(\n",
    "        coords=dict(\n",
    "            latitude=data[\"latitude\"].values,\n",
    "            longitude=data[\"longitude\"].values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    grid[\"dlat\"] = grid[\"latitude\"].values[1] - grid[\"latitude\"].values[0]\n",
    "    grid[\"dlon\"] = grid[\"longitude\"].values[1] - grid[\"longitude\"].values[0]\n",
    "\n",
    "    grid[\"dlat_rad\"] = grid[\"dlat\"] / 180.0 * np.pi\n",
    "    grid[\"dlon_rad\"] = grid[\"dlon\"] / 180.0 * np.pi\n",
    "    R = 6.378e8  # earth radius (centimeters)\n",
    "\n",
    "    ## height of gridcell doesn't depend on longitude\n",
    "    grid[\"dy\"] = R * grid[\"dlat_rad\"]  # unit: meters\n",
    "    grid[\"dy\"] = grid[\"dy\"] * xr.ones_like(grid[\"latitude\"])\n",
    "\n",
    "    ## Compute width of gridcell\n",
    "    grid[\"lat_rad\"] = grid[\"latitude\"] / 180 * np.pi  # latitude in radians\n",
    "    grid[\"dx\"] = R * np.cos(grid[\"lat_rad\"]) * grid[\"dlon_rad\"]\n",
    "\n",
    "    return grid[[\"dy\", \"dx\"]]\n",
    "\n",
    "\n",
    "def u_dfdx(u, f):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_cm = get_dydx(f)[\"dx\"]\n",
    "    sec_per_year = 86400 * 365\n",
    "    factor = sec_per_year / dx_cm\n",
    "\n",
    "    u_dfdx_ = u * f.differentiate(\"longitude\") * factor\n",
    "\n",
    "    return u_dfdx_\n",
    "\n",
    "\n",
    "def v_dfdy(v, f):\n",
    "    \"\"\"meridional advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dy_cm = get_dydx(f)[\"dy\"]\n",
    "    sec_per_year = 86400 * 365\n",
    "    factor = sec_per_year / dy_cm\n",
    "\n",
    "    v_dfdy_ = v * f.differentiate(\"latitude\") * factor\n",
    "\n",
    "    return v_dfdy_\n",
    "\n",
    "\n",
    "def get_adv(uv, T):\n",
    "    \"\"\"\n",
    "    Compute T tendency from horizontal advection.\n",
    "    Equal to:\n",
    "        (u,v) dot grad(-T)\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute grad T\n",
    "    u_dTdx = u_dfdx(u=uv[\"uvel\"], f=T)\n",
    "    v_dTdy = v_dfdy(v=uv[\"vvel\"], f=T)\n",
    "\n",
    "    ## get\n",
    "\n",
    "    return -(u_dTdx + v_dTdy)\n",
    "\n",
    "\n",
    "def merimean(x, lat_bound=5):\n",
    "    \"\"\"get meridional mean\"\"\"\n",
    "\n",
    "    ## get bounds for latitude averaging\n",
    "    coords = dict(\n",
    "        longitude=slice(140, 285),\n",
    "        latitude=slice(-lat_bound, lat_bound),\n",
    "    )\n",
    "\n",
    "    return x.sel(coords).mean(\"latitude\")\n",
    "\n",
    "\n",
    "def plot_cycle_hov(ax, data, amp, is_filled=True, xticks=[190, 240], lat_bound=5):\n",
    "    \"\"\"plot data on ax object\"\"\"\n",
    "\n",
    "    ## specify shared kwargs\n",
    "    shared_kwargs = dict(levels=src.utils.make_cb_range(amp, amp / 5), extend=\"both\")\n",
    "\n",
    "    ## specify kwargs\n",
    "    if is_filled:\n",
    "        plot_fn = ax.contourf\n",
    "        kwargs = dict(cmap=\"cmo.balance\")\n",
    "\n",
    "    else:\n",
    "        plot_fn = ax.contour\n",
    "        kwargs = dict(colors=\"k\", linewidths=0.8)\n",
    "\n",
    "    ## average over latitudes (if necessary)\n",
    "    if \"latitude\" in data.coords:\n",
    "        plot_data = merimean(data, lat_bound=lat_bound)\n",
    "    else:\n",
    "        plot_data = data\n",
    "\n",
    "    ## do the plotting\n",
    "    cp = plot_fn(\n",
    "        plot_data.longitude,\n",
    "        plot_data.month,\n",
    "        plot_data,\n",
    "        **kwargs,\n",
    "        **shared_kwargs,\n",
    "    )\n",
    "\n",
    "    ## format ax object\n",
    "    kwargs = dict(c=\"w\", ls=\"--\", lw=1)\n",
    "    ax.set_xlim([145, 280])\n",
    "    ax.set_xlabel(\"Lon\")\n",
    "    ax.set_xticks(xticks)\n",
    "    for tick in xticks:\n",
    "        ax.axvline(tick, **kwargs)\n",
    "\n",
    "    return cp\n",
    "\n",
    "\n",
    "def prep(data):\n",
    "    \"\"\"remove sst dependence and compute tendencies\"\"\"\n",
    "\n",
    "    ## remove from h indices\n",
    "    for h_idx in [\"h_w\", \"h\"]:\n",
    "        data[f\"{h_idx}_hat\"] = src.utils.remove_sst_dependence_v2(\n",
    "            data, h_var=h_idx, T_var=\"T_34\"\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def regress(data, y_var, x_vars):\n",
    "    \"\"\"multiple linear regression\"\"\"\n",
    "\n",
    "    ## Get covariates and targets\n",
    "    X = data[x_vars].to_dataarray(dim=\"i\")\n",
    "    Y = data[y_var]\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    YXt = xr.cov(Y, X, dim=[\"member\", \"time\"])\n",
    "    XXt = xr.cov(X, X.rename({\"i\": \"j\"}), dim=[\"member\", \"time\"])\n",
    "\n",
    "    ## invert XX^T\n",
    "    XXt_inv = xr.zeros_like(XXt)\n",
    "    XXt_inv.values = np.linalg.inv(XXt.values)\n",
    "\n",
    "    ## get least-squares fit, YX^T @ (XX^T)^{-1}\n",
    "    m = (YXt * XXt_inv).sum(\"i\")\n",
    "\n",
    "    return m.to_dataset(dim=\"j\")\n",
    "\n",
    "\n",
    "def regress_bymonth(data, y_var, x_vars):\n",
    "    \"\"\"do multiple linear regression for each month separately\"\"\"\n",
    "    return data.groupby(\"time.month\").map(regress, y_var=y_var, x_vars=x_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a80a98-3a71-430f-b3ab-d4a6a43afe9d",
   "metadata": {},
   "source": [
    "## initialize cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679fe2a-c229-4d32-8601-2c6cc9ece182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import LocalCluster, Client\n",
    "\n",
    "# cluster = LocalCluster(n_workers=4)\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6f806-7cb2-446a-a9c1-63adc1930685",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81b793-263e-47ed-8a47-72859ffcbe5f",
   "metadata": {},
   "source": [
    "### $T$, $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc268a-e60d-45bb-b68d-acd3860e5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open data\n",
    "Th = src.utils.load_cesm_indices()\n",
    "\n",
    "## rename indices for convenience\n",
    "Th = Th.rename(\n",
    "    {\n",
    "        \"north_tropical_atlantic\": \"natl\",\n",
    "        \"atlantic_nino\": \"nino_atl\",\n",
    "        \"tropical_indian_ocean\": \"iobm\",\n",
    "        \"indian_ocean_dipole\": \"iod\",\n",
    "        \"north_pacific_meridional_mode\": \"npmm\",\n",
    "        \"south_pacific_meridional_mode\": \"spmm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "## load tropical SST avg\n",
    "trop_sst = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/trop_sst.nc\"))\n",
    "\n",
    "## Load T,h (total)\n",
    "Th_total = xr.open_dataset(DATA_FP / \"cesm\" / \"Th.nc\")\n",
    "\n",
    "## compute relative sst\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\"]:\n",
    "    Th[f\"{n}_rel\"] = Th_total[n] - trop_sst[\"trop_sst_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021c452-b3f9-4dbb-bec5-706376791de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ELI data\n",
    "eli = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/eli.nc\"))\n",
    "\n",
    "## get forced/anomalous component\n",
    "eli_forced, eli_anom = src.utils.separate_forced(eli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f711ba-bc31-42a3-9154-6ef25c986fb3",
   "metadata": {},
   "source": [
    "### Spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a20d-d8f0-43dd-9c05-fca1f596d79b",
   "metadata": {},
   "source": [
    "#### MMLEA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62809ad8-327d-4215-af03-7ac255d72a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to EOF data\n",
    "eofs_fp = pathlib.Path(DATA_FP, \"cesm\")\n",
    "\n",
    "## variables to load (and how to rename them)\n",
    "names = [\n",
    "    \"tos\",\n",
    "    \"mlotst\",\n",
    "    \"tauu\",\n",
    "    \"nhf\",\n",
    "]\n",
    "newnames = [\"sst\", \"mld\", \"taux\", \"nhf\"]\n",
    "\n",
    "# ## load the EOFs\n",
    "load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "eofs = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "## for convenience, put spatial patterns / components in single dataset\n",
    "components = xr.merge([eofs_.components().rename(y) for (y, eofs_) in eofs.items()])\n",
    "\n",
    "# reset member dimension so they all match (NHF labeled differently...)\n",
    "member_coord = dict(member=np.arange(100))\n",
    "get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "scores = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs.items()])\n",
    "\n",
    "## convert from stress on atm to stress on ocn\n",
    "scores[\"taux\"].values *= -1\n",
    "\n",
    "## convert MLD from cm to m\n",
    "scores[\"mld\"] = scores[\"mld\"] / 100\n",
    "\n",
    "# ## get forced/anomalous component\n",
    "forced, anom = src.utils.separate_forced(scores)\n",
    "\n",
    "## add T,h information\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\", \"h\", \"h_w\"]:\n",
    "    anom[n] = Th[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a379a7e-bf35-4100-84c1-7b325b24bb54",
   "metadata": {},
   "source": [
    "#### Subsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a780a-4ded-401d-81d7-465baf4f51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lon_coord(data_sub):\n",
    "    \"\"\"fix longitude coordinate on subsurface data\"\"\"\n",
    "\n",
    "    data_sub = data_sub.assign_coords({\"nlon\": data_sub.lon.isel(z_t=0).values})\n",
    "    data_sub = data_sub.drop_vars(\"lon\").rename({\"nlon\": \"lon\"})\n",
    "\n",
    "    return data_sub\n",
    "\n",
    "\n",
    "def convert_cm_to_m_helper(data, z_coord_name):\n",
    "    \"\"\"convert z-coord from cm to m\"\"\"\n",
    "    return data.assign_coords({z_coord_name: data[z_coord_name].values / 100})\n",
    "\n",
    "\n",
    "def convert_cm_to_m(data):\n",
    "    \"\"\"convert all z-coords from cm to m\"\"\"\n",
    "\n",
    "    ## convert both z-coordinates\n",
    "    for z_coord in [\"z_t\", \"z_w_top\"]:\n",
    "        data = convert_cm_to_m_helper(data, z_coord_name=z_coord)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f9e8e-07ff-4e52-b482-bb80538ac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to EOF data\n",
    "eofs_fp = pathlib.Path(DATA_FP, \"cesm\")\n",
    "\n",
    "## variables to load (and how to rename them)\n",
    "names = [\n",
    "    \"temp\",\n",
    "    \"wvel\",\n",
    "    \"uvel_sub\",\n",
    "]\n",
    "newnames = [\"T\", \"w\", \"u\"]\n",
    "\n",
    "## load the EOFs\n",
    "load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "eofs_sub = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "## for convenience, put spatial patterns / components in single dataset\n",
    "components_sub = xr.merge(\n",
    "    [eofs_.components().rename(y) for (y, eofs_) in eofs_sub.items()]\n",
    ")\n",
    "\n",
    "## fix longitude coord\n",
    "components_sub = fix_lon_coord(components_sub)\n",
    "\n",
    "# reset member dimension so they all match (NHF labeled differently...)\n",
    "member_coord = dict(member_id=np.arange(100))\n",
    "get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "scores_sub = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs_sub.items()])\n",
    "\n",
    "## convert z coords from cm to m\n",
    "components_sub = convert_cm_to_m(components_sub)\n",
    "\n",
    "## convert u and w from cm/s to m/month\n",
    "\n",
    "# conversion factors\n",
    "m_per_cm = 1 / 100\n",
    "s_per_day = 86400\n",
    "s_per_month = s_per_day * 30\n",
    "\n",
    "# do conversion\n",
    "scores_sub[\"w\"] = scores_sub[\"w\"] * m_per_cm * s_per_month\n",
    "scores_sub[\"u\"] = scores_sub[\"u\"] * m_per_cm * s_per_month\n",
    "\n",
    "## get forced/anomalous component\n",
    "forced_sub, anom_sub = src.utils.separate_forced(\n",
    "    scores_sub.rename({\"member_id\": \"member\"})\n",
    ")\n",
    "\n",
    "## add anomalies to original dataarray\n",
    "for n in list(anom_sub):\n",
    "    anom[n] = anom_sub[n]\n",
    "    components[n] = components_sub[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c65b3c-4f85-4ebb-a567-0b726ff686f6",
   "metadata": {},
   "source": [
    "#### Budget data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f40fd5-5c98-4939-91b3-f5459650e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to cesm data\n",
    "CESM_FP = DATA_FP / \"cesm\"\n",
    "\n",
    "\n",
    "def load_var(varname):\n",
    "    \"\"\"load variable from prepped folder\"\"\"\n",
    "\n",
    "    ## open data\n",
    "    data = xr.open_mfdataset(\n",
    "        sorted(list(pathlib.Path(DATA_FP, \"cesm\", f\"{varname}_temp\").glob(\"*.nc\"))),\n",
    "        concat_dim=\"member\",\n",
    "        combine=\"nested\",\n",
    "        parallel=True,\n",
    "    )\n",
    "\n",
    "    return data.assign_coords({\"member\": np.arange(100)})\n",
    "\n",
    "\n",
    "## load data\n",
    "budget_data = xr.merge([load_var(v) for v in [\"adv\", \"ddt_T\"]])\n",
    "\n",
    "## get difference\n",
    "budget_data[\"diff\"] = budget_data[\"TEND_TEMP\"] - budget_data[\"ADV_3D_TEMP\"]\n",
    "\n",
    "## convert z coord from cm to m, and unit from K/s to K/mo\n",
    "M_PER_CM = 1e-2\n",
    "SEC_PER_MO = 8.64e4 * 30\n",
    "\n",
    "## convert from (i) cm to m and (ii) K/s to K/mo\n",
    "budget_data = budget_data.assign_coords({\"z_t\": budget_data.z_t * M_PER_CM})\n",
    "budget_data = budget_data * SEC_PER_MO\n",
    "\n",
    "## fix longitude coordinate\n",
    "budget_data = budget_data.assign_coords({\"nlon\": budget_data.lon.values})\n",
    "budget_data = budget_data.drop_vars(\"lon\").rename({\"nlon\": \"lon\"})\n",
    "\n",
    "## trim in time and load to memory\n",
    "t_idx = np.concatenate([np.arange(0, 480), np.arange(3012 - 480, 3012)])\n",
    "budget_data = budget_data.isel(time=t_idx).compute()\n",
    "\n",
    "## separate forced/anomalies\n",
    "forced_bud, anom_bud = src.utils.separate_forced(budget_data)\n",
    "\n",
    "## add anomalies to data\n",
    "for n in list(anom_bud):\n",
    "    anom[n] = anom_bud[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbb125-dac9-4aea-ae0f-6bb5011e3dbc",
   "metadata": {},
   "source": [
    "## Bjerknes coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8eba95-1518-4147-9e7d-bcdec53b18be",
   "metadata": {},
   "source": [
    "#### prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44503c-687d-4ffa-bb70-caa4aede6d45",
   "metadata": {},
   "source": [
    "Add EOF info to surface data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827999b-6078-4e25-a750-2d520f5f06b9",
   "metadata": {},
   "source": [
    "Add eof data to subsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a176d-04f9-497c-a175-0fe877c4235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in list(components):\n",
    "    if f\"{v}_comp\" not in list(anom):\n",
    "        anom[f\"{v}_comp\"] = components[v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e6dbb-7d50-4c9a-97f2-996737ea9506",
   "metadata": {},
   "source": [
    "Split into early/late, and compute tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1016e13-f341-4406-bf74-effd6083d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into early/late periods\n",
    "t_early = dict(time=slice(\"1851\", \"1880\"))\n",
    "t_late = dict(time=slice(\"2071\", \"2100\"))\n",
    "\n",
    "## split surface data\n",
    "anom_early = anom.sel(t_early)\n",
    "anom_late = anom.sel(t_late)\n",
    "\n",
    "## remove ssh dependence\n",
    "anom_early = prep(anom_early)\n",
    "anom_late = prep(anom_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d0029-1362-4e4c-a5a8-1a235edb8d77",
   "metadata": {},
   "source": [
    "#### Mixed layer info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08373b-887d-4a78-ac52-6b866715250e",
   "metadata": {},
   "source": [
    "Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d8346-9fec-4696-a987-f98872b4fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mld_bounds(ax, clim, m):\n",
    "    \"\"\"Plot MLD cli|matology and ± bounds\"\"\"\n",
    "\n",
    "    ## clim\n",
    "    ax.plot(clim.longitude, clim, c=\"k\")\n",
    "\n",
    "    ## El Niño\n",
    "    ax.plot(clim.longitude, clim + m, c=\"r\")\n",
    "\n",
    "    ## La Niña\n",
    "    ax.plot(clim.longitude, clim - m, c=\"b\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_eq_mld(data):\n",
    "    \"\"\"Get equatorial mixed layer depth\"\"\"\n",
    "\n",
    "    data_ = data.sel(latitude=slice(-1.5, 1.5)).mean(\"latitude\")\n",
    "\n",
    "    return data_.sel(longitude=slice(140, 280))\n",
    "\n",
    "\n",
    "def recon_eq_mld(time_dict):\n",
    "    \"\"\"reconstruct equatorial MLD\"\"\"\n",
    "    return src.utils.reconstruct_fn(\n",
    "        scores=forced[\"mld\"].sel(time_dict).groupby(\"time.month\").mean(),\n",
    "        components=components[\"mld\"],\n",
    "        fn=get_eq_mld,\n",
    "    )\n",
    "\n",
    "\n",
    "## function to plot MLDs\n",
    "def plot_mlds(axs, sel):\n",
    "    axs[0].plot(mld_early.longitude, sel(mld_early), c=\"k\")\n",
    "    axs[1].plot(mld_late.longitude, sel(mld_late), c=\"k\", ls=\"--\")\n",
    "    axs[2].plot(mld_early.longitude, sel(mld_early), c=\"k\")\n",
    "    axs[2].plot(mld_late.longitude, sel(mld_late), c=\"k\", ls=\"--\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81038b96-ca89-47ee-ac47-cf5548ad6ff3",
   "metadata": {},
   "source": [
    "Get mixed layer for early/late periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666b568-5b85-45a8-a7de-b7538c2435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_early = recon_eq_mld(t_early)\n",
    "mld_late = recon_eq_mld(t_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40f01f-d96c-4170-83bc-1f8d95ec47c0",
   "metadata": {},
   "source": [
    "#### Get Tsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b68fc5-428c-4ea0-9df9-bea8431ffab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tsub_early(T):\n",
    "    \"\"\"\n",
    "    get subsurface temperature for early period\n",
    "    \"\"\"\n",
    "    return get_dT_sub(T, mld=mld_early, delta=20)\n",
    "\n",
    "\n",
    "def get_Tsub_recon(data):\n",
    "    \"\"\"get subsurface reconstruction\"\"\"\n",
    "\n",
    "    Tsub = src.utils.reconstruct_fn(\n",
    "        scores=data[\"T\"],\n",
    "        fn=get_Tsub_early,\n",
    "        components=data[\"T_comp\"],\n",
    "    )\n",
    "\n",
    "    return Tsub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c8419-cae2-428a-8667-7e9827734a4e",
   "metadata": {},
   "source": [
    "### Compute BJ coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf7cdf-04d9-47c4-a3bd-7c6799abca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clim_sub(t_dict):\n",
    "    \"\"\"Get climatology for given period\"\"\"\n",
    "\n",
    "    ## get climatology by month\n",
    "    clim_proj = forced_sub.sel(t_dict).groupby(\"time.month\").mean()\n",
    "\n",
    "    clim = src.utils.reconstruct_fn(\n",
    "        components=components_sub,\n",
    "        scores=clim_proj,\n",
    "        fn=lambda x: x,\n",
    "    )\n",
    "\n",
    "    return clim\n",
    "\n",
    "\n",
    "clim_sub_early = get_clim_sub(t_early)\n",
    "clim_sub_late = get_clim_sub(t_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbeffd-ca64-43a3-994a-6f34f18e30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(y_var, data, x_vars=[\"T_34\", \"h_w_hat\"]):\n",
    "    \"\"\"fit linear regression model to data\"\"\"\n",
    "\n",
    "    ## infer T variable\n",
    "    T_var = x_vars[0]\n",
    "\n",
    "    ## get coeffs\n",
    "    kwargs = dict(y_var=y_var, x_vars=x_vars)\n",
    "    coefs = src.utils.multi_regress_bymonth(data, **kwargs)\n",
    "\n",
    "    return coefs[T_var]\n",
    "\n",
    "\n",
    "def fit_early(**kwargs):\n",
    "    \"\"\"convenience func to fit to early data\"\"\"\n",
    "    return fit(data=anom_early, **kwargs)\n",
    "\n",
    "\n",
    "def fit_late(**kwargs):\n",
    "    \"\"\"convenience func to fit to early data\"\"\"\n",
    "    return fit(data=anom_late, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d13256-39e2-440c-82a7-811569d60a07",
   "metadata": {},
   "source": [
    "Compute things which don't depend on MLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7740cb-9158-4cd9-87b4-2ce70a066434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## empty datasets to hold results\n",
    "m_early = xr.Dataset()\n",
    "m_late = xr.Dataset()\n",
    "\n",
    "\n",
    "## compute regression coefficients for given variables\n",
    "for n in tqdm.tqdm([\"sst\", \"nhf\", \"taux\", \"T\", \"w\", \"u\"]):\n",
    "    m_early[n] = fit_early(y_var=n)\n",
    "    m_late[n] = fit_late(y_var=n)\n",
    "\n",
    "\n",
    "## taux-Tsub\n",
    "kwargs = dict(x_var=\"taux\", y_var=\"T\")\n",
    "get_slope = lambda x, fn_x: x.groupby(\"time.month\").map(\n",
    "    src.utils.regress_proj, fn_x=fn_x, **kwargs\n",
    ")\n",
    "m_early[\"taux_T\"] = get_slope(anom_early, fn_x=src.utils.get_nino4)\n",
    "m_late[\"taux_T\"] = get_slope(anom_late, fn_x=src.utils.get_nino4)\n",
    "\n",
    "## Thermocline feedback\n",
    "m_early[\"THF\"] = get_wdTdz(w=clim_sub_early[\"w\"], T=m_early[\"T\"])\n",
    "m_late[\"THF\"] = get_wdTdz(w=clim_sub_late[\"w\"], T=m_late[\"T\"])\n",
    "\n",
    "## Ekman feedback\n",
    "m_early[\"EKM\"] = get_wdTdz(T=clim_sub_early[\"T\"], w=m_early[\"w\"])\n",
    "m_late[\"EKM\"] = get_wdTdz(T=clim_sub_late[\"T\"], w=m_late[\"w\"])\n",
    "\n",
    "## zonal advective feedback and dynamical damping\n",
    "m_early[\"ZAF\"] = get_u_adv(T=clim_sub_early[\"T\"], u=m_early[\"u\"])\n",
    "m_early[\"DD\"] = get_u_adv(T=m_early[\"T\"], u=clim_sub_early[\"u\"])\n",
    "m_late[\"ZAF\"] = get_u_adv(T=clim_sub_late[\"T\"], u=m_late[\"u\"])\n",
    "m_late[\"DD\"] = get_u_adv(T=m_late[\"T\"], u=clim_sub_late[\"u\"])\n",
    "\n",
    "## Decompose changes in Ekman feedback\n",
    "delta_w = m_late[\"w\"] - m_early[\"w\"]\n",
    "delta_T = clim_sub_late[\"T\"] - clim_sub_early[\"T\"]\n",
    "m_late[\"delta_EKM_mean\"] = get_wdTdz(T=delta_T, w=m_early[\"w\"])\n",
    "m_late[\"delta_EKM_anom\"] = get_wdTdz(T=clim_sub_early[\"T\"], w=delta_w)\n",
    "m_late[\"delta_EKM_nl\"] = get_wdTdz(T=delta_T, w=delta_w)\n",
    "\n",
    "## Decompose changes in Thermocline feedback\n",
    "delta_w = clim_sub_late[\"w\"] - clim_sub_early[\"w\"]\n",
    "delta_T = m_late[\"T\"] - m_early[\"T\"]\n",
    "m_late[\"delta_THF_mean\"] = get_wdTdz(T=m_early[\"T\"], w=delta_w)\n",
    "m_late[\"delta_THF_anom\"] = get_wdTdz(T=delta_T, w=clim_sub_early[\"w\"])\n",
    "m_late[\"delta_THF_nl\"] = get_wdTdz(T=delta_T, w=delta_w)\n",
    "\n",
    "## sum up\n",
    "for m in [m_early, m_late]:\n",
    "    m[\"ADV\"] = m[\"THF\"] + m[\"EKM\"] + m[\"ZAF\"] + m[\"DD\"]\n",
    "\n",
    "## get ground truth tendencies\n",
    "for n in [\"TEND_TEMP\", \"ADV_3D_TEMP\"]:\n",
    "\n",
    "    kwargs = dict(x_vars=[\"T_34\", \"h_w_hat\"], y_var=n)\n",
    "    m_early[n] = regress_bymonth(anom_early, **kwargs)[\"T_34\"]\n",
    "    m_late[n] = regress_bymonth(anom_late, **kwargs)[\"T_34\"]\n",
    "\n",
    "## get difference\n",
    "m_early[\"diff\"] = m_early[\"TEND_TEMP\"] - m_early[\"ADV_3D_TEMP\"]\n",
    "m_late[\"diff\"] = m_late[\"TEND_TEMP\"] - m_late[\"ADV_3D_TEMP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5b892-3f81-4573-9ed9-3be1ca5ba748",
   "metadata": {},
   "source": [
    "Compute things which *do* depend on MLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62934502-affe-4245-a6a3-9a7a6c79bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## should we use fixed depth MLD?\n",
    "USE_FIXED_MLD = True\n",
    "\n",
    "if USE_FIXED_MLD:\n",
    "    H0 = 70\n",
    "    Hm_early = H0 * xr.ones_like(mld_early)\n",
    "    Hm_late = H0 * xr.ones_like(mld_late)\n",
    "    delta = 0\n",
    "\n",
    "else:\n",
    "    # Hm_early = mld_early\n",
    "    # Hm_late = mld_late\n",
    "    Hm_early = 70 * xr.ones_like(mld_early)\n",
    "    Hm_late = 50 * xr.ones_like(mld_late)\n",
    "    delta = 15\n",
    "\n",
    "## height of entrainment zone (from base of ML)\n",
    "ez_height = 20\n",
    "\n",
    "## other subsurface vars\n",
    "update_lon = lambda x: x.interp({\"longitude\": m_early.longitude})\n",
    "\n",
    "## T_ml - T_sub (regr on Niño 3.4 and taux)\n",
    "fit_Tsub = lambda **kwargs: update_lon(-get_dT_sub(**kwargs, delta=ez_height))\n",
    "m_early[\"dT_n34\"] = fit_Tsub(Tsub=m_early[\"T\"], mld=Hm_early)\n",
    "m_late[\"dT_n34\"] = fit_Tsub(Tsub=m_late[\"T\"], mld=Hm_late)\n",
    "m_early[\"dT_taux\"] = fit_Tsub(Tsub=m_early[\"taux_T\"], mld=Hm_early)\n",
    "m_late[\"dT_taux\"] = fit_Tsub(Tsub=m_late[\"taux_T\"], mld=Hm_late)\n",
    "\n",
    "## Integrate over mixed layer\n",
    "for v in list(m_early):\n",
    "    if \"z_t\" in m_early[v].coords:\n",
    "        m_early[f\"{v}_ml\"] = update_lon(\n",
    "            get_ml_avg_wrapper(m_early[v], Hm=Hm_early, delta=delta)\n",
    "        )\n",
    "for v in list(m_late):\n",
    "    if \"z_t\" in m_late[v].coords:\n",
    "        m_late[f\"{v}_ml\"] = update_lon(\n",
    "            get_ml_avg_wrapper(m_late[v], Hm=Hm_late, delta=delta)\n",
    "        )\n",
    "\n",
    "## get d/dt(SST)\n",
    "m_early[\"ddt_sst\"] = update_lon(\n",
    "    m_early[\"TEND_TEMP\"].rename({\"lon\": \"longitude\"}).isel(z_t=0)\n",
    ")\n",
    "m_late[\"ddt_sst\"] = update_lon(\n",
    "    m_late[\"TEND_TEMP\"].rename({\"lon\": \"longitude\"}).isel(z_t=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171dc450-f2c9-442a-9218-4c4125b3774a",
   "metadata": {},
   "source": [
    "### Feedback hovmollers \n",
    "E.g., thermocline ($\\overline{w}~\\frac{\\partial T'}{\\partial z}$) and Ekman feedback ($w'~\\frac{\\partial \\overline{T}}{\\partial z}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675e54e-f080-4906-9092-4b27037d453e",
   "metadata": {},
   "source": [
    "##### Plot mixed layer integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdf37b-ce4f-4561-8254-3c97e7774f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify plot amplitude\n",
    "amp = 1\n",
    "\n",
    "for n in [\"THF_ml\", \"EKM_ml\", \"ADV_ml\", \"ADV_3D_TEMP_ml\", \"ddt_sst\", \"diff_ml\"]:\n",
    "    # for n in [\"THF_ml\", \"EKM_ml\", \"ZAF_ml\", \"DD_ml\", \"ADV_ml\", \"ADV_3D_TEMP_ml\", \"ddt_sst\"]:\n",
    "\n",
    "    print(f\"\\n{n}\")\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(6, 2.5), layout=\"constrained\")\n",
    "\n",
    "    ## plot data\n",
    "    cp0 = plot_cycle_hov(axs[0], data=m_early[n], amp=amp)\n",
    "    cp1 = plot_cycle_hov(axs[1], data=m_late[n], amp=amp)\n",
    "    cp2 = plot_cycle_hov(axs[2], data=(m_late - m_early)[n], amp=amp * 0.75)\n",
    "\n",
    "    ## make it look nicer\n",
    "    cb = fig.colorbar(\n",
    "        cp0,\n",
    "        ax=axs[2],\n",
    "        ticks=[-amp, 0, amp],\n",
    "        label=r\"$K~\\left(\\text{month}\\right)^{-1}$\",\n",
    "    )\n",
    "    format_hov_axs(axs)\n",
    "    for ax in axs:\n",
    "        ax.axhline(7, ls=\"--\", c=\"k\", lw=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f2133-4cf6-4e96-a101-05128ab2a51e",
   "metadata": {},
   "source": [
    "##### Decompose changes in Ekman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca046b9-03d8-44c6-af1a-8fe1863230dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify colorbar amp\n",
    "amp = 0.5\n",
    "\n",
    "## specify plot data and titles\n",
    "plot_data = [\n",
    "    (m_late - m_early)[\"EKM_ml\"],\n",
    "    m_late[\"delta_EKM_mean_ml\"],\n",
    "    m_late[\"delta_EKM_anom_ml\"],\n",
    "    m_late[\"delta_EKM_nl_ml\"],\n",
    "]\n",
    "titles = [\n",
    "    r\"$\\Delta\\left(w~\\frac{\\partial \\overline{T}}{\\partial z}\\right)$\",\n",
    "    r\"$w_0'~\\Delta\\left(\\frac{\\partial \\overline{T}}{\\partial z}\\right)$\",\n",
    "    r\"$\\Delta\\left(w'\\right)~\\frac{\\partial \\overline{T}_0}{\\partial z}$\",\n",
    "    r\"$\\Delta\\left(w'\\right)~\\Delta\\left(\\frac{\\partial \\overline{T}}{\\partial z}\\right)$\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "format_hov_axs(axs)\n",
    "\n",
    "## plot data\n",
    "for ax, p, t in zip(axs, plot_data, titles):\n",
    "    cp = plot_cycle_hov(ax, data=p, amp=amp)\n",
    "    ax.set_title(t)\n",
    "    ax.axhline(7, ls=\"--\", c=\"k\", lw=1)\n",
    "\n",
    "for ax in axs[3:]:\n",
    "    ax.set_yticks([])\n",
    "\n",
    "## make it look nicer\n",
    "cb = fig.colorbar(\n",
    "    cp,\n",
    "    ax=axs[-1],\n",
    "    ticks=[-amp, 0, amp],\n",
    "    label=r\"$K~\\left(\\text{month}\\right)^{-1}$\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76bf3d-1b57-4420-ad2f-82764f73a1f1",
   "metadata": {},
   "source": [
    "##### Decompose changes in thermocline feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed9ef0-a0fb-46f4-aac8-08abf5085907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify colorbar amp\n",
    "amp = 0.5\n",
    "\n",
    "## specify plot data and titles\n",
    "plot_data = [\n",
    "    (m_late - m_early)[\"THF_ml\"],\n",
    "    m_late[\"delta_THF_mean_ml\"],\n",
    "    m_late[\"delta_THF_anom_ml\"],\n",
    "    m_late[\"delta_THF_nl_ml\"],\n",
    "]\n",
    "titles = [\n",
    "    r\"$\\Delta\\left(\\overline{w}~\\frac{\\partial T'}{\\partial z}\\right)$\",\n",
    "    r\"$\\Delta\\left(\\overline{w}\\right)~\\frac{\\partial T_0}{\\partial z}$\",\n",
    "    r\"$\\overline{w}_0~\\Delta\\left(\\frac{\\partial T'}{\\partial z}\\right)$\",\n",
    "    r\"$\\Delta\\left(\\overline{w}\\right)~\\Delta\\left(\\frac{\\partial T'}{\\partial z}\\right)$\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "format_hov_axs(axs)\n",
    "\n",
    "## plot data\n",
    "for ax, p, t in zip(axs, plot_data, titles):\n",
    "    cp = plot_cycle_hov(ax, data=p, amp=amp)\n",
    "    ax.set_title(t)\n",
    "    ax.axhline(7, ls=\"--\", c=\"k\", lw=1)\n",
    "\n",
    "for ax in axs[3:]:\n",
    "    ax.set_yticks([])\n",
    "\n",
    "## make it look nicer\n",
    "cb = fig.colorbar(\n",
    "    cp,\n",
    "    ax=axs[-1],\n",
    "    ticks=[-amp, 0, amp],\n",
    "    label=r\"$K~\\left(\\text{month}\\right)^{-1}$\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8590c-6ece-48e7-87cf-756dd7d0ddb6",
   "metadata": {},
   "source": [
    "### Plot BJ couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9940a57-390e-40c2-942c-f062770635f2",
   "metadata": {},
   "source": [
    "#### Niño 3.4 - SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6b4ee-c481-462a-8665-dd2e3173535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early[\"sst\"], amp=2, lat_bound=1.5)\n",
    "plot_cycle_hov(axs[0], data=m_late[\"sst\"], amp=2, is_filled=False, lat_bound=1.5)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late[\"sst\"] - m_early[\"sst\"], amp=1, lat_bound=1.5)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"Niño 3.4-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(6, c=\"k\", ls=\"--\", lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67ce4a-337f-4d3a-a2ea-fa1a16d52d6b",
   "metadata": {},
   "source": [
    "### SST - NHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74150f88-371f-45d2-bc09-66aac7a30ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early[\"nhf\"], amp=40, lat_bound=1.5)\n",
    "plot_cycle_hov(axs[0], data=m_late[\"nhf\"], amp=40, lat_bound=1.5, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late[\"nhf\"] - m_early[\"nhf\"], amp=20, lat_bound=1.5)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"$NHF$-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(7, c=\"k\", ls=\"--\", lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85c11f-9505-4ed7-b691-6b57f81b6baa",
   "metadata": {},
   "source": [
    "### SST-$\\tau_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98ff0f-f592-4775-b80e-c9fa346a774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early[\"taux\"], amp=0.015)\n",
    "plot_cycle_hov(axs[0], data=m_late[\"taux\"], amp=0.015, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late[\"taux\"] - m_early[\"taux\"], amp=0.0075)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"$\\tau_x$-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(6, c=\"k\", ls=\"--\", lw=1)\n",
    "    ax.axvline(160, ls=\"--\", c=\"w\")\n",
    "    ax.axvline(210, ls=\"--\", c=\"w\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab5769-9c9c-4aeb-a3d4-73bc0cd8f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = lambda x: x.sel(month=6, latitude=slice(-5, 5)).mean(\"latitude\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2.5))\n",
    "ax.plot(m_early[\"taux\"].longitude, sel(m_late[\"taux\"] - m_early[\"taux\"]))\n",
    "ax.axhline(0, ls=\"--\", c=\"k\", lw=0.8)\n",
    "ax.set_xlim([140, 280])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd8239-9dca-4e97-af5d-0925d7afc859",
   "metadata": {},
   "source": [
    "### $T_{sub}-$Niño3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d52ef-e941-4cc7-a8ce-031d01ca71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper func to update longitude coord\n",
    "sel_data = lambda x: x[\"dT_n34\"]\n",
    "\n",
    "## make hövmöllers\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 5), layout=\"constrained\")\n",
    "\n",
    "## kwargs\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\", levels=src.utils.make_cb_range(1e0, 1e-1), extend=\"both\"\n",
    ")\n",
    "cb_kwargs = dict(ticks=[-1, 0, 1], label=r\"$K~/~K$\")\n",
    "\n",
    "## plot early\n",
    "cp0 = src.utils.plot_cycle_hov(axs[0], sel_data(m_early), **kwargs)\n",
    "cb0 = fig.colorbar(cp0, ax=axs[0], **cb_kwargs)\n",
    "\n",
    "# ## plot late\n",
    "cp1 = src.utils.plot_cycle_hov(axs[1], sel_data(m_late), **kwargs)\n",
    "cb1 = fig.colorbar(cp1, ax=axs[1], **cb_kwargs)\n",
    "\n",
    "## plot difference\n",
    "cp2 = src.utils.plot_cycle_hov(\n",
    "    axs[2],\n",
    "    sel_data(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(0.5e0, 0.5e-1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb2 = fig.colorbar(cp2, ax=axs[2], ticks=[-0.5, 0, 0.5], label=r\"$K~/~K$\")\n",
    "\n",
    "## label\n",
    "axs[0].set_title(\"Early\")\n",
    "axs[1].set_title(\"Late\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "axs[-1].set_xlabel(\"Longitude\")\n",
    "axs[-1].set_xticks([140, 190, 240])\n",
    "axs[-1].axhline(7, c=\"k\", lw=0.8, ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc638aaf-8853-43f7-9ebc-34ba9de06bbe",
   "metadata": {},
   "source": [
    "### $T_{sub}-\\tau_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05e390-47f2-405a-9f3b-44e670f6033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=7)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m[\"taux_T\"]),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(200, 20),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early)[\"taux_T\"],\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(100, 10),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-10, 0, 10], label=r\"$K~\\text{Pa}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01411c2f-2948-478c-9e3e-fc7e72e20a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper func to update longitude coord\n",
    "sel_data = lambda x: x[\"dT_taux\"]\n",
    "\n",
    "## make hövmöllers\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 5), layout=\"constrained\")\n",
    "\n",
    "## kwargs\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\", levels=src.utils.make_cb_range(1e2, 1e1), extend=\"both\"\n",
    ")\n",
    "cb_kwargs = dict(ticks=[-100, 0, 100], label=r\"$K~/~Pa$\")\n",
    "\n",
    "## plot early\n",
    "cp0 = src.utils.plot_cycle_hov(axs[0], sel_data(m_early), **kwargs)\n",
    "cb0 = fig.colorbar(cp0, ax=axs[0], **cb_kwargs)\n",
    "\n",
    "# ## plot late\n",
    "cp1 = src.utils.plot_cycle_hov(axs[1], sel_data(m_late), **kwargs)\n",
    "cb1 = fig.colorbar(cp1, ax=axs[1], **cb_kwargs)\n",
    "\n",
    "## plot difference\n",
    "cp2 = src.utils.plot_cycle_hov(\n",
    "    axs[2],\n",
    "    sel_data(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(5e1, 5e0),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb2 = fig.colorbar(cp2, ax=axs[2], ticks=[-50, 0, 50], label=r\"$K~/~Pa$\")\n",
    "\n",
    "## label\n",
    "axs[0].set_title(\"Early\")\n",
    "axs[1].set_title(\"Late\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "axs[-1].set_xlabel(\"Longitude\")\n",
    "axs[-1].set_xticks([140, 190, 240])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f7674-7ef3-44b0-a548-a33e78bd0ff5",
   "metadata": {},
   "source": [
    "##### Horizontal cross-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caed31f-ea66-4f38-b61f-c8112af21814",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [\"THF\", \"EKM\", \"ZAF\", \"ADV\", \"ADV_3D_TEMP\"]:\n",
    "\n",
    "    print(f\"\\n\\n{n}\")\n",
    "\n",
    "    ## specify which period/month to plot\n",
    "    sel = lambda x: x.sel(month=6)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "    for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "        ## temperature\n",
    "        cp = ax.contourf(\n",
    "            m.lon,\n",
    "            m.z_t,\n",
    "            sel(m)[n],\n",
    "            cmap=\"cmo.balance\",\n",
    "            levels=src.utils.make_cb_range(2, 0.2),\n",
    "            extend=\"both\",\n",
    "        )\n",
    "\n",
    "    ## difference\n",
    "    axs[2].contourf(\n",
    "        m_early.lon,\n",
    "        m_early.z_t,\n",
    "        sel(m_late - m_early)[n],\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(1, 0.1),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    ## plot MLD\n",
    "    plot_mlds(axs, sel=sel)\n",
    "\n",
    "    ## set ax limit and plot Niño 3.4 bounds\n",
    "    cb = fig.colorbar(\n",
    "        cp, ax=axs[2], ticks=[-2, 0, 2], label=r\"$K~\\left(\\text{month}\\right)^{-1}$\"\n",
    "    )\n",
    "    format_subsurf_axs(axs)\n",
    "    for ax in axs:\n",
    "        ax.set_ylim([100, 5])\n",
    "        ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "        ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
