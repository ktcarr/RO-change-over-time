{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22516693-2eb8-45f7-b9d4-4511a195a408",
   "metadata": {},
   "source": [
    "# Bjerknes feedback changes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e795c63-4ea6-4623-b0a2-e33656d4c420",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d155a1-2906-4d88-9022-b7996ecf7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pathlib\n",
    "import cmocean\n",
    "import os\n",
    "import cartopy.util\n",
    "import copy\n",
    "\n",
    "# Import custom modules\n",
    "import src.utils\n",
    "from src.XRO import XRO, xcorr\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "SAVE_FP = pathlib.Path(os.environ[\"SAVE_FP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382b7b8-eac8-4cf0-8ad1-4632a36727b9",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874f9c6-8fd1-4c20-abb1-98e3e4962768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hov(ax, data, amp, label=None):\n",
    "    \"\"\"Plot hovmoller of longitude vs. year\"\"\"\n",
    "\n",
    "    # kwargs = dict(levels=src.utils.make_cb_range(3, 0.3), cmap=\"cmo.balance\", extend=\"both\")\n",
    "    plot_data = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.year,\n",
    "        data.T,\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"both\",\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "    )\n",
    "    cb = fig.colorbar(\n",
    "        plot_data, orientation=\"horizontal\", ticks=[-amp, 0, amp], label=label\n",
    "    )\n",
    "\n",
    "    ## label\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_xticks([190, 240])\n",
    "        ax.set_yticks([])\n",
    "        ax.axvline(190, **kwargs)\n",
    "        ax.axvline(240, **kwargs)\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_hov2(ax, data, amp, label=None):\n",
    "    \"\"\"Plot hovmoller of longitude vs. year\"\"\"\n",
    "\n",
    "    # kwargs = dict(levels=src.utils.make_cb_range(3, 0.3), cmap=\"cmo.balance\", extend=\"both\")\n",
    "    plot_data = ax.contourf(\n",
    "        data.month,\n",
    "        data.year,\n",
    "        data.T,\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"max\",\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "    )\n",
    "    cb = fig.colorbar(\n",
    "        plot_data,\n",
    "        orientation=\"horizontal\",\n",
    "        ticks=[-amp, 0, amp],\n",
    "        label=label,\n",
    "        # plot_data, orientation=\"horizontal\", ticks=[], label=None\n",
    "    )\n",
    "\n",
    "    ## label\n",
    "    kwargs = dict(ls=\"--\", c=\"w\", lw=0.8)\n",
    "    for ax in axs:\n",
    "        # ax.set_xlabel(\"Month\")\n",
    "        # ax.set_xticks([1, 12])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_rolling_var(data, n=10):\n",
    "    \"\"\"\n",
    "    Get variance, computing over time and ensemble member. To increase\n",
    "    sample size for variance estimate, compute over time window of 2n+1\n",
    "    years, centered at given year.\n",
    "    \"\"\"\n",
    "\n",
    "    return src.utils.get_rolling_fn_bymonth(data, fn=np.var, n=n)\n",
    "\n",
    "\n",
    "def get_ml_avg(data, Hm, delta=5, H0=None):\n",
    "    \"\"\"func to average data from surface to Hm + delta\"\"\"\n",
    "\n",
    "    ## interpolate MLD onto data grid\n",
    "    Hm_ = Hm.rename({\"longitude\": \"lon\"}).interp({\"lon\": data.lon})\n",
    "\n",
    "    ## tweak integration bounds\n",
    "    if H0 is None:\n",
    "        Hm_ = Hm_ + delta\n",
    "\n",
    "    else:\n",
    "        Hm_ = H0 * xr.ones_like(Hm_)\n",
    "\n",
    "    ## average over everything above the mixed layer\n",
    "    return data.where(data.z_t <= Hm_).mean(\"z_t\")\n",
    "\n",
    "\n",
    "def get_ml_avg_wrapper(data, Hm, delta=5):\n",
    "    \"\"\"wrapper function to format data for plotting\"\"\"\n",
    "\n",
    "    ## first, compute mixed layer average\n",
    "    ml_avg = get_ml_avg(data=data, Hm=Hm, delta=delta)\n",
    "\n",
    "    ## rename coord and tranpose\n",
    "    return ml_avg.rename({\"lon\": \"longitude\"}).transpose(\"month\", ...)\n",
    "\n",
    "\n",
    "def plot_mld_bounds(ax, clim, m):\n",
    "    \"\"\"Plot MLD climatology and ± bounds\"\"\"\n",
    "\n",
    "    ## clim\n",
    "    ax.plot(clim.longitude, clim, c=\"k\")\n",
    "\n",
    "    ## El Niño\n",
    "    ax.plot(clim.longitude, clim + m, c=\"r\")\n",
    "\n",
    "    ## La Niña\n",
    "    ax.plot(clim.longitude, clim - m, c=\"b\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_wT(w, T):\n",
    "    \"\"\"function to get vertical flux (handles diff. w/T grids)\"\"\"\n",
    "\n",
    "    ## rename w grid\n",
    "    w_ = copy.deepcopy(w).rename({\"z_w_top\": \"z_t\"})\n",
    "    w_ = w_.assign_coords({\"z_t\": T.z_t})\n",
    "\n",
    "    return w_ * T\n",
    "\n",
    "\n",
    "def get_wdTdz(w, T):\n",
    "    \"\"\"function to get vertical flux (handles diff. w/T grids)\"\"\"\n",
    "\n",
    "    ## rename w grid\n",
    "    w_ = copy.deepcopy(w).rename({\"z_w_top\": \"z_t\"})\n",
    "    w_ = w_.assign_coords({\"z_t\": T.z_t})\n",
    "\n",
    "    ## get dTdz (convert from 1/cm to 1/m)\n",
    "    dTdz = T.differentiate(\"z_t\")\n",
    "\n",
    "    return w_ * dTdz\n",
    "\n",
    "\n",
    "def get_udTdx(u, T):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dlon_deg = T.lon.values[1] - T.lon.values[0]\n",
    "    lat_deg = 0.0\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_m = get_dx(lat_deg=lat_deg, dlon_deg=dlon_deg)\n",
    "\n",
    "    ## differentiate\n",
    "    u_dfdx_ = u * T.differentiate(\"lon\") * 1 / dx_m\n",
    "\n",
    "    return u_dfdx_\n",
    "\n",
    "\n",
    "def get_u_adv(u, T):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dlon_deg = T.lon.values[1] - T.lon.values[0]\n",
    "    lat_deg = 0.0\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_m = get_dx(lat_deg=lat_deg, dlon_deg=dlon_deg)\n",
    "\n",
    "    ## differentiate and convert units to K/yr\n",
    "    mo_per_yr = 12\n",
    "    u_dfdx_ = u * T.differentiate(\"lon\") * 1 / dx_m * mo_per_yr\n",
    "\n",
    "    return -u_dfdx_\n",
    "\n",
    "\n",
    "def recon_clim(data, components, varname=\"sst\"):\n",
    "    \"\"\"reconstruct climatology for data\"\"\"\n",
    "\n",
    "    ## get climatolgoy in PC space\n",
    "    monthly_clim = data.groupby(\"time.month\").mean()\n",
    "\n",
    "    ## function to compute equatorial mean\n",
    "    equatorial_mean = lambda x: x.sel(latitude=slice(-2, 2)).mean(\"latitude\")\n",
    "\n",
    "    ## reconstruct\n",
    "    recon = src.utils.reconstruct_fn(\n",
    "        components[varname], monthly_clim[varname], fn=equatorial_mean\n",
    "    )\n",
    "\n",
    "    ## fill zero values with NaN\n",
    "    recon.values[recon.values == 0] = np.nan\n",
    "\n",
    "    return recon\n",
    "\n",
    "\n",
    "def get_monthly_eli(t_bnds):\n",
    "\n",
    "    ## get eli for period\n",
    "    eli_ = eli_forced.isel(time=slice(*t_bnds)).groupby(\"time.month\").mean()\n",
    "\n",
    "    return eli_\n",
    "\n",
    "\n",
    "def get_monthly_eli_std(t_bnds):\n",
    "\n",
    "    ## get eli for period\n",
    "    eli_ = (\n",
    "        eli_anom.isel(time=slice(*t_bnds)).groupby(\"time.month\").std([\"time\", \"member\"])\n",
    "    )\n",
    "\n",
    "    return eli_\n",
    "\n",
    "\n",
    "def plot_cyclic(ax, data, sigma=None, **kwargs):\n",
    "    \"\"\"plot data on hovmoller with cyclic dependence on month\"\"\"\n",
    "\n",
    "    ## add cyclic point\n",
    "    data_cyclic, dim_cyclic = cartopy.util.add_cyclic_point(data, data.month, axis=0)\n",
    "\n",
    "    ## plot data\n",
    "    ax.plot(data_cyclic, dim_cyclic, **kwargs)\n",
    "\n",
    "    ## plot bounds if they exist\n",
    "    if sigma is not None:\n",
    "        sigma_cyclic, _ = cartopy.util.add_cyclic_point(sigma, data.month, axis=0)\n",
    "\n",
    "        ## plot data\n",
    "        ax.plot(data_cyclic + sigma_cyclic, dim_cyclic, **kwargs, lw=0.8)\n",
    "        ax.plot(data_cyclic - sigma_cyclic, dim_cyclic, **kwargs, lw=0.8)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_cyclic_quantiles(ax, data, quantiles=[0.5, 0.15, 0.85], **kwargs):\n",
    "    \"\"\"plot data on hovmoller with cyclic dependence on month\"\"\"\n",
    "\n",
    "    ## compute quantiles\n",
    "    q = data.groupby(\"time.month\").quantile(q=quantiles, dim=[\"time\", \"member\"])\n",
    "    # q = q.rename({\"quantile\":\"q\"})\n",
    "\n",
    "    ## convert to numpy\n",
    "    month = q.month.values\n",
    "    q = q.transpose(\"quantile\", \"month\").values\n",
    "\n",
    "    ## add cyclic point\n",
    "    q_cyclic, dim_cyclic = cartopy.util.add_cyclic_point(q, month, axis=1)\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(q_cyclic[0], dim_cyclic, **kwargs)\n",
    "\n",
    "    ## plot other quantiles\n",
    "    if len(quantiles) > 1:\n",
    "        for j in range(1, len(quantiles)):\n",
    "            ax.plot(q_cyclic[j], dim_cyclic, lw=0.8, **kwargs)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def format_subsurf_axs(axs):\n",
    "    \"\"\"add labels/formatting to 3-panel axs\"\"\"\n",
    "\n",
    "    ## loop thru axs\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(ax.get_ylim()[::-1])\n",
    "        ax.set_xlim([None, 281])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "    axs[0].set_yticks([300, 150, 0])\n",
    "    axs[0].set_ylabel(\"Depth (m)\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def format_hov_axs(axs):\n",
    "    \"\"\"put hovmoller axs in standardized format\"\"\"\n",
    "\n",
    "    ## set fontsize\n",
    "    font_kwargs = dict(size=8)\n",
    "    axs[0].set_ylabel(\"Month\", **font_kwargs)\n",
    "    axs[0].set_title(\"Early\", **font_kwargs)\n",
    "    axs[1].set_title(\"Late\", **font_kwargs)\n",
    "    axs[2].set_title(\"Difference (x2)\", **font_kwargs)\n",
    "\n",
    "    axs[1].set_yticks([])\n",
    "    axs[2].set_yticks([])\n",
    "    axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "\n",
    "    for ax in axs:\n",
    "        # ax.set_xlim([190, None])\n",
    "        ax.set_xticks([190, 240])\n",
    "        ax.axvline(240, ls=\"--\", c=\"w\", lw=1)\n",
    "        ax.axvline(190, ls=\"--\", c=\"w\", lw=1)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_w_int(w):\n",
    "    \"\"\"get vertical velocity integrated over top 200 m\"\"\"\n",
    "    return w.sel(z_w_top=slice(None, 200)).mean(\"z_w_top\")\n",
    "\n",
    "\n",
    "def get_dTdz(Tsub):\n",
    "    \"\"\"get vertical velocity integrated over top 200 m\"\"\"\n",
    "    T_surf = Tsub.sel(z_t=0, method=\"nearest\").squeeze(drop=True)\n",
    "    T_subsurf = Tsub.sel(z_t=200, method=\"nearest\").squeeze(drop=True)\n",
    "\n",
    "    return T_surf - T_subsurf\n",
    "\n",
    "\n",
    "def get_diags(data):\n",
    "    \"\"\"get diagnostics\"\"\"\n",
    "    diags = xr.merge(\n",
    "        [get_dTdz(data[\"T\"]).rename(\"dTdz\"), get_w_int(data[\"w\"]).rename(\"w_int\")]\n",
    "    )\n",
    "    return diags.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "\n",
    "def get_dT_sub(Tsub, mld, delta=25):\n",
    "    \"\"\"get temperature difference b/n mixed layer and entrainment zone\"\"\"\n",
    "\n",
    "    ## interpolate mld to match w\n",
    "    mld_interp = mld.interp({\"longitude\": Tsub.lon.values}).rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    ## subset for non-NaN coords\n",
    "    valid_lon_idx = ~np.isnan(mld_interp).all(\"month\")\n",
    "    mld_interp = mld_interp.isel(lon=valid_lon_idx)\n",
    "    Tsub = Tsub.isel(lon=valid_lon_idx)\n",
    "\n",
    "    ## find indices in ML and entrainment zone (ez)\n",
    "    in_ml = Tsub.z_t <= mld_interp\n",
    "    in_ez = (Tsub.z_t > mld_interp) & (Tsub.z_t < (delta + mld_interp))\n",
    "\n",
    "    ## get Tbar and Tplus (following Frankignoul et al paper)\n",
    "    Tbar = Tsub.where(in_ml).mean(\"z_t\")\n",
    "    Tplus = Tsub.where(in_ez).mean(\"z_t\")\n",
    "\n",
    "    ## get gradient\n",
    "    dT = Tbar - Tplus\n",
    "\n",
    "    return dT.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "\n",
    "def get_dTdz_sub(Tsub, mld, delta=25):\n",
    "    \"\"\"get velocity at base of mixed layer\"\"\"\n",
    "\n",
    "    ## get temperature difference\n",
    "    dT = get_dT_sub(Tsub=Tsub, mld=mld, delta=delta)\n",
    "\n",
    "    ## interpolate mld to match w\n",
    "    mld_interp = mld.interp({\"longitude\": Tsub.lon.values}).rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    ## subset for non-NaN coords\n",
    "    valid_lon_idx = ~np.isnan(mld_interp).all(\"month\")\n",
    "    mld_interp = mld_interp.isel(lon=valid_lon_idx)\n",
    "\n",
    "    ## get gradient\n",
    "    dTdz = dT / mld_interp.rename({\"lon\": \"longitude\"})\n",
    "\n",
    "    return dTdz\n",
    "\n",
    "\n",
    "def get_nino34(data):\n",
    "    return data.sel(lon=slice(190, 240)).mean(\"lon\")\n",
    "\n",
    "\n",
    "def get_w_int_idx(data):\n",
    "    \"\"\"get nino3.4 w-int\"\"\"\n",
    "    return get_nino34(get_w_int(data))\n",
    "\n",
    "\n",
    "def get_dTdz_idx(data):\n",
    "    \"\"\"get nino3.4 w-int\"\"\"\n",
    "    return get_nino34(get_dTdz(data))\n",
    "\n",
    "\n",
    "def eq_avg(x):\n",
    "    return x.sel(latitude=slice(-5, 5), longitude=slice(125, 279)).mean(\"latitude\")\n",
    "\n",
    "\n",
    "def avg_mon_range(data, m0, m1):\n",
    "    \"\"\"average data each year over specified month range\"\"\"\n",
    "\n",
    "    ## find indices for month range\n",
    "    month = data.time.dt.month\n",
    "    is_season = (month >= m0) & (month <= m1)\n",
    "\n",
    "    ## get avg avg\n",
    "    data_season = data.isel(time=is_season).groupby(\"time.year\").mean()\n",
    "\n",
    "    return data_season.rename({\"year\": \"time\"})\n",
    "\n",
    "\n",
    "def get_mam(data):\n",
    "    \"\"\"subset for MAM months\"\"\"\n",
    "\n",
    "    return avg_mon_range(data, m0=3, m1=5)\n",
    "\n",
    "\n",
    "def set_ylims(axs):\n",
    "    lims = np.stack([ax.get_ylim() for ax in axs.flatten()], axis=0)\n",
    "\n",
    "    lb = lims[:, 0].min()\n",
    "    ub = lims[:, 1].max()\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_ylim([lb, ub])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def set_xlims(axs):\n",
    "    lims = np.stack([ax.get_xlim() for ax in axs.flatten()], axis=0)\n",
    "\n",
    "    lb = lims[:, 0].min()\n",
    "    ub = lims[:, 1].max()\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlim([lb, ub])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_dy(dlat_deg):\n",
    "    \"\"\"get spacing between latitudes in meters\"\"\"\n",
    "\n",
    "    ## convert from degrees to radians\n",
    "    dlat_rad = dlat / 180.0 * np.pi\n",
    "\n",
    "    ## multiply by radius of earth\n",
    "    R = 6.378e8  # earth radius (centimeters)\n",
    "    dlat_meters = R * dlat_rad\n",
    "\n",
    "    return dlat_meters\n",
    "\n",
    "\n",
    "def get_dx(lat_deg, dlon_deg):\n",
    "    \"\"\"get spacing between longitudes in meters\"\"\"\n",
    "\n",
    "    ## convert from degrees to radians\n",
    "    dlon_rad = dlon_deg / 180.0 * np.pi\n",
    "    lat_rad = lat_deg / 180 * np.pi\n",
    "\n",
    "    ## multiply by radius of earth\n",
    "    R = 6.378e6  # earth radius (meters)\n",
    "    dlon_meters = R * np.cos(lat_rad) * dlon_rad\n",
    "\n",
    "    return dlon_meters\n",
    "\n",
    "\n",
    "def get_dydx(data):\n",
    "    \"\"\"get dy and dx for given data\"\"\"\n",
    "\n",
    "    ## empty array to hold result\n",
    "    grid = xr.Dataset(\n",
    "        coords=dict(\n",
    "            latitude=data[\"latitude\"].values,\n",
    "            longitude=data[\"longitude\"].values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    grid[\"dlat\"] = grid[\"latitude\"].values[1] - grid[\"latitude\"].values[0]\n",
    "    grid[\"dlon\"] = grid[\"longitude\"].values[1] - grid[\"longitude\"].values[0]\n",
    "\n",
    "    grid[\"dlat_rad\"] = grid[\"dlat\"] / 180.0 * np.pi\n",
    "    grid[\"dlon_rad\"] = grid[\"dlon\"] / 180.0 * np.pi\n",
    "    R = 6.378e8  # earth radius (centimeters)\n",
    "\n",
    "    ## height of gridcell doesn't depend on longitude\n",
    "    grid[\"dy\"] = R * grid[\"dlat_rad\"]  # unit: meters\n",
    "    grid[\"dy\"] = grid[\"dy\"] * xr.ones_like(grid[\"latitude\"])\n",
    "\n",
    "    ## Compute width of gridcell\n",
    "    grid[\"lat_rad\"] = grid[\"latitude\"] / 180 * np.pi  # latitude in radians\n",
    "    grid[\"dx\"] = R * np.cos(grid[\"lat_rad\"]) * grid[\"dlon_rad\"]\n",
    "\n",
    "    return grid[[\"dy\", \"dx\"]]\n",
    "\n",
    "\n",
    "def u_dfdx(u, f):\n",
    "    \"\"\"zonal advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dx_cm = get_dydx(f)[\"dx\"]\n",
    "    sec_per_year = 86400 * 365\n",
    "    factor = sec_per_year / dx_cm\n",
    "\n",
    "    u_dfdx_ = u * f.differentiate(\"longitude\") * factor\n",
    "\n",
    "    return u_dfdx_\n",
    "\n",
    "\n",
    "def v_dfdy(v, f):\n",
    "    \"\"\"meridional advection\"\"\"\n",
    "\n",
    "    ## get grid spacing\n",
    "    dy_cm = get_dydx(f)[\"dy\"]\n",
    "    sec_per_year = 86400 * 365\n",
    "    factor = sec_per_year / dy_cm\n",
    "\n",
    "    v_dfdy_ = v * f.differentiate(\"latitude\") * factor\n",
    "\n",
    "    return v_dfdy_\n",
    "\n",
    "\n",
    "def get_adv(uv, T):\n",
    "    \"\"\"\n",
    "    Compute T tendency from horizontal advection.\n",
    "    Equal to:\n",
    "        (u,v) dot grad(-T)\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute grad T\n",
    "    u_dTdx = u_dfdx(u=uv[\"uvel\"], f=T)\n",
    "    v_dTdy = v_dfdy(v=uv[\"vvel\"], f=T)\n",
    "\n",
    "    ## get\n",
    "\n",
    "    return -(u_dTdx + v_dTdy)\n",
    "\n",
    "\n",
    "def merimean(x):\n",
    "    return x.sel(longitude=slice(140, 285), latitude=slice(-5, 5)).mean(\"latitude\")\n",
    "\n",
    "\n",
    "def plot_cycle_hov(ax, data, amp, is_filled=True, xticks=[190, 240]):\n",
    "    \"\"\"plot data on ax object\"\"\"\n",
    "\n",
    "    ## specify shared kwargs\n",
    "    shared_kwargs = dict(levels=src.utils.make_cb_range(amp, amp / 5), extend=\"both\")\n",
    "\n",
    "    ## specify kwargs\n",
    "    if is_filled:\n",
    "        plot_fn = ax.contourf\n",
    "        kwargs = dict(cmap=\"cmo.balance\")\n",
    "\n",
    "    else:\n",
    "        plot_fn = ax.contour\n",
    "        kwargs = dict(colors=\"k\", linewidths=0.8)\n",
    "\n",
    "    ## average over latitudes (if necessary)\n",
    "    if \"latitude\" in data.coords:\n",
    "        plot_data = merimean(data)\n",
    "    else:\n",
    "        plot_data = data\n",
    "\n",
    "    ## do the plotting\n",
    "    cp = plot_fn(\n",
    "        plot_data.longitude,\n",
    "        plot_data.month,\n",
    "        plot_data,\n",
    "        **kwargs,\n",
    "        **shared_kwargs,\n",
    "    )\n",
    "\n",
    "    ## format ax object\n",
    "    kwargs = dict(c=\"w\", ls=\"--\", lw=1)\n",
    "    ax.set_xlim([145, 280])\n",
    "    ax.set_xlabel(\"Lon\")\n",
    "    ax.set_xticks(xticks)\n",
    "    for tick in xticks:\n",
    "        ax.axvline(tick, **kwargs)\n",
    "\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a80a98-3a71-430f-b3ab-d4a6a43afe9d",
   "metadata": {},
   "source": [
    "## initialize cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679fe2a-c229-4d32-8601-2c6cc9ece182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6f806-7cb2-446a-a9c1-63adc1930685",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81b793-263e-47ed-8a47-72859ffcbe5f",
   "metadata": {},
   "source": [
    "### $T$, $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc268a-e60d-45bb-b68d-acd3860e5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open data\n",
    "Th = src.utils.load_cesm_indices()\n",
    "\n",
    "## rename indices for convenience\n",
    "Th = Th.rename(\n",
    "    {\n",
    "        \"north_tropical_atlantic\": \"natl\",\n",
    "        \"atlantic_nino\": \"nino_atl\",\n",
    "        \"tropical_indian_ocean\": \"iobm\",\n",
    "        \"indian_ocean_dipole\": \"iod\",\n",
    "        \"north_pacific_meridional_mode\": \"npmm\",\n",
    "        \"south_pacific_meridional_mode\": \"spmm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "## load tropical SST avg\n",
    "trop_sst = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/trop_sst.nc\"))\n",
    "\n",
    "## Load T,h (total)\n",
    "Th_total = xr.open_dataset(DATA_FP / \"cesm\" / \"Th.nc\")\n",
    "\n",
    "## compute relative sst\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\"]:\n",
    "    Th[f\"{n}_rel\"] = Th_total[n] - trop_sst[\"trop_sst_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021c452-b3f9-4dbb-bec5-706376791de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ELI data\n",
    "eli = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/eli.nc\"))\n",
    "\n",
    "## get forced/anomalous component\n",
    "eli_forced, eli_anom = src.utils.separate_forced(eli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f711ba-bc31-42a3-9154-6ef25c986fb3",
   "metadata": {},
   "source": [
    "### Spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a20d-d8f0-43dd-9c05-fca1f596d79b",
   "metadata": {},
   "source": [
    "#### MMLEA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62809ad8-327d-4215-af03-7ac255d72a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to EOF data\n",
    "eofs_fp = pathlib.Path(DATA_FP, \"cesm\")\n",
    "\n",
    "## variables to load (and how to rename them)\n",
    "names = [\n",
    "    \"tos\",\n",
    "    \"mlotst\",\n",
    "    \"tauu\",\n",
    "    \"zos\",\n",
    "]  # , \"zos\", \"tauu\", \"tauv\", \"nhf\", \"mlotst\", \"pr\"]\n",
    "newnames = [\"sst\", \"mld\", \"taux\", \"ssh\"]  # , \"ssh\", \"taux\", \"tauy\", \"nhf\", \"mld\", \"pr\"]\n",
    "\n",
    "# ## load the EOFs\n",
    "load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "eofs = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "## for convenience, put spatial patterns / components in single dataset\n",
    "components = xr.merge([eofs_.components().rename(y) for (y, eofs_) in eofs.items()])\n",
    "\n",
    "# reset member dimension so they all match (NHF labeled differently...)\n",
    "member_coord = dict(member=np.arange(100))\n",
    "get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "scores = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs.items()])\n",
    "\n",
    "## convert ssh from m to cm\n",
    "scores[\"ssh\"].values *= 100\n",
    "\n",
    "## convert from stress on atm to stress on ocn\n",
    "scores[\"taux\"].values *= -1\n",
    "\n",
    "## convert MLD from cm to m\n",
    "scores[\"mld\"] = scores[\"mld\"] / 100\n",
    "\n",
    "# ## get forced/anomalous component\n",
    "forced, anom = src.utils.separate_forced(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc9525-f2f9-404d-bf0a-4a208b90f51a",
   "metadata": {},
   "source": [
    "#### Surface velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba0f94-7dea-4775-9843-aae07d09fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load advection data\n",
    "# uvel_eofs = xr.open_dataset(eofs_fp / \"eofs_uvel.nc\")\n",
    "# vvel_eofs = xr.open_dataset(eofs_fp / \"eofs_vvel.nc\")\n",
    "\n",
    "# ## func to merge u and v data\n",
    "# merge = lambda u, v: xr.merge(\n",
    "#     [\n",
    "#         x.rename(n).drop_vars([\"variable\", \"z_t\"])\n",
    "#         for x, n in zip([u, v], [\"uvel\", \"vvel\"])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ## merge component data\n",
    "# vel_comps = merge(uvel_eofs.components, vvel_eofs.components)\n",
    "# vel_comps = vel_comps.rename({\"uvel\": \"uvel_comp\", \"vvel\": \"vvel_comp\"})\n",
    "\n",
    "# ## interpolate to SST grid for ease\n",
    "# rename_dict = dict(lat=\"latitude\", lon=\"longitude\")\n",
    "# vel_comps = vel_comps.rename(rename_dict).interp_like(components[\"sst\"])\n",
    "\n",
    "# ## merge scores\n",
    "# vel_scores = merge(uvel_eofs.scores, vvel_eofs.scores)\n",
    "# vel_scores = vel_scores.rename({\"member_id\": \"member\"})\n",
    "# vel_scores = vel_scores.assign_coords(dict(member=np.arange(100)))\n",
    "\n",
    "# ## separate forced and anom\n",
    "# vel_forced, vel_anom = src.utils.separate_forced(vel_scores)\n",
    "\n",
    "# ## merge with other data\n",
    "# anom = xr.merge([anom, vel_anom, vel_comps])\n",
    "# forced = xr.merge([forced, vel_forced])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a379a7e-bf35-4100-84c1-7b325b24bb54",
   "metadata": {},
   "source": [
    "#### Subsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a780a-4ded-401d-81d7-465baf4f51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lon_coord(data_sub):\n",
    "    \"\"\"fix longitude coordinate on subsurface data\"\"\"\n",
    "\n",
    "    data_sub = data_sub.assign_coords({\"nlon\": data_sub.lon.isel(z_t=0).values})\n",
    "    data_sub = data_sub.drop_vars(\"lon\").rename({\"nlon\": \"lon\"})\n",
    "\n",
    "    return data_sub\n",
    "\n",
    "\n",
    "def convert_cm_to_m_helper(data, z_coord_name):\n",
    "    \"\"\"convert z-coord from cm to m\"\"\"\n",
    "    return data.assign_coords({z_coord_name: data[z_coord_name].values / 100})\n",
    "\n",
    "\n",
    "def convert_cm_to_m(data):\n",
    "    \"\"\"convert all z-coords from cm to m\"\"\"\n",
    "\n",
    "    ## convert both z-coordinates\n",
    "    for z_coord in [\"z_t\", \"z_w_top\"]:\n",
    "        data = convert_cm_to_m_helper(data, z_coord_name=z_coord)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f8559-7c5d-42d3-b169-e7829dcefc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to EOF data\n",
    "eofs_fp = pathlib.Path(DATA_FP, \"cesm\")\n",
    "\n",
    "## variables to load (and how to rename them)\n",
    "names = [\n",
    "    \"temp\",\n",
    "    \"wvel\",\n",
    "    \"uvel_sub\",\n",
    "]\n",
    "newnames = [\"T\", \"w\", \"u\"]\n",
    "\n",
    "## load the EOFs\n",
    "load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "eofs_sub = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "## for convenience, put spatial patterns / components in single dataset\n",
    "components_sub = xr.merge(\n",
    "    [eofs_.components().rename(y) for (y, eofs_) in eofs_sub.items()]\n",
    ")\n",
    "\n",
    "## fix longitude coord\n",
    "components_sub = fix_lon_coord(components_sub)\n",
    "\n",
    "# reset member dimension so they all match (NHF labeled differently...)\n",
    "member_coord = dict(member_id=np.arange(100))\n",
    "get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "scores_sub = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs_sub.items()])\n",
    "\n",
    "## convert z coords from cm to m\n",
    "components_sub = convert_cm_to_m(components_sub)\n",
    "\n",
    "## convert u and w from cm/s to m/month\n",
    "\n",
    "# conversion factors\n",
    "m_per_cm = 1 / 100\n",
    "s_per_day = 86400\n",
    "s_per_month = s_per_day * 30\n",
    "\n",
    "# do conversion\n",
    "scores_sub[\"w\"] = scores_sub[\"w\"] * m_per_cm * s_per_month\n",
    "scores_sub[\"u\"] = scores_sub[\"u\"] * m_per_cm * s_per_month\n",
    "\n",
    "## get forced/anomalous component\n",
    "forced_sub, anom_sub = src.utils.separate_forced(\n",
    "    scores_sub.rename({\"member_id\": \"member\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbb125-dac9-4aea-ae0f-6bb5011e3dbc",
   "metadata": {},
   "source": [
    "### Bjerknes coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8eba95-1518-4147-9e7d-bcdec53b18be",
   "metadata": {},
   "source": [
    "#### prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c32e7b-b771-4c07-8675-502461bdf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(data):\n",
    "    \"\"\"remove sst dependence and compute tendencies\"\"\"\n",
    "\n",
    "    ## remove SST dependence from SSH field\n",
    "    if \"ssh\" in list(data):\n",
    "        data[\"ssh_hat\"] = src.utils.remove_sst_dependence_v2(\n",
    "            data, h_var=\"ssh\", T_var=\"nino34\"\n",
    "        )\n",
    "        data[\"ssh_hat_comp\"] = data[\"ssh_comp\"]\n",
    "\n",
    "    ## remove from h indices\n",
    "    for h_idx in [\"h_w\", \"h\"]:\n",
    "        data[f\"{h_idx}_hat\"] = src.utils.remove_sst_dependence_v2(\n",
    "            data, h_var=h_idx, T_var=\"nino34\"\n",
    "        )\n",
    "\n",
    "    ## compute tendencies\n",
    "    data = src.utils.get_ddt(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44503c-687d-4ffa-bb70-caa4aede6d45",
   "metadata": {},
   "source": [
    "Add EOF info to surface data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2a775-27b2-41fb-96a4-e1dc4476bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in list(components):\n",
    "    if f\"{v}_comp\" not in list(anom):\n",
    "        anom[f\"{v}_comp\"] = components[v]\n",
    "\n",
    "## add T and h indices to data\n",
    "names = [\"nino3\", \"nino34\", \"nino4\"]\n",
    "fns = [src.utils.get_nino3, src.utils.get_nino34, src.utils.get_nino4]\n",
    "for n, fn in zip(names, fns):\n",
    "    if n not in list(anom):\n",
    "        anom[n] = src.utils.reconstruct_fn(\n",
    "            scores=anom[\"sst\"], components=anom[\"sst_comp\"], fn=fn\n",
    "        )\n",
    "\n",
    "names = [\"h_w\", \"h\"]\n",
    "fns = [src.utils.get_RO_hw, src.utils.get_RO_h]\n",
    "for n, fn in zip(names, fns):\n",
    "    if n not in list(anom):\n",
    "        anom[n] = src.utils.reconstruct_fn(\n",
    "            scores=anom[\"ssh\"], components=anom[\"ssh_comp\"], fn=fn\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827999b-6078-4e25-a750-2d520f5f06b9",
   "metadata": {},
   "source": [
    "Add eof data to subsurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a176d-04f9-497c-a175-0fe877c4235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add components to dataset\n",
    "for v in list(components_sub):\n",
    "    if f\"{v}_comp\" not in list(anom_sub):\n",
    "        anom_sub[f\"{v}_comp\"] = components_sub[v]\n",
    "\n",
    "## add sst to dataset\n",
    "if \"sst\" not in list(anom_sub):\n",
    "    anom_sub[\"sst\"] = anom[\"sst\"].isel(time=slice(1, None))\n",
    "    anom_sub[\"sst_comp\"] = anom[\"sst_comp\"]\n",
    "\n",
    "if \"taux\" not in list(anom_sub):\n",
    "    anom_sub[\"taux\"] = anom[\"taux\"].isel(time=slice(1, None))\n",
    "    anom_sub[\"taux_comp\"] = anom[\"taux_comp\"]\n",
    "\n",
    "if \"ssh\" not in list(anom_sub):\n",
    "    anom_sub[\"ssh\"] = anom[\"ssh\"].isel(time=slice(1, None))\n",
    "    anom_sub[\"ssh_comp\"] = anom[\"ssh_comp\"]\n",
    "\n",
    "## add indices to dataset\n",
    "if \"nino34\" not in list(anom_sub):\n",
    "    for n in [\"nino3\", \"nino34\", \"h_w\", \"h\"]:\n",
    "        anom_sub[n] = anom[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e6dbb-7d50-4c9a-97f2-996737ea9506",
   "metadata": {},
   "source": [
    "Split into early/late, and compute tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6c536-b8c5-4277-96d7-8840513ec5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into early/late periods\n",
    "t_early = dict(time=slice(\"1851\", \"1880\"))\n",
    "t_late = dict(time=slice(\"2071\", \"2100\"))\n",
    "\n",
    "## split surface data\n",
    "anom_early = anom.sel(t_early)\n",
    "anom_late = anom.sel(t_late)\n",
    "\n",
    "## split subsurface data\n",
    "anom_sub_early = anom_sub.sel(t_early)\n",
    "anom_sub_late = anom_sub.sel(t_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e324d-e82e-496b-b6ef-6ff3647950a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute time derivatives\n",
    "anom_early = prep(anom_early)\n",
    "anom_late = prep(anom_late)\n",
    "\n",
    "anom_sub_early = prep(anom_sub_early)\n",
    "anom_sub_late = prep(anom_sub_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d0029-1362-4e4c-a5a8-1a235edb8d77",
   "metadata": {},
   "source": [
    "#### Mixed layer info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08373b-887d-4a78-ac52-6b866715250e",
   "metadata": {},
   "source": [
    "Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d8346-9fec-4696-a987-f98872b4fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mld_bounds(ax, clim, m):\n",
    "    \"\"\"Plot MLD climatology and ± bounds\"\"\"\n",
    "\n",
    "    ## clim\n",
    "    ax.plot(clim.longitude, clim, c=\"k\")\n",
    "\n",
    "    ## El Niño\n",
    "    ax.plot(clim.longitude, clim + m, c=\"r\")\n",
    "\n",
    "    ## La Niña\n",
    "    ax.plot(clim.longitude, clim - m, c=\"b\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_eq_mld(data):\n",
    "    \"\"\"Get equatorial mixed layer depth\"\"\"\n",
    "\n",
    "    data_ = data.sel(latitude=slice(-1.5, 1.5)).mean(\"latitude\")\n",
    "\n",
    "    return data_.sel(longitude=slice(140, 280))\n",
    "\n",
    "\n",
    "def recon_eq_mld(time_dict):\n",
    "    \"\"\"reconstruct equatorial MLD\"\"\"\n",
    "    return src.utils.reconstruct_fn(\n",
    "        scores=forced[\"mld\"].sel(time_dict).groupby(\"time.month\").mean(),\n",
    "        components=components[\"mld\"],\n",
    "        fn=get_eq_mld,\n",
    "    )\n",
    "\n",
    "\n",
    "## function to plot MLDs\n",
    "def plot_mlds(axs, sel):\n",
    "    axs[0].plot(mld_early.longitude, sel(mld_early), c=\"k\")\n",
    "    axs[1].plot(mld_late.longitude, sel(mld_late), c=\"k\", ls=\"--\")\n",
    "    axs[2].plot(mld_early.longitude, sel(mld_early), c=\"k\")\n",
    "    axs[2].plot(mld_late.longitude, sel(mld_late), c=\"k\", ls=\"--\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81038b96-ca89-47ee-ac47-cf5548ad6ff3",
   "metadata": {},
   "source": [
    "Get mixed layer for early/late periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666b568-5b85-45a8-a7de-b7538c2435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_early = recon_eq_mld(t_early)\n",
    "mld_late = recon_eq_mld(t_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40f01f-d96c-4170-83bc-1f8d95ec47c0",
   "metadata": {},
   "source": [
    "#### Get Tsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b68fc5-428c-4ea0-9df9-bea8431ffab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tsub_early(T):\n",
    "    \"\"\"\n",
    "    get subsurface temperature for early period\n",
    "    \"\"\"\n",
    "    return get_dT_sub(T, mld=mld_early, delta=20)\n",
    "\n",
    "\n",
    "def get_Tsub_recon(data):\n",
    "    \"\"\"get subsurface reconstruction\"\"\"\n",
    "\n",
    "    Tsub = src.utils.reconstruct_fn(\n",
    "        scores=data[\"T\"],\n",
    "        fn=get_Tsub_early,\n",
    "        components=data[\"T_comp\"],\n",
    "    )\n",
    "\n",
    "    return Tsub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8590c-6ece-48e7-87cf-756dd7d0ddb6",
   "metadata": {},
   "source": [
    "## Plot BJ couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6bcbb-8cca-4137-b049-dcaad89de08e",
   "metadata": {},
   "source": [
    "### $\\frac{d T}{d t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774cbf4-502a-4609-85b7-ef1a83f761e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(x_vars=[\"nino34\", \"h_w_hat\"], y_var=\"ddt_T\")\n",
    "\n",
    "m_early = src.utils.multi_regress_bymonth(anom_sub_early, **kwargs)[\"nino34\"]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_sub_late, **kwargs)[\"nino34\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4d431-8406-4f86-b115-b79805eb87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=7)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(10, 1),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(10, 1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-10, 0, 10], label=r\"$K~\\text{yr}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85c11f-9505-4ed7-b691-6b57f81b6baa",
   "metadata": {},
   "source": [
    "### SST-$\\tau_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600dedf-f8b0-41a4-89b2-350b609f5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared args\n",
    "kwargs = dict(x_vars=[\"nino34\"], y_var=\"taux\")\n",
    "\n",
    "## compute coefs\n",
    "m_early = src.utils.multi_regress_bymonth(anom_early, **kwargs).to_dataarray().squeeze()\n",
    "m_late = src.utils.multi_regress_bymonth(anom_late, **kwargs).to_dataarray().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98ff0f-f592-4775-b80e-c9fa346a774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(4, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "cp0 = plot_cycle_hov(axs[0], data=m_early, amp=0.015)\n",
    "plot_cycle_hov(axs[0], data=m_late, amp=0.015, is_filled=False)\n",
    "\n",
    "## plot difference\n",
    "cp2 = plot_cycle_hov(axs[1], data=m_late - m_early, amp=0.0075)\n",
    "\n",
    "## make it look nicer\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_yticks([1, 5, 9, 12], labels=[\"Jan\", \"May\", \"Sep\", \"Dec\"])\n",
    "axs[0].set_ylabel(\"Month\")\n",
    "axs[0].set_title(r\"$\\tau_x$-SST coupling\")\n",
    "axs[1].set_title(\"Change\")\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_xlim([150,280])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd8239-9dca-4e97-af5d-0925d7afc859",
   "metadata": {},
   "source": [
    "### $\\tau_x-T_{sub}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e61df8-01d9-4e00-94c8-723324be6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify T variable\n",
    "T_var = \"nino34\"\n",
    "\n",
    "kwargs = dict(x_vars=[T_var, \"h_w_hat\"], y_var=\"T\")\n",
    "# kwargs = dict(x_vars=[\"nino34\"],  y_var=\"T\")\n",
    "\n",
    "m_early = src.utils.multi_regress_bymonth(anom_sub_early, **kwargs)[T_var]\n",
    "m_late = src.utils.multi_regress_bymonth(anom_sub_late, **kwargs)[T_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc874c7b-027b-4daa-9de5-97f8a7d852f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify max depth for entrainment zone (relative to base of ML)\n",
    "ez_depth = 20\n",
    "\n",
    "## get vertical grad\n",
    "dT_early = -get_dT_sub(Tsub=m_early, mld=mld_early, delta=ez_depth)\n",
    "dT_late = -get_dT_sub(Tsub=m_late, mld=mld_late, delta=ez_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d52ef-e941-4cc7-a8ce-031d01ca71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make hövmöllers\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 5), layout=\"constrained\")\n",
    "\n",
    "## kwargs\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\", levels=src.utils.make_cb_range(1e0, 1e-1), extend=\"both\"\n",
    ")\n",
    "cb_kwargs = dict(ticks=[-1, 0, 1], label=r\"$K~/~K$\")\n",
    "\n",
    "## plot early\n",
    "cp0 = src.utils.plot_cycle_hov(axs[0], dT_early, **kwargs)\n",
    "cb0 = fig.colorbar(cp0, ax=axs[0], **cb_kwargs)\n",
    "\n",
    "# ## plot late\n",
    "cp1 = src.utils.plot_cycle_hov(axs[1], dT_late, **kwargs)\n",
    "cb1 = fig.colorbar(cp1, ax=axs[1], **cb_kwargs)\n",
    "\n",
    "## plot difference\n",
    "cp2 = src.utils.plot_cycle_hov(\n",
    "    axs[2],\n",
    "    dT_late - dT_early,\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(0.5e0, 0.5e-1),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb2 = fig.colorbar(cp2, ax=axs[2], ticks=[-0.5, 0, 0.5], label=r\"$K~/~K$\")\n",
    "\n",
    "## label\n",
    "axs[0].set_title(\"Early\")\n",
    "axs[1].set_title(\"Late\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "axs[-1].set_xlabel(\"Longitude\")\n",
    "axs[-1].set_xticks([140, 190, 240])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65b5e5-8c3f-4aa0-be70-e858788c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared kwargs\n",
    "kwargs = dict(x_var=\"taux\", y_var=\"T\")\n",
    "\n",
    "## function to get slope\n",
    "get_slope = lambda x, fn_x: x.groupby(\"time.month\").map(\n",
    "    src.utils.regress_proj, fn_x=fn_x, **kwargs\n",
    ")\n",
    "\n",
    "## then, reconstruct regression coefficient\n",
    "m_early = get_slope(anom_sub_early, fn_x=src.utils.get_nino34)\n",
    "m_late = get_slope(anom_sub_late, fn_x=src.utils.get_nino34)\n",
    "# m_early = get_slope(anom_sub_early, fn_x=src.utils.get_nino4)\n",
    "# m_late = get_slope(anom_sub_early, fn_x=src.utils.get_nino34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05e390-47f2-405a-9f3b-44e670f6033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=7)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t,\n",
    "        sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(200, 20),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t,\n",
    "    sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(100, 10),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-10, 0, 10], label=r\"$K~\\text{Pa}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51286f7e-0838-4b8c-8be8-326fb5e0e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify max depth for entrainment zone (relative to base of ML)\n",
    "ez_depth = 20\n",
    "\n",
    "## get vertical grad\n",
    "dT_early = -get_dT_sub(Tsub=m_early, mld=mld_early, delta=ez_depth)\n",
    "dT_late = -get_dT_sub(Tsub=m_late, mld=mld_late, delta=ez_depth)\n",
    "\n",
    "# dT_early = -get_dT_sub(Tsub=m_early, mld=mld_early, delta=ez_depth)\n",
    "# dT_late = -get_dT_sub(Tsub=m_late, mld=mld_early, delta=ez_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01411c2f-2948-478c-9e3e-fc7e72e20a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make hövmöllers\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 5), layout=\"constrained\")\n",
    "\n",
    "## kwargs\n",
    "kwargs = dict(\n",
    "    cmap=\"cmo.balance\", levels=src.utils.make_cb_range(1e2, 1e1), extend=\"both\"\n",
    ")\n",
    "cb_kwargs = dict(ticks=[-100, 0, 100], label=r\"$K~/~Pa$\")\n",
    "\n",
    "## plot early\n",
    "cp0 = src.utils.plot_cycle_hov(axs[0], dT_early, **kwargs)\n",
    "cb0 = fig.colorbar(cp0, ax=axs[0], **cb_kwargs)\n",
    "\n",
    "# ## plot late\n",
    "cp1 = src.utils.plot_cycle_hov(axs[1], dT_late, **kwargs)\n",
    "cb1 = fig.colorbar(cp1, ax=axs[1], **cb_kwargs)\n",
    "\n",
    "## plot difference\n",
    "cp2 = src.utils.plot_cycle_hov(\n",
    "    axs[2],\n",
    "    dT_late - dT_early,\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(5e1, 5e0),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb2 = fig.colorbar(cp2, ax=axs[2], ticks=[-50, 0, 50], label=r\"$K~/~Pa$\")\n",
    "\n",
    "## label\n",
    "axs[0].set_title(\"Early\")\n",
    "axs[1].set_title(\"Late\")\n",
    "axs[2].set_title(\"Difference\")\n",
    "axs[-1].set_xlabel(\"Longitude\")\n",
    "axs[-1].set_xticks([140, 190, 240])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11a4e7-2239-42c9-bd73-92dd4ff1c387",
   "metadata": {},
   "source": [
    "## ENSO composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9ae9d-74cd-4ac5-9b7a-cdf27c40c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_composite(idx, data, peak_month, time_idx, q=0.95, is_warm=True):\n",
    "    \"\"\"\n",
    "    Get hovmoller composite based on specified:\n",
    "    - data: used to compute index/make composite\n",
    "    - peak_month: month to center composite on\n",
    "    - q: quantile threshold for composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## get data subset\n",
    "    data_ = data.sel(time_idx)\n",
    "    idx_ = idx.sel(time_idx)\n",
    "\n",
    "    ## handle warm/cold case\n",
    "    if is_warm:\n",
    "        kwargs = dict(q=q, check_cutoff=lambda x, cut: x > cut)\n",
    "    else:\n",
    "        kwargs = dict(q=1 - q, check_cutoff=lambda x, cut: x < cut)\n",
    "\n",
    "    ## kwargs for composite\n",
    "    kwargs = dict(kwargs, peak_month=peak_month, idx=idx_, data=data_)\n",
    "\n",
    "    ## composite of projected data\n",
    "    comp_proj = src.utils.make_composite(**kwargs)\n",
    "\n",
    "    return comp_proj\n",
    "\n",
    "\n",
    "def get_spatial_composite(components, **composite_kwargs):\n",
    "    \"\"\"\n",
    "    Get spatial composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## get projected composite\n",
    "    comp_proj = get_composite(**composite_kwargs)\n",
    "\n",
    "    ## reconstruct spatial fields\n",
    "    comp = reconstruct_helper(comp_proj, components, func=lambda x: x).drop_vars(\"mode\")\n",
    "\n",
    "    ## reconstruct relative SST\n",
    "    comp[\"sst_rel\"] = comp[\"sst_total\"] - comp[\"trop_sst_05\"]\n",
    "\n",
    "    return comp\n",
    "\n",
    "\n",
    "def reconstruct_helper(composite, components, func):\n",
    "    \"\"\"reconstruction helper function for composite\"\"\"\n",
    "\n",
    "    ## copy to hold reconstructed results\n",
    "    composite_recon = copy.deepcopy(composite)\n",
    "\n",
    "    ## reconstruct anomalies\n",
    "    for c in list(components):\n",
    "        composite_recon[c] = src.utils.reconstruct_fn(\n",
    "            components=components[c],\n",
    "            scores=composite[c],\n",
    "            fn=func,\n",
    "        )\n",
    "\n",
    "    ## check for \"total\" fields\n",
    "    for c in list(composite):\n",
    "        if \"_total\" in c:\n",
    "            n = c[:-6]\n",
    "            composite_recon[c] = src.utils.reconstruct_fn(\n",
    "                components=components[n],\n",
    "                scores=composite[c],\n",
    "                fn=func,\n",
    "            )\n",
    "\n",
    "    return composite_recon\n",
    "\n",
    "\n",
    "def get_spatial_clim(forced, time_idx, lags, peak_month, components):\n",
    "    \"\"\"get climatologies of spatial variables\"\"\"\n",
    "\n",
    "    ## reconstruct monthly climatology for period\n",
    "    clim = src.utils.reconstruct_fn(\n",
    "        scores=forced.sel(time_idx).groupby(\"time.month\").mean(),\n",
    "        components=components,\n",
    "        fn=lambda x: x,\n",
    "    )\n",
    "\n",
    "    ## convert to lag coordinates\n",
    "    months = 1 + np.mod(lags + peak_month - 1, 12)\n",
    "    clim_comp = xr.concat(\n",
    "        [clim.sel(month=m).drop_vars(\"month\") for m in months],\n",
    "        dim=lags,\n",
    "    )\n",
    "\n",
    "    return clim_comp\n",
    "\n",
    "\n",
    "def add_advection_terms(comp, comp_clim, delta=5, H0=None):\n",
    "    \"\"\"add advection terms to composite\"\"\"\n",
    "\n",
    "    ## copy composite\n",
    "    comp_ = copy.deepcopy(comp)\n",
    "\n",
    "    ## zonal velocity\n",
    "    comp_[\"adv_uprime_Tbar\"] = -get_udTdx(u=comp[\"u\"], T=comp_clim[\"T\"])\n",
    "    comp_[\"adv_ubar_Tprime\"] = -get_udTdx(T=comp[\"T\"], u=comp_clim[\"u\"])\n",
    "\n",
    "    ## vertical velocity\n",
    "    comp_[\"adv_wprime_Tbar\"] = get_wdTdz(w=comp[\"w\"], T=comp_clim[\"T\"])\n",
    "    comp_[\"adv_wbar_Tprime\"] = get_wdTdz(T=comp[\"T\"], w=comp_clim[\"w\"])\n",
    "\n",
    "    ## integrate over mixed layer\n",
    "    for v in list(comp_):\n",
    "        if \"adv\" in v:\n",
    "            comp_[f\"{v}_ml\"] = get_ml_avg(\n",
    "                comp_[v],\n",
    "                Hm=comp_clim[\"mld\"],\n",
    "                delta=delta,\n",
    "                H0=H0,\n",
    "            )\n",
    "\n",
    "    ## add together zonal adv and thermocline feedbacks\n",
    "    comp_[\"Th_zaf_ml\"] = comp_[\"adv_wbar_Tprime_ml\"] + comp_[\"adv_uprime_Tbar_ml\"]\n",
    "\n",
    "    return comp_\n",
    "\n",
    "\n",
    "def get_T_ml_tendency(T, mld, delta=5, H0=None):\n",
    "    \"\"\"compute mixed-layer temperature tendency\"\"\"\n",
    "\n",
    "    ## integrate over mixed layer\n",
    "    T_ml = get_ml_avg(T, Hm=mld, delta=delta, H0=H0)\n",
    "\n",
    "    ## compute tendency\n",
    "    return T_ml.differentiate(\"lag\")\n",
    "\n",
    "\n",
    "def get_spatial_composite_wrapper(\n",
    "    forced_scores,\n",
    "    components,\n",
    "    peak_month,\n",
    "    time_idx,\n",
    "    delta=5,\n",
    "    H0=None,\n",
    "    **composite_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get spatial composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## shared args\n",
    "    shared_args = dict(\n",
    "        time_idx=time_idx,\n",
    "        peak_month=peak_month,\n",
    "    )\n",
    "\n",
    "    ## get spatial composite of anomalies\n",
    "    composite = get_spatial_composite(\n",
    "        components=components,\n",
    "        **shared_args,\n",
    "        **composite_kwargs,\n",
    "    )\n",
    "\n",
    "    ## get background state\n",
    "    comp_clim = get_spatial_clim(\n",
    "        forced=forced_scores,\n",
    "        lags=composite.lag,\n",
    "        components=components[[\"u\", \"w\", \"T\", \"mld\"]],\n",
    "        **shared_args,\n",
    "    )\n",
    "\n",
    "    ## add advection terms\n",
    "    composite = add_advection_terms(\n",
    "        comp=composite, comp_clim=comp_clim, delta=delta, H0=H0\n",
    "    )\n",
    "\n",
    "    ## add mixed-layer temperature tendency\n",
    "    composite[\"ddt_T\"] = get_T_ml_tendency(\n",
    "        composite[\"T\"],\n",
    "        mld=comp_clim[\"mld\"],\n",
    "        delta=delta,\n",
    "        H0=H0,\n",
    "    )\n",
    "\n",
    "    ## add SST tendency\n",
    "    ddt_sst = composite[\"sst\"].differentiate(\"lag\").rename({\"longitude\": \"lon\"})\n",
    "    composite[\"ddt_sst\"] = ddt_sst.interp({\"lon\": composite.lon.values})\n",
    "\n",
    "    ## get NHF in units of K/mo\n",
    "    sec_per_mo = 8.64e4 * 30\n",
    "    rho = 1.02e3\n",
    "    Cp = 4.2e3\n",
    "    H = comp_clim[\"mld\"]\n",
    "    # H = 50\n",
    "    Q = composite[\"nhf\"] * sec_per_mo / (rho * Cp * H)\n",
    "    Q = Q.rename({\"longitude\": \"lon\"})\n",
    "    composite[\"Q\"] = Q.interp({\"lon\": composite.lon.values})\n",
    "\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68746f-fab6-439e-a50d-58bbec7a900f",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d447e2a-1f37-47a5-a6a2-c7823939b2a3",
   "metadata": {},
   "source": [
    "Subset of data for making composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d78483-2569-4d7b-b8dc-01dd78e3082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data array for computing composite\n",
    "comp_data = xr.merge(\n",
    "    [\n",
    "        anom[[\"sst\", \"pr\", \"ssh\", \"mld\", \"nhf\"]],  # anomalies\n",
    "        scores[[\"sst\", \"pr\"]].rename({\"sst\": \"sst_total\", \"pr\": \"pr_total\"}),\n",
    "        eli[\"eli_05\"],\n",
    "        trop_sst[\"trop_sst_05\"],\n",
    "        anom_sub[[\"T\", \"u\", \"w\"]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "## get components\n",
    "comp_components = xr.merge(\n",
    "    [components[[\"sst\", \"ssh\", \"pr\", \"mld\", \"nhf\"]], components_sub[[\"T\", \"u\", \"w\"]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428cc50-da77-44b7-9d9f-dc9c7597d433",
   "metadata": {},
   "source": [
    "Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240df763-2e70-4c0b-a25c-83feb9da5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify shared args\n",
    "kwargs = dict(\n",
    "    peak_month=12,\n",
    "    q=0.95,\n",
    "    idx=Th[\"T_34\"],\n",
    "    is_warm=True,\n",
    "    data=comp_data,\n",
    "    components=comp_components,\n",
    "    delta=10,\n",
    "    H0=None,\n",
    ")\n",
    "\n",
    "## specify early/late times\n",
    "t_idx_early = dict(time=slice(\"1851\", \"1880\"))\n",
    "t_idx_late = dict(time=slice(\"2071\", \"2100\"))\n",
    "\n",
    "comp_early = get_spatial_composite_wrapper(\n",
    "    forced_scores=xr.merge([forced_sub, forced[\"mld\"]]),\n",
    "    time_idx=t_idx_early,\n",
    "    **kwargs,\n",
    ")\n",
    "comp_late = get_spatial_composite_wrapper(\n",
    "    forced_scores=xr.merge([forced_sub, forced[\"mld\"]]),\n",
    "    time_idx=t_idx_late,\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "## hovmoller version\n",
    "merimean = lambda x: x.sel(latitude=slice(-5, 5)).mean(\"latitude\")\n",
    "hov_comp_early = merimean(comp_early).transpose(\"lag\", ...)\n",
    "hov_comp_late = merimean(comp_late).transpose(\"lag\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2f27-9ac0-47c5-a5ce-fa5c945b350b",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0c410-a120-4f97-836c-276a79b0644d",
   "metadata": {},
   "source": [
    "#### SST hovmoller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096a3ea-6ac3-451b-b795-6a384fcc2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify amplitudes for plots\n",
    "scales = np.array([4 / 3, 4 / 3, 4 / 3])\n",
    "\n",
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7, 3), layout=\"constrained\")\n",
    "\n",
    "for ax, merimean, scale in zip(\n",
    "    axs, [hov_comp_early, hov_comp_late, 2 * (hov_comp_late - hov_comp_early)], scales\n",
    "):\n",
    "    cf, _ = src.utils.plot_hov(ax=ax, x=merimean, beta=scale)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ## label x axis\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_xticks([190, 240])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "## label\n",
    "font_kwargs = dict(size=10)\n",
    "axs[0].set_title(\"Early (1853-1883)\", **font_kwargs)\n",
    "axs[1].set_title(\"Late (2067-2097)\", **font_kwargs)\n",
    "axs[2].set_title(\"Difference (x2)\", **font_kwargs)\n",
    "cb = fig.colorbar(cf, ax=axs[2], ticks=[-4, 0, 4], label=\"K\")\n",
    "src.utils.label_hov_yaxis(axs[0], peak_mon=kwargs[\"peak_month\"])\n",
    "\n",
    "## plot ELI\n",
    "axs[0].plot(\n",
    "    comp_early[\"eli_05\"],\n",
    "    comp_early.lag,\n",
    "    c=\"magenta\",\n",
    ")\n",
    "axs[1].plot(comp_late[\"eli_05\"], comp_late.lag, c=\"magenta\", ls=\"--\")\n",
    "axs[2].plot(comp_early[\"eli_05\"], comp_early.lag, c=\"magenta\", ls=\"-\")\n",
    "axs[2].plot(comp_late[\"eli_05\"], comp_late.lag, c=\"magenta\", ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763bf75-4a9a-49e3-8070-fc50f887e75e",
   "metadata": {},
   "source": [
    "#### Relative SST and precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16c1a8-7e0b-4639-82f7-4bf64f7ecfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7, 3), layout=\"constrained\")\n",
    "\n",
    "## plot  composite for each period\n",
    "for ax, merimean in zip(axs[:2], [hov_comp_early, hov_comp_late]):\n",
    "\n",
    "    cf = ax.contourf(\n",
    "        merimean.longitude,\n",
    "        merimean.lag,\n",
    "        8.6e4 * merimean[\"pr_total\"],\n",
    "        cmap=\"cmo.rain\",\n",
    "        levels=np.arange(0, 21, 3),\n",
    "        extend=\"max\",\n",
    "    )\n",
    "\n",
    "\n",
    "## plot difference\n",
    "cf_diff = axs[2].contourf(\n",
    "    merimean.longitude,\n",
    "    merimean.lag,\n",
    "    8.6e4 * (hov_comp_late - hov_comp_early)[\"pr_total\"],\n",
    "    cmap=\"cmo.balance_r\",\n",
    "    levels=src.utils.make_cb_range(9, 1.5),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ## label x axis\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_xticks([190, 240])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([140, 280])\n",
    "    ax.axvline(190, c=\"w\", ls=\"--\", lw=0.8)\n",
    "    ax.axvline(240, c=\"w\", ls=\"--\", lw=0.8)\n",
    "    ax.axhline(6, c=\"w\", ls=\"--\", lw=0.8, alpha=0.5)\n",
    "\n",
    "## label\n",
    "font_kwargs = dict(size=10)\n",
    "axs[0].set_title(\"Early (1853-1883)\", **font_kwargs)\n",
    "axs[1].set_title(\"Late (2067-2097)\", **font_kwargs)\n",
    "axs[2].set_title(\"Difference\", **font_kwargs)\n",
    "cb = fig.colorbar(cf, ax=axs[1], ticks=[0, 9, 18])\n",
    "cb_diff = fig.colorbar(cf_diff, ax=axs[2], ticks=[-9, 0, 9], label=\"mm / day\")\n",
    "src.utils.label_hov_yaxis(axs[0], peak_mon=kwargs[\"peak_month\"])\n",
    "\n",
    "## plot ELI\n",
    "\n",
    "## plot zero line\n",
    "for ax, hov, ls, c in zip(\n",
    "    axs[:2], [hov_comp_early, hov_comp_late], [\"-\", \"--\"], [\"gray\", \"k\"]\n",
    "):\n",
    "    ax.contour(\n",
    "        hov.longitude,\n",
    "        hov.lag,\n",
    "        hov[\"sst_rel\"],\n",
    "        levels=[0],\n",
    "        colors=c,\n",
    "        linestyles=ls,\n",
    "        linewidths=2,\n",
    "    )\n",
    "\n",
    "for hov, ls, c in zip([hov_comp_early, hov_comp_late], [\"-\", \"--\"], [\"gray\", \"k\"]):\n",
    "    axs[2].contour(\n",
    "        hov.longitude,\n",
    "        hov.lag,\n",
    "        hov[\"sst_rel\"],\n",
    "        levels=[0],\n",
    "        colors=c,\n",
    "        linestyles=ls,\n",
    "        linewidths=2,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a81fd4-ef80-4116-b68a-d13f4ba5edaa",
   "metadata": {},
   "source": [
    "#### Advection terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb82fc5-d5a2-4b1f-98ab-95fb61959909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_hov_ax(ax):\n",
    "    \"\"\"format hovmoller ax\"\"\"\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ## label x axis\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([140, 280])\n",
    "    ax.axvline(190, c=\"w\", ls=\"--\", lw=0.8)\n",
    "    ax.axvline(240, c=\"w\", ls=\"--\", lw=0.8)\n",
    "    for t, c in zip([-6, 0, 6], [\"w\", \"k\", \"w\"]):\n",
    "        ax.axhline(t, c=c, ls=\"--\", lw=0.8, alpha=0.5)\n",
    "    # ax.axhline(-4, c=\"w\", ls=\"--\", lw=0.8, alpha=0.5)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd2f04-6b6a-4ebf-905d-6d7ec7efa230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### specify which terms to plot\n",
    "\n",
    "## tendency and zonal advective\n",
    "# plot_vars = [\"adv_uprime_Tbar_ml\", \"ddt_T\"]\n",
    "# plot_vars = [\"ddt_T\", \"adv_wbar_Tprime_ml\", \"Th_zaf_ml\"]\n",
    "# plot_vars = [\"ddt_sst\", \"adv_wbar_Tprime_ml\", \"Th_zaf_ml\"]\n",
    "plot_vars = [\"ddt_T\", \"Th_zaf_ml\", \"Q\"]\n",
    "\n",
    "## thermocline and zonal feedbacks\n",
    "# plot_vars = [\"adv_wbar_Tprime_ml\", \"adv_uprime_Tbar_ml\"]\n",
    "\n",
    "## thermocline and ekman\n",
    "# plot_vars = [\"adv_wbar_Tprime_ml\", \"adv_wprime_Tbar_ml\"]\n",
    "\n",
    "#### set up plot\n",
    "fig, axs = plt.subplots(3, 3, figsize=(5, 6), layout=\"constrained\")\n",
    "\n",
    "## specify plotting specs\n",
    "plot_kwargs = dict(\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(1.5, 0.15),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "for row_i, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    ## plot  composite for each period\n",
    "    for col_i, merimean in enumerate([hov_comp_early, hov_comp_late]):\n",
    "\n",
    "        ## plot absolute\n",
    "        cf = axs[row_i, col_i].contourf(\n",
    "            merimean.lon,\n",
    "            merimean.lag,\n",
    "            merimean[plot_var],\n",
    "            **plot_kwargs,\n",
    "        )\n",
    "\n",
    "    ## plot difference\n",
    "    cf_diff = axs[row_i, 2].contourf(\n",
    "        merimean.lon,\n",
    "        merimean.lag,\n",
    "        2 * (hov_comp_late - hov_comp_early)[plot_var],\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "\n",
    "for ax in axs.flatten():\n",
    "\n",
    "    format_hov_ax(ax)\n",
    "\n",
    "## label\n",
    "font_kwargs = dict(size=10)\n",
    "axs[0, 0].set_title(\"Early\", **font_kwargs)\n",
    "axs[0, 1].set_title(\"Late\", **font_kwargs)\n",
    "axs[0, 2].set_title(\"Difference (x2)\", **font_kwargs)\n",
    "\n",
    "cb = fig.colorbar(cf, ax=axs[:, 2], ticks=[-1, 0, 1], label=r\"$K~mo^{-1}$\")\n",
    "\n",
    "for ax in axs[:, 0]:\n",
    "    src.utils.label_hov_yaxis(ax, peak_mon=kwargs[\"peak_month\"])\n",
    "\n",
    "for ax in axs[-1, :]:\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_xticks([190, 240])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbe7a9-d1c9-4985-be95-5b933bb227df",
   "metadata": {},
   "source": [
    "#### Spatial patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37668c-98f8-42dc-8d59-035a48fd9d90",
   "metadata": {},
   "source": [
    "Relative SST and precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602963e-d378-4fea-8ee6-ddbb3bc35b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sst_rel(ax, data):\n",
    "    \"\"\"plot relative sst on ax object\"\"\"\n",
    "\n",
    "    cp = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.latitude,\n",
    "        data[\"sst_rel\"],\n",
    "        cmap=\"cmo.balance\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=src.utils.make_cb_range(10, 1),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    return cp\n",
    "\n",
    "\n",
    "def plot_contour(ax, data, lev, lw, c=\"k\"):\n",
    "    \"\"\"plot relative sst on ax object\"\"\"\n",
    "\n",
    "    cp = ax.contour(\n",
    "        data.longitude,\n",
    "        data.latitude,\n",
    "        data[\"sst_rel\"],\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=[lev],\n",
    "        linewidths=lw,\n",
    "        colors=c,\n",
    "    )\n",
    "\n",
    "    return cp\n",
    "\n",
    "\n",
    "def plot_pr(ax, data):\n",
    "    \"\"\"plot precip on ax object\"\"\"\n",
    "\n",
    "    ## convert from kg / m / s to mm/day\n",
    "    ## 1e-3 (m3 / kg) * 1e3 (mm / m) * 8.6e4 (s / day)\n",
    "    factor = 8.6e4\n",
    "\n",
    "    cp = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.latitude,\n",
    "        factor * data[\"pr_total\"],\n",
    "        cmap=\"cmo.rain\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=np.arange(0, 28, 4),\n",
    "        extend=\"max\",\n",
    "    )\n",
    "\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097d915-4565-453d-a752-12e4c2fc67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which month to look at\n",
    "sel = lambda x: x.sel(lag=2)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4.375), layout=\"constrained\")\n",
    "format_func = lambda ax,: src.utils.plot_setup_pac(ax, max_lat=20)\n",
    "axs = src.utils.subplots_with_proj(fig, nrows=3, ncols=2, format_func=format_func)\n",
    "\n",
    "## plot early\n",
    "cp0 = plot_sst_rel(axs[0, 0], sel(comp_early))\n",
    "cp1 = plot_pr(axs[0, 1], sel(comp_early))\n",
    "\n",
    "## plot late\n",
    "plot_sst_rel(axs[1, 0], sel(comp_late))\n",
    "plot_pr(axs[1, 1], sel(comp_late))\n",
    "\n",
    "## plot diff\n",
    "cp0_ = axs[2, 0].contourf(\n",
    "    comp_early.longitude,\n",
    "    comp_early.latitude,\n",
    "    sel((comp_late - comp_early)[\"sst_rel\"]),\n",
    "    cmap=\"cmo.balance\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    levels=src.utils.make_cb_range(2, 0.2),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cp1_ = axs[2, 1].contourf(\n",
    "    comp_early.longitude,\n",
    "    comp_early.latitude,\n",
    "    8.6e4 * sel((comp_late - comp_early)[\"pr_total\"]),\n",
    "    cmap=\"cmo.balance_r\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    levels=src.utils.make_cb_range(12, 2),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "## plot convective bounds\n",
    "for ax in axs[0, :]:\n",
    "    plot_contour(ax, sel(comp_early), lev=0, lw=2)\n",
    "    # plot_contour(ax, sel(comp_early), lev=-1, lw=1)\n",
    "\n",
    "for ax in axs[1, :]:\n",
    "    plot_contour(ax, sel(comp_late), lev=0, lw=2)\n",
    "    # plot_contour(ax, sel(comp_late), lev=-1, lw=1)\n",
    "\n",
    "for ax in axs[2]:\n",
    "    plot_contour(ax, sel(comp_early), lev=0, lw=2, c=\"gray\")\n",
    "    plot_contour(ax, sel(comp_late), lev=0, lw=2)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axhline(0, c=\"magenta\", lw=1, alpha=0.5)\n",
    "\n",
    "## colorbars\n",
    "fig.colorbar(cp0, ax=axs[:2, 0], ticks=[-10, 0, 10])\n",
    "fig.colorbar(cp1, ax=axs[:2, 1], ticks=[0, 12, 24])\n",
    "fig.colorbar(cp0_, ax=axs[2, 0], ticks=[-2, 0, 2])\n",
    "fig.colorbar(cp1_, ax=axs[2, 1], ticks=[-12, 0, 12])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca3990-6ee0-4413-a546-4ffd252f5949",
   "metadata": {},
   "source": [
    "SST and precip anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a157f9-eb90-46ae-bdb1-c1d2929926f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sst_anom(ax, data, amp=2):\n",
    "    \"\"\"plot relative sst on ax object\"\"\"\n",
    "\n",
    "    cp = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.latitude,\n",
    "        data[\"sst\"],\n",
    "        cmap=\"cmo.balance\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    return cp\n",
    "\n",
    "\n",
    "def plot_pr_anom(ax, data, amp=20):\n",
    "    \"\"\"plot precip on ax object\"\"\"\n",
    "\n",
    "    ## convert from kg / m / s to mm/day\n",
    "    ## 1e-3 (m3 / kg) * 1e3 (mm / m) * 8.6e4 (s / day)\n",
    "    factor = 8.6e4\n",
    "\n",
    "    cp = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.latitude,\n",
    "        factor * data[\"pr\"],\n",
    "        cmap=\"cmo.balance_r\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=src.utils.make_cb_range(amp, amp / 10),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ca1bc-02da-4b18-972a-e43663954ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify amplitudes for each plot\n",
    "sst_amp = 3.5\n",
    "pr_amp = 20\n",
    "\n",
    "## specify which month to look at\n",
    "sel = lambda x: x.sel(lag=2)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4.375), layout=\"constrained\")\n",
    "format_func = lambda ax,: src.utils.plot_setup_pac(ax, max_lat=20)\n",
    "axs = src.utils.subplots_with_proj(fig, nrows=3, ncols=2, format_func=format_func)\n",
    "\n",
    "## plot early\n",
    "cp0 = plot_sst_anom(axs[0, 0], sel(comp_early), amp=sst_amp)\n",
    "cp1 = plot_pr_anom(axs[0, 1], sel(comp_early))\n",
    "\n",
    "## plot late\n",
    "plot_sst_anom(axs[1, 0], sel(comp_late), amp=sst_amp)\n",
    "plot_pr_anom(axs[1, 1], sel(comp_late), amp=pr_amp)\n",
    "\n",
    "## plot diff\n",
    "cp0_diff = plot_sst_anom(\n",
    "    axs[2, 0],\n",
    "    sel(comp_late - comp_early),\n",
    "    amp=sst_amp,\n",
    ")\n",
    "\n",
    "cp1_diff = plot_pr_anom(\n",
    "    axs[2, 1],\n",
    "    sel(comp_late - comp_early),\n",
    "    amp=pr_amp,\n",
    ")\n",
    "\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axhline(0, c=\"k\", lw=0.8, alpha=0.5, ls=\"--\")\n",
    "\n",
    "## plot convective bounds\n",
    "for ax in axs[0, :]:\n",
    "    plot_contour(ax, sel(comp_early), lev=0, lw=2)\n",
    "    # plot_contour(ax, sel(comp_early), lev=-1, lw=1)\n",
    "\n",
    "for ax in axs[1, :]:\n",
    "    plot_contour(ax, sel(comp_late), lev=0, lw=2)\n",
    "    # plot_contour(ax, sel(comp_late), lev=-1, lw=1)\n",
    "\n",
    "for ax in axs[2]:\n",
    "    plot_contour(ax, sel(comp_early), lev=0, lw=2, c=\"gray\")\n",
    "    plot_contour(ax, sel(comp_late), lev=0, lw=2)\n",
    "\n",
    "## colorbars\n",
    "fig.colorbar(cp0, ax=axs[:, 0], ticks=[-4, 0, 4])\n",
    "fig.colorbar(cp1, ax=axs[:, 1], ticks=[-20, 0, 20])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90d4ae-09bb-4072-8639-0a05a8997307",
   "metadata": {},
   "source": [
    "## Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d294509-0588-40b7-8204-6ad0d4cc97c1",
   "metadata": {},
   "source": [
    "### Load heat budget data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e9b0b-7fc9-4a21-a761-503dc01243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to cesm data\n",
    "CESM_FP = DATA_FP / \"cesm\"\n",
    "\n",
    "\n",
    "def load_var(varname):\n",
    "    \"\"\"load variable from prepped folder\"\"\"\n",
    "\n",
    "    data = xr.open_mfdataset(\n",
    "        sorted(list(pathlib.Path(CESM_FP, f\"{varname}_temp\").glob(\"*.nc\"))),\n",
    "        concat_dim=\"member\",\n",
    "        combine=\"nested\",\n",
    "    )\n",
    "\n",
    "    return data.assign_coords({\"member\": np.arange(100)})\n",
    "\n",
    "\n",
    "## load data\n",
    "data = xr.merge([load_var(v) for v in [\"uet\", \"vnt\", \"wtt\"]])\n",
    "\n",
    "## update z-coord in WTT\n",
    "data[\"WTT\"] = (\n",
    "    data[\"WTT\"].rename({\"z_w_top\": \"z_t\"}).assign_coords({\"z_t\": data.z_t.values})\n",
    ")\n",
    "data = data.drop_vars(\"z_w_top\")\n",
    "\n",
    "## get total advection tendency\n",
    "data[\"ADV\"] = data[\"UET\"] + data[\"VNT\"] + data[\"WTT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c4a95-2912-4925-ba96-f563eaee92cc",
   "metadata": {},
   "source": [
    "### Merge and get forced component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e91e3-b2fa-4f28-83e2-0f1b999a80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge\n",
    "data = xr.merge([data, Th])\n",
    "\n",
    "## get early/late\n",
    "data_early = data.sel(time=slice(\"1850\", \"1879\")).compute()\n",
    "data_late = data.sel(time=slice(\"2071\", \"2100\")).compute()\n",
    "\n",
    "## get forced component\n",
    "forced_early, anom_early = src.utils.separate_forced(data_early)\n",
    "forced_late, anom_late = src.utils.separate_forced(data_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21481d8-2036-4a8b-890a-748f10352491",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91421830-7bae-4d9c-91e8-35df4a34332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress(data, y_var, x_vars):\n",
    "    \"\"\"multiple linear regression\"\"\"\n",
    "\n",
    "    ## Get covariates and targets\n",
    "    X = data[x_vars].to_dataarray(dim=\"i\")\n",
    "    Y = data[y_var]\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    YXt = xr.cov(Y, X, dim=[\"member\", \"time\"])\n",
    "    XXt = xr.cov(X, X.rename({\"i\": \"j\"}), dim=[\"member\", \"time\"])\n",
    "\n",
    "    ## invert XX^T\n",
    "    XXt_inv = xr.zeros_like(XXt)\n",
    "    XXt_inv.values = np.linalg.inv(XXt.values)\n",
    "\n",
    "    ## get least-squares fit, YX^T @ (XX^T)^{-1}\n",
    "    m = (YXt * XXt_inv).sum(\"i\")\n",
    "\n",
    "    return m.to_dataset(dim=\"j\")\n",
    "\n",
    "\n",
    "def regress_bymonth(data, y_var, x_vars):\n",
    "    \"\"\"do multiple linear regression for each month separately\"\"\"\n",
    "    return data.groupby(\"time.month\").map(regress, y_var=y_var, x_vars=x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad87a22-b644-4399-a419-948c0c75cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(x_vars=[\"T_34\"], y_var=\"ADV\")\n",
    "\n",
    "m_early = regress_bymonth(anom_early, **kwargs)[\"T_34\"]\n",
    "m_late = regress_bymonth(anom_late, **kwargs)[\"T_34\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf11ca1-ef53-4e57-80cc-31cd19beece6",
   "metadata": {},
   "source": [
    "Note: this is flux, not divergence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7b9e3-7a7d-4781-9fb3-b5674d9e87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEC_PER_MO = 8.64e4 * 30\n",
    "\n",
    "## specify which period/month to plot\n",
    "# sel = lambda x: x.mean(\"month\")\n",
    "sel = lambda x: x.sel(month=7)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 2.5), layout=\"constrained\")\n",
    "\n",
    "for ax, m in zip(axs[:2], [m_early, m_late]):\n",
    "\n",
    "    ## temperature\n",
    "    cp = ax.contourf(\n",
    "        m.lon,\n",
    "        m.z_t / 100,\n",
    "        SEC_PER_MO * sel(m),\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(500, 50),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "## difference\n",
    "axs[2].contourf(\n",
    "    m.lon,\n",
    "    m.z_t / 100,\n",
    "    SEC_PER_MO * sel(m_late - m_early),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=src.utils.make_cb_range(250, 25),\n",
    "    extend=\"both\",\n",
    ")\n",
    "## plot MLD\n",
    "# plot_mlds(axs=axs, sel=sel)\n",
    "\n",
    "## label\n",
    "cb = fig.colorbar(cp, ax=axs[2], ticks=[-10, 0, 10], label=r\"$K~\\text{yr}^{-1}$\")\n",
    "format_subsurf_axs(axs)\n",
    "for ax in axs:\n",
    "    ax.set_ylim([100, 5])\n",
    "    ax.axvline(190, ls=\"--\", c=\"w\", lw=0.8)\n",
    "    ax.axvline(240, ls=\"--\", c=\"w\", lw=0.8)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
