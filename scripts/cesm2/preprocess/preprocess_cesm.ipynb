{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287d082a-1ad3-4544-b5d8-25ad7a9da4e9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a29b8-4a30-45c8-99c2-7822bb9738b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import xeofs as xe\n",
    "import xesmf\n",
    "import time\n",
    "import src.utils\n",
    "import copy\n",
    "\n",
    "## specify filepath for data\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI for presentation\n",
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ee97b-5871-40d3-b923-bbf84af00c1a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23d1ad-616f-4b0d-9a45-d97095655d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(varname):\n",
    "    \"\"\"get files for given variable name\"\"\"\n",
    "\n",
    "    ## path to cesm2 data in MMLEA archive\n",
    "    cesm2_fp = pathlib.Path(\"/glade/campaign/collections/rda/data/d651039/cesm2_lens\")\n",
    "\n",
    "    ## check if ocean or atmosphere\n",
    "    is_oc = varname in [\"mlotst\", \"sos\", \"tos\", \"z20\", \"zos\"]\n",
    "\n",
    "    if is_oc:\n",
    "        data_fp = cesm2_fp / pathlib.Path(\"Omon\", varname)\n",
    "\n",
    "    else:\n",
    "        data_fp = cesm2_fp / pathlib.Path(\"Amon\", varname)\n",
    "\n",
    "    return sorted(data_fp.glob(\"*.nc\"))\n",
    "\n",
    "\n",
    "def check_member_file(i):\n",
    "    \"\"\"check zos and tos files match for given member idx\"\"\"\n",
    "    return str(get_files(\"tos\")[i])[-71:] == str(get_files(\"zos\")[i])[-71:]\n",
    "\n",
    "\n",
    "def check_member_files():\n",
    "    \"\"\"check all files match\"\"\"\n",
    "\n",
    "    checks = np.array([check_member_file(i) for i in range(100)])\n",
    "    return np.all(checks)\n",
    "\n",
    "\n",
    "def load_member_varname(member_idx, varname):\n",
    "    \"\"\"load ensemble member. Args:\n",
    "    - member_idx: integer in [0,99]\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get list of files\n",
    "    files = get_files(varname)\n",
    "\n",
    "    ## open data\n",
    "    data = xr.open_dataset(files[member_idx])\n",
    "\n",
    "    ## remove un-needed coords\n",
    "    data = data[varname].squeeze(drop=True)\n",
    "\n",
    "    ## rename lon/lat\n",
    "    data = data.rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_member_Th(member_idx):\n",
    "    \"\"\"Load T and h data for given member index\"\"\"\n",
    "\n",
    "    ## compute indices\n",
    "    T_idxs = src.utils.get_RO_T_indices(load_member_varname(member_idx, \"tos\"))\n",
    "    h_idxs = src.utils.get_RO_h_indices(load_member_varname(member_idx, \"zos\"))\n",
    "\n",
    "    ## compute indices\n",
    "    return xr.merge([T_idxs, h_idxs])\n",
    "\n",
    "\n",
    "def load_ensemble_Th(save_fp):\n",
    "    \"\"\"Load all ensemble members\"\"\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if save_fp.is_file():\n",
    "\n",
    "        data = xr.open_dataset(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## new dimension: ensemble member\n",
    "        member_dim = pd.Index(np.arange(100), name=\"member\")\n",
    "\n",
    "        ## do computation\n",
    "        data = xr.concat(\n",
    "            [load_member_Th(i) for i in tqdm.tqdm(member_dim)],\n",
    "            dim=member_dim,\n",
    "        )\n",
    "\n",
    "        ## save to file\n",
    "        data.to_netcdf(save_fp)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_Th(Th, save_dir):\n",
    "    \"\"\"pre-process Th data (compute ensemble mean and anomalies\"\"\"\n",
    "\n",
    "    ## define filepaths for saving\n",
    "    save_fp_emean = pathlib.Path(save_dir, \"Th_emean.nc\")\n",
    "    save_fp_anom = pathlib.Path(save_dir, \"Th_anom.nc\")\n",
    "\n",
    "    ## compute ensemble mean and anomalies\n",
    "    Th_emean = Th.mean(\"member\")\n",
    "    Th_anom = Th - Th_emean\n",
    "\n",
    "    ## save to file if not already\n",
    "    if not save_fp_emean.is_file():\n",
    "        Th_emean.to_netcdf(save_fp_emean)\n",
    "\n",
    "    if not save_fp_anom.is_file():\n",
    "        Th_anom.to_netcdf(save_fp_anom)\n",
    "\n",
    "    return Th_emean, Th_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ccc04f-88a3-4dbd-8f9f-b60e7969da3b",
   "metadata": {},
   "source": [
    "## $T$, $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754e570-3e6e-49bb-92e7-562f82190cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save file paths\n",
    "save_dir = DATA_FP / \"cesm\"\n",
    "\n",
    "## load data\n",
    "Th = load_ensemble_Th(save_dir / \"Th.nc\")\n",
    "\n",
    "## compute ensemble stats/anomalies\n",
    "Th_emean, Th_anom = preprocess_Th(Th, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494f9c0-9ca3-490b-9f9d-1d4ae25241eb",
   "metadata": {},
   "source": [
    "## tropical SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610bb042-56f2-4e84-917e-657aec5ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_member_trop_sst(member_idx):\n",
    "    \"\"\"Load T and h data for given member index\"\"\"\n",
    "\n",
    "    ## load sst data\n",
    "    sst = load_member_varname(member_idx, \"tos\")\n",
    "\n",
    "    ## compute sst averaged over various lat bands\n",
    "    avgs = []\n",
    "    bands = np.arange(5, 35, 5)\n",
    "    for b in bands:\n",
    "        avg = sst.sel(latitude=slice(-b, b)).mean([\"latitude\", \"longitude\"])\n",
    "        avgs.append(avg.rename(f\"trop_sst_{b:02d}\"))\n",
    "\n",
    "    return xr.merge(avgs)\n",
    "\n",
    "\n",
    "def load_ensemble_trop_sst(save_fp):\n",
    "    \"\"\"Load all ensemble members\"\"\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if save_fp.is_file():\n",
    "\n",
    "        data = xr.open_dataset(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## new dimension: ensemble member\n",
    "        member_dim = pd.Index(np.arange(100), name=\"member\")\n",
    "\n",
    "        ## do computation\n",
    "        data = xr.concat(\n",
    "            [load_member_trop_sst(i) for i in tqdm.tqdm(member_dim)],\n",
    "            dim=member_dim,\n",
    "        )\n",
    "\n",
    "        ## save to file\n",
    "        data.to_netcdf(save_fp)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd712ab4-ad76-4b56-8066-5676966d72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save file paths\n",
    "save_fp = pathlib.Path(DATA_FP, \"cesm\", \"trop_sst.nc\")\n",
    "\n",
    "## load data\n",
    "trop_sst = load_ensemble_trop_sst(save_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4847b4-07b0-4f67-adc4-dd6dca4857d6",
   "metadata": {},
   "source": [
    "## ELI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48727b8e-5b8f-4690-88cd-b33868b1d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eli(sst_trop):\n",
    "    \"\"\"compute ELI from tropical SST data\"\"\"\n",
    "\n",
    "    ## get relative SST\n",
    "    rsst = sst_trop - sst_trop.mean([\"latitude\", \"longitude\"])\n",
    "\n",
    "    ## get SST in tropical Pac\n",
    "    rsst_pac = rsst.sel(longitude=slice(140, 285))\n",
    "\n",
    "    ## get boolean array where SST exceeds thresh\n",
    "    exceeds_thresh = rsst_pac >= 0\n",
    "\n",
    "    ## sum and count longitudes exceeding thresh\n",
    "    longitude_sum = (exceeds_thresh * rsst_pac[\"longitude\"]).sum(\n",
    "        [\"longitude\", \"latitude\"]\n",
    "    )\n",
    "    longitude_count = exceeds_thresh.sum([\"longitude\", \"latitude\"])\n",
    "\n",
    "    ## eli is average longitude\n",
    "    eli = longitude_sum / longitude_count\n",
    "\n",
    "    return eli\n",
    "\n",
    "\n",
    "def load_member_eli(member_idx):\n",
    "    \"\"\"Load eli data for given member index\"\"\"\n",
    "\n",
    "    ## load sst data\n",
    "    sst = load_member_varname(member_idx, \"tos\")\n",
    "\n",
    "    ## compute sst averaged over various lat bands\n",
    "    eli = []\n",
    "    bands = np.arange(5, 35, 5)\n",
    "    for b in bands:\n",
    "\n",
    "        ## get sst subset\n",
    "        sst_band = sst.sel(latitude=slice(-b, b))\n",
    "\n",
    "        ## get ELI\n",
    "        eli_ = get_eli(sst_band)\n",
    "        eli.append(eli_.rename(f\"eli_{b:02d}\"))\n",
    "\n",
    "    return xr.merge(eli)\n",
    "\n",
    "\n",
    "def load_ensemble_eli(save_fp):\n",
    "    \"\"\"Load all ensemble members\"\"\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if save_fp.is_file():\n",
    "\n",
    "        data = xr.open_dataset(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## new dimension: ensemble member\n",
    "        member_dim = pd.Index(np.arange(100), name=\"member\")\n",
    "\n",
    "        ## do computation\n",
    "        data = xr.concat(\n",
    "            [load_member_eli(i) for i in tqdm.tqdm(member_dim)],\n",
    "            dim=member_dim,\n",
    "        )\n",
    "\n",
    "        ## save to file\n",
    "        data.to_netcdf(save_fp)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a5a9e-b302-41b2-bf62-f68458dd4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save file paths\n",
    "save_fp = pathlib.Path(DATA_FP, \"cesm\", \"eli.nc\")\n",
    "\n",
    "## load data\n",
    "eli = load_ensemble_eli(save_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977598a-b9b4-43b8-99fb-6948d3c947d1",
   "metadata": {},
   "source": [
    "## EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c78cf-6d75-4f5f-b813-baf7c4dbab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_to_eq_pac(data):\n",
    "    \"\"\"trim data to eq. Pac\"\"\"\n",
    "\n",
    "    ## specfy\n",
    "    lonlat_idx = dict(longitude=slice(100, 300), latitude=slice(-30, 30))\n",
    "\n",
    "    return data.sel(lonlat_idx)\n",
    "\n",
    "\n",
    "def load_ensemble(varname, trim_fn=None):\n",
    "    \"\"\"load spatial data for given variable\"\"\"\n",
    "\n",
    "    ## specify loading function\n",
    "    if trim_fn is None:\n",
    "        load = lambda i: load_member_varname(i, varname)\n",
    "\n",
    "    else:\n",
    "        load = lambda i: trim_fn(load_member_varname(i, varname))\n",
    "\n",
    "    ## new dimension: ensemble member\n",
    "    member_dim = pd.Index(np.arange(100), name=\"member\")\n",
    "\n",
    "    ## load data\n",
    "    data = xr.concat([load(i) for i in tqdm.tqdm(member_dim)], dim=member_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_eofs(varname):\n",
    "    \"\"\"compute/load eofs for given variable\"\"\"\n",
    "\n",
    "    ## get filename\n",
    "    filename = DATA_FP / pathlib.Path(f\"cesm/eofs_{varname}.nc\")\n",
    "\n",
    "    ## try to load pre-computed EOFs\n",
    "    if filename.is_file():\n",
    "        eofs = src.utils.load_eofs(filename)\n",
    "\n",
    "    ## if not pre-computed, do the computation here...\n",
    "    else:\n",
    "        data = load_ensemble(varname, trim_fn=trim_to_eq_pac)\n",
    "\n",
    "        ## specs for EOFs\n",
    "        eofs_kwargs = dict(\n",
    "            n_modes=300, standardize=False, use_coslat=True, center=False\n",
    "        )\n",
    "\n",
    "        ## initialize EOF model\n",
    "        eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "        ## compute\n",
    "        eofs.fit(data, dim=[\"time\", \"member\"])\n",
    "\n",
    "        ## save to file\n",
    "        eofs.save(filename, engine=\"netcdf4\")\n",
    "\n",
    "    return eofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff6502-31f7-45fb-baee-72486e1f1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nloading TOS EOFs...\")\n",
    "eofs_tos = compute_eofs(\"tos\")\n",
    "\n",
    "print(f\"\\nloading ZOS EOFs...\")\n",
    "eofs_tos = compute_eofs(\"zos\")\n",
    "\n",
    "print(f\"\\nloading tauu EOFs...\")\n",
    "eofs_tauu = compute_eofs(\"tauu\")\n",
    "\n",
    "print(f\"\\nloading pr EOFs...\")\n",
    "eofs_tauu = compute_eofs(\"pr\")\n",
    "\n",
    "print(f\"\\nloading mixed layer EOFs...\")\n",
    "eofs_mlotst = compute_eofs(\"mlotst\")\n",
    "\n",
    "print(f\"\\nloading tauv EOFs...\")\n",
    "eofs_tauv = compute_eofs(\"tauv\")\n",
    "\n",
    "print(f\"\\nloading z20 EOFs...\")\n",
    "eofs_z20 = compute_eofs(\"z20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3bc0ce-b64e-4c3c-a26a-1b57aa91a54e",
   "metadata": {},
   "source": [
    "## surface heat flux data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f442bcd-2621-47d0-a8a9-eb6a1cde946b",
   "metadata": {},
   "source": [
    "### First, compute for each ensemble member"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e62fd-cff1-4b99-9eac-f8d65a25039b",
   "metadata": {},
   "source": [
    "[Link to heat flux calculation](https://bb.cgd.ucar.edu/cesm/threads/sign-definition-about-shflx-lhflx.8301/)  \n",
    "\"FSNS (net shortwave) is defined as positive into the surface\n",
    "FLNS (net longwave), LHFLX (latent heat), and SHFLX (sensible heat) are defined as positive into the atmosphere\":\n",
    "```Fnet_sfc = FSNS - FLNS - LHFLX - SHFLX```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8d6c9-9ce5-46f6-aed9-735ebc769d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_ids():\n",
    "    \"\"\"get files for given variable name\"\"\"\n",
    "\n",
    "    ## path to cesm2 lens data\n",
    "    cesm2_fp = pathlib.Path(\n",
    "        \"/glade/campaign/collections/rda/data/d651056/CESM2-LE/atm/proc/tseries/month_1\"\n",
    "    )\n",
    "\n",
    "    ## path to FSNS (arbitrary, just want the ids)\n",
    "    data_fp = cesm2_fp / \"FSNS\"\n",
    "\n",
    "    ## get list of ensemble ids\n",
    "    ensemble_ids = []\n",
    "    for f in data_fp.glob(\"*.nc\"):\n",
    "        ensemble_ids.append(str(f)[-54:-29])\n",
    "\n",
    "    ## get unique values and sort\n",
    "    ensemble_ids = sorted(list(set(ensemble_ids)))\n",
    "\n",
    "    return ensemble_ids\n",
    "\n",
    "\n",
    "def trim_to_eq_pac_CAM(data):\n",
    "    \"\"\"trim data to eq. Pac\"\"\"\n",
    "\n",
    "    ## specfy\n",
    "    lonlat_idx = dict(lon=slice(100, 300), lat=slice(-30, 30))\n",
    "\n",
    "    return data.sel(lonlat_idx)\n",
    "\n",
    "\n",
    "def load_var(varname, ensemble_id):\n",
    "    \"\"\"Load variable for given ensemble ID\"\"\"\n",
    "\n",
    "    ## get path to data\n",
    "    cesm2_fp = pathlib.Path(\n",
    "        \"/glade/campaign/collections/rda/data/d651056/CESM2-LE/atm/proc/tseries/month_1\"\n",
    "    )\n",
    "\n",
    "    ## path to FSNS (arbitrary, just want the ids)\n",
    "    data_fp = cesm2_fp / varname\n",
    "\n",
    "    ## open data for ensemble member\n",
    "    data = xr.open_mfdataset(data_fp.glob(f\"*{ensemble_id}*.nc\"))\n",
    "\n",
    "    ## trim to eq Pac\n",
    "    data = trim_to_eq_pac_CAM(data).compute()\n",
    "\n",
    "    ## rename coords (to match reference grid)\n",
    "    data = data[varname].rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "\n",
    "    ## open reference grid\n",
    "    ref_fp = pathlib.Path(DATA_FP, \"cesm\", \"eofs_tos.nc\")\n",
    "    ref = src.utils.load_eofs(ref_fp).components().isel(mode=0)\n",
    "\n",
    "    ## interpolate to reference grid\n",
    "    data = data.interp_like(ref)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_nhf(ensemble_id):\n",
    "    \"\"\"Load net heat flux for given ensemble id\"\"\"\n",
    "\n",
    "    ## Load individual components\n",
    "    FSNS = load_var(\"FSNS\", ensemble_id)\n",
    "    FLNS = load_var(\"FLNS\", ensemble_id)\n",
    "    LHFLX = load_var(\"LHFLX\", ensemble_id)\n",
    "    SHFLX = load_var(\"SHFLX\", ensemble_id)\n",
    "\n",
    "    return FSNS - FLNS - LHFLX - SHFLX\n",
    "\n",
    "\n",
    "def compute_nhf_ensemble(temp_dir):\n",
    "    \"\"\"compute net heat flux for full ensemble. Save to temp directory\"\"\"\n",
    "\n",
    "    ## get ensemble ids\n",
    "    ensemble_ids = get_ensemble_ids()\n",
    "\n",
    "    ## loop through members\n",
    "    for i in tqdm.tqdm(ensemble_ids):\n",
    "\n",
    "        ## save filepath\n",
    "        save_fp = pathlib.Path(temp_dir, f\"nhf_{i}.nc\")\n",
    "\n",
    "        if save_fp.is_file():\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            nhf = compute_nhf(i)\n",
    "            nhf.to_netcdf(save_fp)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def compute_flux_ensemble(varname, temp_dir):\n",
    "    \"\"\"compute net heat flux for full ensemble. Save to temp directory\"\"\"\n",
    "\n",
    "    ## get ensemble ids\n",
    "    ensemble_ids = get_ensemble_ids()\n",
    "\n",
    "    ## loop through members\n",
    "    for i in tqdm.tqdm(ensemble_ids):\n",
    "\n",
    "        ## save filepath\n",
    "        save_fp = pathlib.Path(temp_dir, f\"{varname}_{i}.nc\")\n",
    "\n",
    "        if save_fp.is_file():\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            flux = load_var(varname=varname, ensemble_id=i)\n",
    "            flux.to_netcdf(save_fp)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd33e5-9824-4b09-9449-246f16ffe30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=24)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5aeb61-a422-4bf0-8c3c-12907461d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute nhf for each file\n",
    "# compute_nhf_ensemble(pathlib.Path(DATA_FP, \"cesm\", \"nhf_temp\"))\n",
    "\n",
    "## compute component fluxes\n",
    "CESM_FP = pathlib.Path(DATA_FP, \"cesm\")\n",
    "for varname in [\"FSNS\", \"FLNS\", \"LHFLX\", \"SHFLX\"]:\n",
    "    compute_flux_ensemble(varname=varname, temp_dir=CESM_FP / f\"{varname.lower()}_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a71418-0776-42e2-8edf-5c899f2a8c57",
   "metadata": {},
   "source": [
    "### Then, compute EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27d5e5-5ad2-4a9a-b5d1-7d0e72312d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = []\n",
    "for i, (f0, f1) in enumerate(zip(get_files(\"tos\"), get_ensemble_ids())):\n",
    "\n",
    "    ## get names for each\n",
    "    n0 = f\"{str(f0)[-59:-55]} {str(f0)[-36:-28]}\"\n",
    "    n1 = f\"{f1[:4]} {f1[-8:]}\"\n",
    "\n",
    "    ## check they match\n",
    "    checks.append(n0 == n1)\n",
    "\n",
    "print(all(checks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d46823-89f7-4556-bbee-526869939d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nhf_ensemble():\n",
    "    \"\"\"load spatial data for NHF\"\"\"\n",
    "\n",
    "    ## new dimension: ensemble member\n",
    "    member_dim = pd.Index(get_ensemble_ids(), name=\"member\")\n",
    "\n",
    "    ## load data\n",
    "    load_fp = pathlib.Path(DATA_FP, \"cesm\", \"nhf_temp\")\n",
    "    data = [xr.open_dataarray(load_fp / f\"nhf_{i}.nc\") for i in tqdm.tqdm(member_dim)]\n",
    "    data = xr.concat(data, dim=member_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_nhf_eofs():\n",
    "    \"\"\"compute/load eofs for given variable\"\"\"\n",
    "\n",
    "    ## get filename\n",
    "    filename = DATA_FP / pathlib.Path(f\"cesm/eofs_nhf.nc\")\n",
    "\n",
    "    ## try to load pre-computed EOFs\n",
    "    if filename.is_file():\n",
    "        eofs = src.utils.load_eofs(filename)\n",
    "\n",
    "    ## if not pre-computed, do the computation here...\n",
    "    else:\n",
    "        data = load_nhf_ensemble()\n",
    "\n",
    "        ## specs for EOFs\n",
    "        eofs_kwargs = dict(\n",
    "            n_modes=300, standardize=False, use_coslat=True, center=False\n",
    "        )\n",
    "\n",
    "        ## initialize EOF model\n",
    "        eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "        ## compute\n",
    "        eofs.fit(data, dim=[\"time\", \"member\"])\n",
    "\n",
    "        ## save to file\n",
    "        eofs.save(filename, engine=\"netcdf4\")\n",
    "\n",
    "    return eofs\n",
    "\n",
    "\n",
    "def load_flux_ensemble(varname):\n",
    "    \"\"\"load spatial data for flux variable\"\"\"\n",
    "\n",
    "    ## new dimension: ensemble member\n",
    "    member_dim = pd.Index(get_ensemble_ids(), name=\"member\")\n",
    "\n",
    "    ## load data\n",
    "    load_fp = pathlib.Path(DATA_FP, \"cesm\", f\"{varname.lower()}_temp\")\n",
    "    data = [\n",
    "        xr.open_dataarray(load_fp / f\"{varname}_{i}.nc\") for i in tqdm.tqdm(member_dim)\n",
    "    ]\n",
    "    data = xr.concat(data, dim=member_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_flux_eofs(varname):\n",
    "    \"\"\"compute/load eofs for given variable\"\"\"\n",
    "\n",
    "    ## get filename\n",
    "    filename = DATA_FP / pathlib.Path(f\"cesm/eofs_{varname.lower()}.nc\")\n",
    "\n",
    "    ## try to load pre-computed EOFs\n",
    "    if filename.is_file():\n",
    "        eofs = src.utils.load_eofs(filename)\n",
    "\n",
    "    ## if not pre-computed, do the computation here...\n",
    "    else:\n",
    "        data = load_flux_ensemble(varname)\n",
    "\n",
    "        ## specs for EOFs\n",
    "        eofs_kwargs = dict(\n",
    "            n_modes=300, standardize=False, use_coslat=True, center=False\n",
    "        )\n",
    "\n",
    "        ## initialize EOF model\n",
    "        eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "        ## compute\n",
    "        eofs.fit(data, dim=[\"time\", \"member\"])\n",
    "\n",
    "        ## save to file\n",
    "        eofs.save(filename, engine=\"netcdf4\")\n",
    "\n",
    "    return eofs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd970e71-64b2-4f5b-b948-f025bdb2d292",
   "metadata": {},
   "source": [
    "Net heat flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69f73e-0196-4a19-ba09-237bf9a7e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nloading NHF EOFs...\")\n",
    "\n",
    "t0 = time.time()\n",
    "eofs_nhf = compute_nhf_eofs()\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Elapsed time: {t1-t0:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12137016-fb1d-48b1-aad0-904664952288",
   "metadata": {},
   "source": [
    "Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630dcc8-ef41-4fa2-8702-269d72ae7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname in [\"FSNS\", \"FLNS\", \"LHFLX\", \"SHFLX\"]:\n",
    "    compute_flux_eofs(varname=varname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aac04f-9621-437a-8652-d4ae26d739d1",
   "metadata": {},
   "source": [
    "## Ocean data (subsurface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b372172-c56f-4b17-95f4-b9894e8cb2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subsurf_ensemble(varname):\n",
    "    \"\"\"load subsurface data\"\"\"\n",
    "\n",
    "    ## Get list of files and member idx\n",
    "    # load_fp = pathlib.Path(DATA_FP, \"cesm\", f\"{varname}_temp_v2\")\n",
    "    load_fp = pathlib.Path(DATA_FP, \"cesm\", f\"{varname}_temp\")\n",
    "    files = list(sorted(load_fp.glob(\"*.nc\")))\n",
    "    member_id = pd.Index([str(f)[-28:-3] for f in files], name=\"member_id\")\n",
    "\n",
    "    # ## load data (loop method)\n",
    "    # data = [xr.open_dataarray(f) for f in files]\n",
    "    # data = xr.concat(data, dim=member_id)\n",
    "\n",
    "    ## load data (dask method?)\n",
    "    data = xr.open_mfdataset(\n",
    "        files,\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"member_id\",\n",
    "        chunks={\"time\": 720},\n",
    "    )\n",
    "    data = data.assign_coords({\"member_id\": member_id})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_subsurf_eofs(varname):\n",
    "    \"\"\"compute/load eofs for given variable\"\"\"\n",
    "\n",
    "    ## get filename\n",
    "    filename = DATA_FP / pathlib.Path(f\"cesm/eofs_{varname}.nc\")\n",
    "\n",
    "    ## try to load pre-computed EOFs\n",
    "    if filename.is_file():\n",
    "        eofs = src.utils.load_eofs(filename)\n",
    "\n",
    "    ## if not pre-computed, do the computation here...\n",
    "    else:\n",
    "        data = load_subsurf_ensemble(varname)\n",
    "\n",
    "        ## specs for EOFs\n",
    "        eofs_kwargs = dict(n_modes=300, standardize=False, center=False)\n",
    "\n",
    "        ## initialize EOF model\n",
    "        eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "        ## compute\n",
    "        eofs.fit(data, dim=[\"time\", \"member_id\"])\n",
    "\n",
    "        ## save to file\n",
    "        try:\n",
    "            eofs.save(filename, engine=\"netcdf4\")\n",
    "\n",
    "        except:\n",
    "\n",
    "            ## extract information (avoids saving issue)\n",
    "            components = eofs.components().to_dataarray()\n",
    "            components = components.squeeze().rename(\"components\")\n",
    "            scores = eofs.scores()\n",
    "            del scores.attrs[\"solver_kwargs\"]\n",
    "\n",
    "            ## netcdf with data\n",
    "            eof_data = xr.merge([scores, components])\n",
    "\n",
    "            ## save to file\n",
    "            eof_data.to_netcdf(filename)\n",
    "\n",
    "    return eofs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805f12f-23b6-4e86-b082-4572dd51b41e",
   "metadata": {},
   "source": [
    "Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59617db6-07dc-4f00-bae9-ca928c2219dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\nloading subsurf. temp EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_temp = compute_subsurf_eofs(\"temp\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading subsurf. wvel EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_wvel = compute_subsurf_eofs(\"wvel\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading subsurf. WTT EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_wvel = compute_subsurf_eofs(\"wtt\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading subsurf. UET EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_wvel = compute_subsurf_eofs(\"uet\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading subsurf. UVEL EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_wvel = compute_subsurf_eofs(\"uvel_sub\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading 3d VVEL EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_vvel_3d = compute_subsurf_eofs(\"vvel_3d\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading 3d TEMP EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_temp_3d = compute_subsurf_eofs(\"temp_3d\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading 3d UVEL EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_uvel_3d = compute_subsurf_eofs(\"uvel_3d\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "# print(f\"\\nloading 3d WVEL EOFs...\")\n",
    "# t0 = time.time()\n",
    "# eofs_wvel_3d = compute_subsurf_eofs(\"wvel_3d\")\n",
    "# t1 = time.time()\n",
    "# print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "print(f\"\\nloading 3d VNT EOFs...\")\n",
    "t0 = time.time()\n",
    "eofs_vnt = compute_subsurf_eofs(\"vnt\")\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {t1-t0:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144c0c0-9a26-4c8b-9c44-6e3c2ab2d55c",
   "metadata": {},
   "source": [
    "### Demo for NaN filling / lazy evaluation\n",
    "See: https://xeofs.readthedocs.io/en/develop/content/user_guide/core_functionalities/dask_support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33d38c-903a-4a09-8966-9dc3ed1157a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load test data\n",
    "# d = load_subsurf_ensemble(\"vvel_3d\")\n",
    "# e = d.isel(member_id=slice(0,2))\n",
    "# e.load();\n",
    "\n",
    "# ## find NaN values\n",
    "# nan_idx = np.isnan(e.isel(member_id=0)).all(\"time\").drop_vars(\"member_id\")\n",
    "\n",
    "# ## fill with zero(?)\n",
    "# e.where(~nan_idx, other=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bc1cb-7c17-4a0b-9c31-8c549fe3f6b6",
   "metadata": {},
   "source": [
    "### Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc7308-ec4d-47f0-8aa4-3681961e5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_load_fp = pathlib.Path(DATA_FP, \"cesm\", \"temp_temp_v2\")\n",
    "temp = xr.open_dataarray(sorted(list(temp_load_fp.glob(\"*.nc\")))[0])\n",
    "\n",
    "wvel_load_fp = pathlib.Path(DATA_FP, \"cesm\", \"wvel_temp_v2\")\n",
    "wvel = xr.open_dataarray(sorted(list(wvel_load_fp.glob(\"*.nc\")))[0])\n",
    "\n",
    "data = xr.merge([temp.rename(\"T\"), wvel.rename(\"w\")])\n",
    "\n",
    "data.load()\n",
    "d = data.mean(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a1517-815c-41f8-9c32-425fdb325571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "ax.contourf(\n",
    "    d[\"T\"].lon,\n",
    "    d[\"T\"].z_t / 100,\n",
    "    d[\"T\"],\n",
    "    cmap=\"cmo.thermal\",\n",
    "    levels=np.arange(12, 32, 2),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cp = ax.contour(\n",
    "    d[\"w\"].lon,\n",
    "    d[\"w\"].z_w_top / 100,\n",
    "    d[\"w\"],\n",
    "    colors=\"k\",\n",
    "    levels=src.utils.make_cb_range(0.0016, 0.00032),\n",
    "    extend=\"both\",\n",
    "    linewidths=1,\n",
    ")\n",
    "# cb = fig.colorbar(cp)\n",
    "\n",
    "\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287cacc1-561a-43af-ae51-6dce00b2ed59",
   "metadata": {},
   "source": [
    "## Ocean data (surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0a65a-6cdc-4a98-86d8-c791a37c5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grid(lon_range, lat_range):\n",
    "    \"\"\"Create mask from OISST data on cloud\"\"\"\n",
    "\n",
    "    ## load sst data\n",
    "    sst = xr.open_dataset(\n",
    "        r\"http://psl.noaa.gov/thredds/dodsC/Datasets/noaa.oisst.v2/new/sst.oisst.mon.ltm.1991-2020.nc\",\n",
    "        decode_times=False,\n",
    "    )\n",
    "    sst = sst[\"sst\"].isel(time=0).drop_vars(\"time\")\n",
    "\n",
    "    ## convert to lsm (fill ones over ocean)\n",
    "    lsm = sst.where(np.isnan(sst), other=1.0)\n",
    "\n",
    "    ## sel lon/lat range\n",
    "    lsm = lsm.sel(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "\n",
    "    # ## add binary mask for regridding\n",
    "    lsm[\"mask\"] = ~np.isnan(lsm)\n",
    "\n",
    "    return lsm\n",
    "\n",
    "\n",
    "def load_ocn_surf_ensemble(varname):\n",
    "    \"\"\"load subsurface data\"\"\"\n",
    "\n",
    "    ## Get list of files and member idx\n",
    "    load_fp = pathlib.Path(DATA_FP, \"cesm\", f\"{varname}_temp\")\n",
    "    files = list(sorted(load_fp.glob(\"*.nc\")))\n",
    "    member_id = pd.Index([str(f)[-28:-3] for f in files], name=\"member_id\")\n",
    "\n",
    "    ## load data\n",
    "    data = xr.open_mfdataset(\n",
    "        files,\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"member_id\",\n",
    "    )\n",
    "    data = data.assign_coords({\"member_id\": member_id})\n",
    "\n",
    "    ## load into memory\n",
    "    data.load()\n",
    "\n",
    "    ## rename coords for regridding\n",
    "    data = data.rename({\"ULONG\": \"lon\", \"ULAT\": \"lat\"})\n",
    "\n",
    "    ## regrid\n",
    "    grid = load_grid(lon_range=[120, 300], lat_range=[-15, 15])\n",
    "    regridder = xesmf.Regridder(data, grid, \"bilinear\")\n",
    "    data_regrid = regridder(data)\n",
    "\n",
    "    return data_regrid.drop_vars(\"mask\")\n",
    "\n",
    "\n",
    "def compute_ocn_surf_eofs(varname):\n",
    "    \"\"\"compute/load eofs for given variable\"\"\"\n",
    "\n",
    "    ## get filename\n",
    "    filename = DATA_FP / pathlib.Path(f\"cesm/eofs_{varname}.nc\")\n",
    "\n",
    "    ## try to load pre-computed EOFs\n",
    "    if filename.is_file():\n",
    "        eofs = src.utils.load_eofs(filename)\n",
    "\n",
    "    ## if not pre-computed, do the computation here...\n",
    "    else:\n",
    "        data = load_ocn_surf_ensemble(varname).compute()\n",
    "\n",
    "        ## specs for EOFs\n",
    "        eofs_kwargs = dict(\n",
    "            n_modes=300, standardize=False, use_coslat=True, center=False\n",
    "        )\n",
    "\n",
    "        ## initialize EOF model\n",
    "        eofs = xe.single.EOF(**eofs_kwargs)\n",
    "\n",
    "        ## compute\n",
    "        eofs.fit(data, dim=[\"time\", \"member_id\"])\n",
    "\n",
    "        ## extract information (avoids saving issue\n",
    "        components = eofs.components().to_dataarray()\n",
    "        components = components.squeeze().rename(\"components\")\n",
    "        scores = eofs.scores()\n",
    "        del scores.attrs[\"solver_kwargs\"]\n",
    "\n",
    "        eof_data = xr.merge([scores, components])\n",
    "\n",
    "        ## save to file\n",
    "        eof_data.to_netcdf(filename)\n",
    "\n",
    "    return eof_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde6785-f0b5-462f-911c-42c7e36254c9",
   "metadata": {},
   "source": [
    "#### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc3bb4-a8e8-44f5-9322-4015f4eec44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nloading uvel EOFs...\")\n",
    "t0 = time.time()\n",
    "eofs_uvel = compute_ocn_surf_eofs(\"uvel\")\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {t1-t0:.1f} seconds\")\n",
    "\n",
    "print(f\"\\nloading vvel EOFs...\")\n",
    "t0 = time.time()\n",
    "eofs_vvel = compute_ocn_surf_eofs(\"vvel\")\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {t1-t0:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901362a-abf2-432a-a4d4-65a46fcb28e4",
   "metadata": {},
   "source": [
    "## CVDP indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7519e-b3dc-4050-aa3a-2e33f4d20c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cvdp_file(member_id):\n",
    "    \"\"\"Get filename corresponding to given ensemble id\"\"\"\n",
    "\n",
    "    ## Get filename for corresponding spatial data\n",
    "    orig_filename = str(get_files(\"tos\")[member_id])\n",
    "\n",
    "    ## get year initialization and member idx\n",
    "    year_init = orig_filename[-36:-32]\n",
    "    idx = orig_filename[-31:-28]\n",
    "\n",
    "    ## get updated filename\n",
    "    filename = f\"CESM2-LENS_{year_init}.{idx}.cvdp_data.1850-2100.nc\"\n",
    "\n",
    "    ## get path to data\n",
    "    cvdp_fp = DATA_FP / pathlib.Path(\"cesm/cvdp_output\")\n",
    "\n",
    "    return cvdp_fp / filename\n",
    "\n",
    "\n",
    "def load_member_cvdp_idxs(member_id):\n",
    "    \"\"\"Load CVDP indices for given member\"\"\"\n",
    "\n",
    "    ## get filename\n",
    "    filename = get_cvdp_file(member_id)\n",
    "\n",
    "    ## open data\n",
    "    data = xr.open_dataset(filename, decode_times=False)\n",
    "\n",
    "    ## extract given variable names\n",
    "    names = [\n",
    "        \"indian_ocean_dipole\",\n",
    "        \"nino34\",\n",
    "        \"north_pacific_meridional_mode\",\n",
    "        \"south_pacific_meridional_mode\",\n",
    "        \"tropical_indian_ocean\",\n",
    "        \"north_tropical_atlantic\",\n",
    "        \"atlantic_nino\",\n",
    "    ]\n",
    "\n",
    "    return data[names]\n",
    "\n",
    "\n",
    "def load_cvdp_idxs():\n",
    "    \"\"\"Load CVDP data for all members\"\"\"\n",
    "\n",
    "    ## ensemble member index\n",
    "    member_idx = pd.Index(np.arange(100), name=\"member\")\n",
    "\n",
    "    ## load indices and concatenate\n",
    "    data = xr.concat(\n",
    "        [load_member_cvdp_idxs(i) for i in tqdm.tqdm(member_idx)], dim=member_idx\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06617731-d997-4499-939b-dd5968574c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify save file paths\n",
    "save_dir = DATA_FP / \"cesm\"\n",
    "\n",
    "## load data\n",
    "cvdp_total = load_cvdp_idxs()\n",
    "\n",
    "## compute anomalies\n",
    "cvdp_anom = cvdp_total - cvdp_total.mean(\"member\")\n",
    "\n",
    "## save to file\n",
    "cvdp_anom.to_netcdf(save_dir / \"cvdp_anom.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
