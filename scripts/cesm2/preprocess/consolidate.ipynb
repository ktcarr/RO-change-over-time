{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b73c20-e94b-4920-a8a0-7bf2ef9c707b",
   "metadata": {},
   "source": [
    "# Consolidate\n",
    "Merge EOF data for faster loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045207b5-1568-479b-9df5-51265f5ddc3c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f4eb35-a3b9-483f-b70e-520a45d01941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib\n",
    "import src.utils\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36564d-e841-4bec-9b62-93ac602d0626",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95ab946-45a6-4b31-a56b-751288f2606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lon_coord(data_sub):\n",
    "    \"\"\"fix longitude coordinate on subsurface data\"\"\"\n",
    "\n",
    "    data_sub = data_sub.assign_coords({\"nlon\": data_sub.lon.isel(z_t=0).values})\n",
    "    data_sub = data_sub.drop_vars(\"lon\").rename({\"nlon\": \"lon\"})\n",
    "\n",
    "    return data_sub\n",
    "\n",
    "\n",
    "def convert_cm_to_m_helper(data, z_coord_name):\n",
    "    \"\"\"convert z-coord from cm to m\"\"\"\n",
    "    return data.assign_coords({z_coord_name: data[z_coord_name].values / 100})\n",
    "\n",
    "\n",
    "def convert_cm_to_m(data):\n",
    "    \"\"\"convert all z-coords from cm to m\"\"\"\n",
    "\n",
    "    ## convert both z-coordinates\n",
    "    for z_coord in [\"z_t\", \"z_w_top\"]:\n",
    "        data = convert_cm_to_m_helper(data, z_coord_name=z_coord)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_sub():\n",
    "    \"\"\"load subsurface data\"\"\"\n",
    "\n",
    "    ## path to EOF data\n",
    "    eofs_fp = pathlib.Path(os.environ[\"DATA_FP\"], \"cesm\")\n",
    "\n",
    "    ## variables to load (and how to rename them)\n",
    "    names = [\n",
    "        \"temp\",\n",
    "        \"wvel\",\n",
    "        \"uvel_sub\",\n",
    "    ]\n",
    "    newnames = [\"T\", \"w\", \"u\"]\n",
    "\n",
    "    ## load the EOFs\n",
    "    load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "    eofs_sub = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "    ## for convenience, put spatial patterns / components in single dataset\n",
    "    components_sub = xr.merge(\n",
    "        [eofs_.components().rename(y) for (y, eofs_) in eofs_sub.items()]\n",
    "    )\n",
    "\n",
    "    ## fix longitude coord\n",
    "    components_sub = fix_lon_coord(components_sub)\n",
    "\n",
    "    ## rename w grid\n",
    "    w_comp = components_sub[\"w\"].rename({\"z_w_top\": \"z_t\"})\n",
    "    w_comp = w_comp.assign_coords({\"z_t\": components_sub.z_t})\n",
    "\n",
    "    ## update in xarray\n",
    "    components_sub = components_sub.drop_vars(\"w\")\n",
    "    components_sub[\"w\"] = w_comp\n",
    "\n",
    "    # reset member dimension so they all match (NHF labeled differently...)\n",
    "    member_coord = dict(member_id=np.arange(100))\n",
    "    get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "    scores_sub = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs_sub.items()])\n",
    "\n",
    "    ## convert z coords from cm to m\n",
    "    components_sub = convert_cm_to_m(components_sub)\n",
    "\n",
    "    ## convert u and w from cm/s to m/month\n",
    "\n",
    "    # conversion factors\n",
    "    m_per_cm = 1 / 100\n",
    "    s_per_day = 86400\n",
    "    s_per_month = s_per_day * 30\n",
    "\n",
    "    # do conversion\n",
    "    scores_sub[\"w\"] = scores_sub[\"w\"] * m_per_cm * s_per_month\n",
    "    scores_sub[\"u\"] = scores_sub[\"u\"] * m_per_cm * s_per_month\n",
    "\n",
    "    return components_sub, scores_sub\n",
    "\n",
    "\n",
    "def load_surf():\n",
    "    \"\"\"Load surface -- or near-surface -- data\"\"\"\n",
    "\n",
    "    ## path to EOF data\n",
    "    eofs_fp = pathlib.Path(os.environ[\"DATA_FP\"], \"cesm\")\n",
    "\n",
    "    ## variables to load (and how to rename them)\n",
    "    names = [\"tos\", \"zos\", \"tauu\", \"tauv\", \"nhf\", \"mlotst\", \"pr\"]\n",
    "    newnames = [\"sst\", \"ssh\", \"taux\", \"tauy\", \"nhf\", \"mld\", \"pr\"]\n",
    "\n",
    "    # ## load the EOFs\n",
    "    load_var = lambda x: src.utils.load_eofs(pathlib.Path(eofs_fp, f\"eofs_{x}.nc\"))\n",
    "    eofs = {y: load_var(x) for (y, x) in zip(newnames, names)}\n",
    "\n",
    "    ## for convenience, put spatial patterns / components in single dataset\n",
    "    components = xr.merge([eofs_.components().rename(y) for (y, eofs_) in eofs.items()])\n",
    "\n",
    "    # reset member dimension so they all match (NHF labeled differently...)\n",
    "    member_coord = dict(member=np.arange(100))\n",
    "    get_scores = lambda x, n: x.scores().assign_coords(member_coord).rename(n)\n",
    "    scores = xr.merge([get_scores(eofs_, n) for (n, eofs_) in eofs.items()])\n",
    "\n",
    "    ## convert ssh from m to cm\n",
    "    scores[\"ssh\"].values *= 100\n",
    "\n",
    "    ## convert from stress on atm to stress on ocn\n",
    "    scores[\"taux\"].values *= -1\n",
    "\n",
    "    ## convert MLD from cm to m\n",
    "    scores[\"mld\"] = scores[\"mld\"] / 100\n",
    "\n",
    "    return components, scores\n",
    "\n",
    "\n",
    "def load_vel():\n",
    "    \"\"\"Load (ocean) surface velocity data\"\"\"\n",
    "\n",
    "    ## path to EOF data\n",
    "    eofs_fp = pathlib.Path(os.environ[\"DATA_FP\"], \"cesm\")\n",
    "\n",
    "    ## load advection data\n",
    "    uvel_eofs = xr.open_dataset(eofs_fp / \"eofs_uvel.nc\")\n",
    "    vvel_eofs = xr.open_dataset(eofs_fp / \"eofs_vvel.nc\")\n",
    "\n",
    "    ## func to merge u and v data\n",
    "    merge = lambda u, v: xr.merge(\n",
    "        [\n",
    "            x.rename(n).drop_vars([\"variable\", \"z_t\"])\n",
    "            for x, n in zip([u, v], [\"uvel\", \"vvel\"])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## merge component data\n",
    "    vel_comps = merge(uvel_eofs.components, vvel_eofs.components)\n",
    "\n",
    "    ## merge scores\n",
    "    vel_scores = merge(uvel_eofs.scores, vvel_eofs.scores)\n",
    "    vel_scores = vel_scores.rename({\"member_id\": \"member\"})\n",
    "    vel_scores = vel_scores.assign_coords(dict(member=np.arange(100)))\n",
    "\n",
    "    return vel_comps, vel_scores\n",
    "\n",
    "\n",
    "def regrid_pop(pop_data, target_grid):\n",
    "    \"\"\"regrid POP data to target grid\"\"\"\n",
    "\n",
    "    ## get names of old/new coords\n",
    "    if \"lat\" in pop_data:\n",
    "        rename_dict = dict(lat=\"latitude\", lon=\"longitude\")\n",
    "    else:\n",
    "        rename_dict = dict(lon=\"longitude\")\n",
    "\n",
    "    ## rename coords\n",
    "    pop_data = pop_data.rename(rename_dict)\n",
    "\n",
    "    ## regrid\n",
    "    return pop_data.interp_like(target_grid)\n",
    "\n",
    "\n",
    "def load_and_merge():\n",
    "    \"\"\"load data components, merge, and save to specified filepath\"\"\"\n",
    "\n",
    "    ## load data from different datasets\n",
    "    components_sub, scores_sub = load_sub()\n",
    "    components, scores = load_surf()\n",
    "    components_vel, scores_vel = load_vel()\n",
    "\n",
    "    ## regrid so everything matches MMLEA\n",
    "    components_vel = regrid_pop(components_vel, components[[\"latitude\", \"longitude\"]])\n",
    "    components_sub = regrid_pop(components_sub, components[\"longitude\"])\n",
    "\n",
    "    ## rename subsurface scores to match other data\n",
    "    scores_sub = scores_sub.rename({\"member_id\": \"member\"})\n",
    "\n",
    "    ## merge variables\n",
    "    components_all = xr.merge([components, components_vel, components_sub])\n",
    "    scores_all = xr.merge([scores, scores_vel, scores_sub])\n",
    "\n",
    "    return components_all, scores_all\n",
    "\n",
    "\n",
    "def compute_forced_anom(save_dir):\n",
    "    \"\"\"Compute forced and anomaly components, and save to file\"\"\"\n",
    "\n",
    "    ## get filepaths\n",
    "    forced_fp = save_dir / \"forced.nc\"\n",
    "    anom_fp = save_dir / \"anom.nc\"\n",
    "\n",
    "    ## try loading pre-computed data\n",
    "    try:\n",
    "        forced = xr.open_dataset(forced_fp)\n",
    "        anom = xr.open_dataset(anom_fp)\n",
    "\n",
    "    except:\n",
    "\n",
    "        ## load data\n",
    "        components, scores = load_and_merge()\n",
    "\n",
    "        ## separate scores into forced and anomalies\n",
    "        forced, anom = src.utils.separate_forced(scores)\n",
    "\n",
    "        ## new names for components to avoid merge conflict\n",
    "        old_names = list(components)\n",
    "        rename_dict = {n: f\"{n}_comp\" for n in old_names}\n",
    "\n",
    "        ## add component information to scores\n",
    "        forced = xr.merge([forced, components.rename(rename_dict)])\n",
    "        anom = xr.merge([anom, components.rename(rename_dict)])\n",
    "\n",
    "        ## drop attrs (to avoid issues saving)\n",
    "        forced = forced.drop_attrs()\n",
    "        anom = anom.drop_attrs()\n",
    "\n",
    "        ## save to file\n",
    "        forced.to_netcdf(forced_fp)\n",
    "        anom.to_netcdf(anom_fp)\n",
    "\n",
    "    return forced, anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d8c15-31cb-49d8-9774-0bb1f343dcd7",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111b0455-3f4f-4c10-9f01-c7f1346fdc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = pathlib.Path(os.environ[\"DATA_FP\"], \"cesm\", \"consolidated\")\n",
    "forced, anom = compute_forced_anom(save_dir=SAVE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
