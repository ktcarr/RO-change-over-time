{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "456cb565-7349-4383-a5a5-361ce8a7c257",
   "metadata": {},
   "source": [
    "# ENSO composites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e916c4-0168-4b9a-ae1b-6e4b47159b06",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5861338-447b-45f5-aa33-a71239080118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pathlib\n",
    "import cmocean\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Import custom modules\n",
    "import src.utils\n",
    "\n",
    "## set plotting specs\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## bump up DPI\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "## get filepaths\n",
    "DATA_FP = pathlib.Path(os.environ[\"DATA_FP\"])\n",
    "SAVE_FP = pathlib.Path(os.environ[\"SAVE_FP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11b83f-834e-48de-8a2a-cdd0929e8c35",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26caf456-641e-4c54-af6e-ddcf264e196e",
   "metadata": {},
   "source": [
    "### $T$, $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65b6d3-2710-4dd1-93eb-1d7f571dbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open data\n",
    "Th = src.utils.load_cesm_indices()\n",
    "\n",
    "## rename indices for convenience\n",
    "Th = Th.rename(\n",
    "    {\n",
    "        \"north_tropical_atlantic\": \"natl\",\n",
    "        \"atlantic_nino\": \"nino_atl\",\n",
    "        \"tropical_indian_ocean\": \"iobm\",\n",
    "        \"indian_ocean_dipole\": \"iod\",\n",
    "        \"north_pacific_meridional_mode\": \"npmm\",\n",
    "        \"south_pacific_meridional_mode\": \"spmm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "## load ELI and tropical sst data\n",
    "eli = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/eli.nc\"))\n",
    "trop_sst = xr.open_dataset(pathlib.Path(DATA_FP, \"cesm/trop_sst.nc\"))\n",
    "Th = xr.merge([Th, eli, trop_sst])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95d7dc-1a16-4abf-8b7d-946c78728003",
   "metadata": {},
   "source": [
    "### Spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34cf12c-7735-4aee-93e4-04c6d67ce853",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load spatial data\n",
    "CONS_DIR = pathlib.Path(DATA_FP, \"cesm\", \"consolidated\")\n",
    "forced = xr.open_dataset(CONS_DIR / \"forced.nc\")\n",
    "anom = xr.open_dataset(CONS_DIR / \"anom.nc\")\n",
    "\n",
    "## add T,h information\n",
    "for n in [\"T_3\", \"T_34\", \"T_4\", \"eli_05\", \"h\", \"h_w\", \"trop_sst_05\"]:\n",
    "    anom[n] = Th[n]\n",
    "\n",
    "## get \"total\" ssh\n",
    "anom[\"sst_total\"] = forced[\"sst\"] + anom[\"sst\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58129817-f7e5-4bc7-9c41-cf94e1b44b9c",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3acb2-662c-4c6a-a99b-6abe0da0eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into early/late periods\n",
    "t_early = dict(time=slice(\"1851\", \"1880\"))\n",
    "# t_late = dict(time=slice(\"1990\", \"2020\"))\n",
    "t_late = dict(time=slice(\"2071\", \"2100\"))\n",
    "\n",
    "## split surface data\n",
    "anom_early = anom.sel(t_early)\n",
    "anom_late = anom.sel(t_late)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63816f-2573-4bed-bb62-43f268964077",
   "metadata": {},
   "source": [
    "## Composite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f15457-c688-49c6-aabd-996915472b58",
   "metadata": {},
   "source": [
    "### Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde6455-1288-4167-99f8-0feb78be1067",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_composite(idx, data, peak_month, q=0.95, is_warm=True):\n",
    "    \"\"\"\n",
    "    Get hovmoller composite based on specified:\n",
    "    - data: used to compute index/make composite\n",
    "    - peak_month: month to center composite on\n",
    "    - q: quantile threshold for composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## handle warm/cold case\n",
    "    if is_warm:\n",
    "        kwargs = dict(q=q, check_cutoff=lambda x, cut: x > cut)\n",
    "    else:\n",
    "        kwargs = dict(q=1 - q, check_cutoff=lambda x, cut: x < cut)\n",
    "\n",
    "    ## kwargs for composite\n",
    "    kwargs = dict(kwargs, peak_month=peak_month, idx=idx, data=data)\n",
    "\n",
    "    ## composite of projected data\n",
    "    comp_proj = src.utils.make_composite(**kwargs)\n",
    "\n",
    "    return comp_proj\n",
    "\n",
    "\n",
    "def get_spatial_composite(data, **composite_kwargs):\n",
    "    \"\"\"\n",
    "    Get spatial composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## pull out components\n",
    "    components, scores = src.utils.split_components(data)\n",
    "\n",
    "    ## get projected composite\n",
    "    comp_proj = get_composite(data=scores, **composite_kwargs)\n",
    "\n",
    "    ## reconstruct spatial fields\n",
    "    comp = reconstruct_helper(comp_proj, components, func=lambda x: x).drop_vars(\"mode\")\n",
    "\n",
    "    ## reconstruct relative SST\n",
    "    comp[\"sst_rel\"] = comp[\"sst_total\"] - comp[\"trop_sst_05\"]\n",
    "\n",
    "    return comp\n",
    "\n",
    "\n",
    "def reconstruct_helper(composite, components, func):\n",
    "    \"\"\"reconstruction helper function for composite\"\"\"\n",
    "\n",
    "    ## copy to hold reconstructed results\n",
    "    composite_recon = copy.deepcopy(composite)\n",
    "\n",
    "    ## reconstruct anomalies\n",
    "    for c in list(components):\n",
    "        composite_recon[c] = src.utils.reconstruct_fn(\n",
    "            components=components[c],\n",
    "            scores=composite[c],\n",
    "            fn=func,\n",
    "        )\n",
    "\n",
    "    ## check for \"total\" fields\n",
    "    for c in list(composite):\n",
    "        if \"_total\" in c:\n",
    "            n = c[:-6]\n",
    "            composite_recon[c] = src.utils.reconstruct_fn(\n",
    "                components=components[n],\n",
    "                scores=composite[c],\n",
    "                fn=func,\n",
    "            )\n",
    "\n",
    "    return composite_recon\n",
    "\n",
    "\n",
    "def get_spatial_clim(forced, lags, peak_month):\n",
    "    \"\"\"get climatologies of spatial variables\"\"\"\n",
    "\n",
    "    ## reconstruct monthly climatology for period\n",
    "    clim = src.utils.reconstruct_clim(data=forced)\n",
    "\n",
    "    ## convert to lag coordinates\n",
    "    months = 1 + np.mod(lags + peak_month - 1, 12)\n",
    "    clim_comp = xr.concat(\n",
    "        [clim.sel(month=m).drop_vars(\"month\") for m in months],\n",
    "        dim=lags,\n",
    "    )\n",
    "\n",
    "    return clim_comp\n",
    "\n",
    "\n",
    "def add_advection_terms(comp, comp_clim, delta=5, H0=None):\n",
    "    \"\"\"add advection terms to composite\"\"\"\n",
    "\n",
    "    ## copy composite\n",
    "    comp_ = copy.deepcopy(comp)\n",
    "\n",
    "    ## zonal velocity\n",
    "    comp_[\"adv_uprime_Tbar\"] = -src.utils.get_udTdx(u=comp[\"u\"], T=comp_clim[\"T\"])\n",
    "    comp_[\"adv_ubar_Tprime\"] = -src.utils.get_udTdx(T=comp[\"T\"], u=comp_clim[\"u\"])\n",
    "\n",
    "    ## vertical velocity\n",
    "    comp_[\"adv_wprime_Tbar\"] = src.utils.get_wdTdz(w=comp[\"w\"], T=comp_clim[\"T\"])\n",
    "    comp_[\"adv_wbar_Tprime\"] = src.utils.get_wdTdz(T=comp[\"T\"], w=comp_clim[\"w\"])\n",
    "\n",
    "    ## integrate over mixed layer\n",
    "    for v in list(comp_):\n",
    "        if \"adv\" in v:\n",
    "            comp_[f\"{v}_ml\"] = src.utils.get_ml_avg(\n",
    "                comp_[v],\n",
    "                Hm=comp_clim[\"mld\"],\n",
    "                delta=delta,\n",
    "                H0=H0,\n",
    "            )\n",
    "\n",
    "    ## add together zonal adv and thermocline feedbacks\n",
    "    comp_[\"Th_zaf_ml\"] = comp_[\"adv_wbar_Tprime_ml\"] + comp_[\"adv_uprime_Tbar_ml\"]\n",
    "\n",
    "    return comp_\n",
    "\n",
    "\n",
    "def get_T_ml_tendency(T, mld, delta=5, H0=None):\n",
    "    \"\"\"compute mixed-layer temperature tendency\"\"\"\n",
    "\n",
    "    ## integrate over mixed layer\n",
    "    T_ml = src.utils.get_ml_avg(T, Hm=mld, delta=delta, H0=H0)\n",
    "\n",
    "    ## compute tendency\n",
    "    return T_ml.differentiate(\"lag\")\n",
    "\n",
    "\n",
    "def get_spatial_composite_wrapper(\n",
    "    data,\n",
    "    forced_scores,\n",
    "    peak_month,\n",
    "    delta=5,\n",
    "    H0=None,\n",
    "    **composite_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get spatial composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## get spatial composite of anomalies\n",
    "    composite = get_spatial_composite(\n",
    "        data=data,\n",
    "        peak_month=peak_month,\n",
    "        **composite_kwargs,\n",
    "    )\n",
    "\n",
    "    ## get background state\n",
    "    comp_clim = get_spatial_clim(\n",
    "        forced=forced_scores,\n",
    "        lags=composite.lag,\n",
    "        peak_month=peak_month,\n",
    "    )\n",
    "\n",
    "    ## add advection terms\n",
    "    composite = add_advection_terms(\n",
    "        comp=composite, comp_clim=comp_clim, delta=delta, H0=H0\n",
    "    )\n",
    "\n",
    "    ## add mixed-layer temperature tendency\n",
    "    composite[\"ddt_T\"] = get_T_ml_tendency(\n",
    "        composite[\"T\"],\n",
    "        mld=comp_clim[\"mld\"],\n",
    "        delta=delta,\n",
    "        H0=H0,\n",
    "    )\n",
    "\n",
    "    ## add SST tendency\n",
    "    composite[\"ddt_sst\"] = composite[\"sst\"].differentiate(\"lag\")\n",
    "\n",
    "    ## get NHF in units of K/mo\n",
    "    sec_per_mo = 8.64e4 * 30\n",
    "    rho = 1.02e3\n",
    "    Cp = 4.2e3\n",
    "    H = comp_clim[\"mld\"]\n",
    "    # H = 50\n",
    "    composite[\"Q\"] = composite[\"nhf\"] * sec_per_mo / (rho * Cp * H)\n",
    "\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9957c-c23a-4627-ae6f-80e618ac0f9a",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52bfdb-8a05-4455-aeb5-447b007cbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify what variable to use\n",
    "VARNAME = \"T_34\"\n",
    "\n",
    "## specify shared args\n",
    "kwargs = dict(\n",
    "    peak_month=12,\n",
    "    q=0.95,\n",
    "    is_warm=True,\n",
    "    delta=10,\n",
    "    H0=60,\n",
    ")\n",
    "\n",
    "## do the compute\n",
    "comp_early = get_spatial_composite_wrapper(\n",
    "    idx=anom_early[VARNAME],\n",
    "    data=anom_early,\n",
    "    forced_scores=forced.sel(t_early),\n",
    "    **kwargs,\n",
    ")\n",
    "comp_late = get_spatial_composite_wrapper(\n",
    "    idx=anom_late[VARNAME],\n",
    "    data=anom_late,\n",
    "    forced_scores=forced.sel(t_late),\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "## hovmoller version\n",
    "merimean = lambda x: x.sel(latitude=slice(-5, 5)).mean(\"latitude\")\n",
    "hov_comp_early = merimean(comp_early).transpose(\"lag\", ...)\n",
    "hov_comp_late = merimean(comp_late).transpose(\"lag\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4621b-227a-4e7b-8cc7-c09abe8bfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify amplitudes for plots\n",
    "scales = np.array([4 / 3, 4 / 3, 4 / 3])\n",
    "\n",
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7, 3), layout=\"constrained\")\n",
    "\n",
    "for ax, merimean, scale in zip(\n",
    "    axs, [hov_comp_early, hov_comp_late, 2 * (hov_comp_late - hov_comp_early)], scales\n",
    "):\n",
    "    cf, _ = src.utils.plot_hov(ax=ax, x=merimean, beta=scale)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ## label x axis\n",
    "    ax.set_xlabel(\"Lon\")\n",
    "    ax.set_xticks([190, 240])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "## label\n",
    "font_kwargs = dict(size=10)\n",
    "axs[0].set_title(\"Early (1853-1883)\", **font_kwargs)\n",
    "axs[1].set_title(\"Late (2067-2097)\", **font_kwargs)\n",
    "axs[2].set_title(\"Difference (x2)\", **font_kwargs)\n",
    "cb = fig.colorbar(cf, ax=axs[2], ticks=[-4, 0, 4], label=\"K\")\n",
    "src.utils.label_hov_yaxis(axs[0], peak_mon=kwargs[\"peak_month\"])\n",
    "\n",
    "## plot ELI\n",
    "axs[0].plot(\n",
    "    comp_early[\"eli_05\"],\n",
    "    comp_early.lag,\n",
    "    c=\"magenta\",\n",
    ")\n",
    "axs[1].plot(comp_late[\"eli_05\"], comp_late.lag, c=\"magenta\", ls=\"--\")\n",
    "axs[2].plot(comp_early[\"eli_05\"], comp_early.lag, c=\"magenta\", ls=\"-\")\n",
    "axs[2].plot(comp_late[\"eli_05\"], comp_late.lag, c=\"magenta\", ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envs]",
   "language": "python",
   "name": "conda-env-envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
